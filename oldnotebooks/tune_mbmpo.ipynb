{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example of using training on CartPole.\"\"\"\n",
    "\n",
    "#import argparse\n",
    "#/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/model_ensemble.py\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.agents.mbmpo.model_ensemble import DynamicsEnsembleCustomModel\n",
    "from ray.rllib.examples.env.mbmpo_env import CartPoleWrapper\n",
    "from ray.rllib.models.catalog import ModelCatalog\n",
    "from ray.rllib.agents.mbmpo.utils import MBMPOExploration \n",
    "from ray.rllib.env.wrappers.model_vector_env import model_vector_env\n",
    "from ray.rllib.utils.deprecation import DEPRECATED_VALUE\n",
    "from ray.rllib.agents.mbmpo.mbmpo import MBMPOTrainer\n",
    "train=True\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--num-workers\", default=6, type=int)\n",
    "#parser.add_argument(\"--training-iteration\", default=10000, type=int)\n",
    "#parser.add_argument(\"--ray-num-cpus\", default=7, type=int)\n",
    "#args = parser.parse_args()\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=7)\n",
    "\n",
    "ModelCatalog.register_custom_model(\"DynamicsEnsembleCustomModel\", DynamicsEnsembleCustomModel)\n",
    "\n",
    "config={\n",
    "    \"env\": CartPoleWrapper,\n",
    "    \"use_gae\": True,\n",
    "    # GAE(lambda) parameter.\n",
    "    \"lambda\": 1.0,\n",
    "    # Initial coefficient for KL divergence.\n",
    "    \"kl_coeff\": 0.0005,\n",
    "    # Size of batches collected from each worker.\n",
    "    \"rollout_fragment_length\": 200,\n",
    "    # Do create an actual env on the local worker (worker-idx=0).\n",
    "    \"create_env_on_driver\": True,\n",
    "    # Step size of SGD.\n",
    "    \"lr\": 1e-3,\n",
    "    # Coefficient of the value function loss.\n",
    "    \"vf_loss_coeff\": 0.5,\n",
    "    # Coefficient of the entropy regularizer.\n",
    "    \"entropy_coeff\": 0.0,\n",
    "    # PPO clip parameter.\n",
    "    \"clip_param\": 0.5,\n",
    "    # Clip param for the value function. Note that this is sensitive to the\n",
    "    # scale of the rewards. If your expected V is large, increase this.\n",
    "    \"vf_clip_param\": 10.0,\n",
    "    # If specified, clip the global norm of gradients by this amount.\n",
    "    \"grad_clip\": None,\n",
    "    # Target value for KL divergence.\n",
    "    \"kl_target\": 0.01,\n",
    "    # Whether to rollout \"complete_episodes\" or \"truncate_episodes\".\n",
    "    \"batch_mode\": \"complete_episodes\",\n",
    "    # Which observation filter to apply to the observation.\n",
    "    \"observation_filter\": \"NoFilter\",\n",
    "    # Number of Inner adaptation steps for the MAML algorithm.\n",
    "    \"inner_adaptation_steps\": 1,\n",
    "    # Number of MAML steps per meta-update iteration (PPO steps).\n",
    "    \"maml_optimizer_steps\": 8,\n",
    "    # Inner adaptation step size.\n",
    "    \"inner_lr\": 1e-3,\n",
    "    # Horizon of the environment (200 in MB-MPO paper).\n",
    "    \"horizon\": 200,\n",
    "    # Dynamics ensemble hyperparameters.\n",
    "    \"dynamics_model\": {\n",
    "        \"custom_model\": DynamicsEnsembleCustomModel,\n",
    "        # Number of Transition-Dynamics (TD) models in the ensemble.\n",
    "        \"ensemble_size\": 5,\n",
    "        # Hidden layers for each model in the TD-model ensemble.\n",
    "        \"fcnet_hiddens\": [512, 512, 512],\n",
    "        # Model learning rate.\n",
    "        \"lr\": 1e-3,\n",
    "        # Max number of training epochs per MBMPO iter.\n",
    "        \"train_epochs\": 500,\n",
    "        # Model batch size.\n",
    "        \"batch_size\": 500,\n",
    "        # Training/validation split.\n",
    "        \"valid_split_ratio\": 0.2,\n",
    "        # Normalize data (obs, action, and deltas).\n",
    "        \"normalize_data\": True,\n",
    "    },\n",
    "    # Exploration for MB-MPO is based on StochasticSampling, but uses 8000\n",
    "    # random timesteps up-front for worker=0.\n",
    "    \"exploration_config\": {\n",
    "        \"type\": MBMPOExploration,\n",
    "        \"random_timesteps\": 8000,\n",
    "    },\n",
    "    # Workers sample from dynamics models, not from actual envs.\n",
    "    \"custom_vector_env\": model_vector_env,\n",
    "    # How many iterations through MAML per MBMPO iteration.\n",
    "    \"num_maml_steps\": 10,\n",
    "\n",
    "    # Deprecated keys:\n",
    "    # Share layers for value function. If you set this to True, it's important\n",
    "    # to tune vf_loss_coeff.\n",
    "    # Use config.model.vf_share_layers instead.\n",
    "    \"vf_share_layers\": DEPRECATED_VALUE,\n",
    "}\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 10:36:13,592\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2022-08-18 10:36:13,603\tWARNING mbmpo.py:351 -- MB-MPO only supported in PyTorch so far! Switching to `framework=torch`.\n",
      "2022-08-18 10:36:13,604\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2022-08-18 10:36:13,695\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "2022-08-18 10:36:14,089\tWARNING deprecation.py:46 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dynamics Ensemble - Epoch #0:Train loss: 1.0244043 1.0177811 0.958069 0.9996267 1.0046558, Valid Loss: 0.7060777 0.7210353 0.7389786 0.6927346 0.6807207,  Moving Avg Valid Loss: 1.0414646 1.0635271 1.0899935 1.0217835 1.0040629\n",
      "Training Dynamics Ensemble - Epoch #1:Train loss: 0.73617774 0.7062043 0.666462 0.68393123 0.70411044, Valid Loss: 0.47564933 0.47751516 0.41951814 0.4376904 0.42459798,  Moving Avg Valid Loss: 1.0131738 1.0342264 1.0564697 0.9925788 0.97508967\n",
      "Training Dynamics Ensemble - Epoch #2:Train loss: 0.47969782 0.42715365 0.4009486 0.40463194 0.43163553, Valid Loss: 0.24128017 0.23920935 0.1461424 0.19061852 0.17496255,  Moving Avg Valid Loss: 0.9745791 0.99447554 1.0109533 0.95248073 0.93508327\n",
      "Training Dynamics Ensemble - Epoch #3:Train loss: 0.22634193 0.18853109 0.15329848 0.16549137 0.17201005, Valid Loss: 0.08172831 0.06509285 0.060785085 0.038180195 0.036184985,  Moving Avg Valid Loss: 0.9299366 0.9480064 0.9634449 0.9067657 0.8901383\n",
      "Training Dynamics Ensemble - Epoch #4:Train loss: 0.061400436 0.08050324 0.030339137 0.0644383 0.04911953, Valid Loss: 0.09640433 0.040317066 0.1715378 0.089193605 0.10245696,  Moving Avg Valid Loss: 0.88825995 0.90262187 0.9238495 0.8658871 0.85075426\n",
      "Training Dynamics Ensemble - Epoch #5:Train loss: 0.09102155 0.091474466 0.1158227 0.11233147 0.15414926, Valid Loss: 0.1739217 0.13425566 0.21019924 0.16823399 0.13285957,  Moving Avg Valid Loss: 0.852543 0.8642036 0.888167 0.83100444 0.8148595\n",
      "Training Dynamics Ensemble - Epoch #6:Train loss: 0.17534368 0.17150015 0.16781825 0.16593102 0.17299588, Valid Loss: 0.13469604 0.08570741 0.11735372 0.09656171 0.06319958,  Moving Avg Valid Loss: 0.8166506 0.82527876 0.8496263 0.7942823 0.7772765\n",
      "Training Dynamics Ensemble - Epoch #7:Train loss: 0.12955162 0.103522345 0.08839055 0.093487486 0.074421115, Valid Loss: 0.054116942 0.023683824 0.030118894 0.026783517 0.016491596,  Moving Avg Valid Loss: 0.778524 0.785199 0.808651 0.7559074 0.73923725\n",
      "Training Dynamics Ensemble - Epoch #8:Train loss: 0.0477512 0.033418067 0.01840325 0.02573342 0.014601214, Valid Loss: 0.021049507 0.018608209 0.019028643 0.023291217 0.03547421,  Moving Avg Valid Loss: 0.7406503 0.74686944 0.7691698 0.7192766 0.7040491\n",
      "Training Dynamics Ensemble - Epoch #9:Train loss: 0.019300826 0.02030218 0.016891293 0.020258129 0.0341149, Valid Loss: 0.035108916 0.03975664 0.056475442 0.049203657 0.07160779,  Moving Avg Valid Loss: 0.70537317 0.71151376 0.73353505 0.68577296 0.67242706\n",
      "Training Dynamics Ensemble - Epoch #10:Train loss: 0.038206693 0.03751917 0.05138021 0.045266543 0.0717026, Valid Loss: 0.057553045 0.056547683 0.079494044 0.06770299 0.079746686,  Moving Avg Valid Loss: 0.67298216 0.6787655 0.70083296 0.65486944 0.642793\n",
      "Training Dynamics Ensemble - Epoch #11:Train loss: 0.061879367 0.06265148 0.071796216 0.06491953 0.0785959, Valid Loss: 0.065473735 0.056605414 0.06796342 0.06666344 0.060070165,  Moving Avg Valid Loss: 0.64260674 0.64765745 0.6691895 0.62545913 0.6136569\n",
      "Training Dynamics Ensemble - Epoch #12:Train loss: 0.066933475 0.067622505 0.0640494 0.06290876 0.057680022, Valid Loss: 0.05963981 0.042647522 0.04085844 0.050667413 0.031999327,  Moving Avg Valid Loss: 0.6134584 0.6174069 0.637773 0.59671956 0.584574\n",
      "Training Dynamics Ensemble - Epoch #13:Train loss: 0.05667241 0.04938375 0.041315954 0.04553588 0.030797265, Valid Loss: 0.04769713 0.026007414 0.019293485 0.030720834 0.012742051,  Moving Avg Valid Loss: 0.5851703 0.5878369 0.606849 0.56841964 0.5559824\n",
      "Training Dynamics Ensemble - Epoch #14:Train loss: 0.041121166 0.028490625 0.01983372 0.027187115 0.01447556, Valid Loss: 0.033685356 0.0135360705 0.010330812 0.015514387 0.009314079,  Moving Avg Valid Loss: 0.557596 0.5591219 0.5770231 0.54077435 0.528649\n",
      "Training Dynamics Ensemble - Epoch #15:Train loss: 0.026073184 0.016911559 0.008621128 0.01510195 0.0125640435, Valid Loss: 0.020181468 0.0077397227 0.011765717 0.009496654 0.017866429,  Moving Avg Valid Loss: 0.53072524 0.5315528 0.54876024 0.5142104 0.5031098\n",
      "Training Dynamics Ensemble - Epoch #16:Train loss: 0.014691198 0.011339967 0.009184608 0.010990019 0.01972871, Valid Loss: 0.012094864 0.01194402 0.01891219 0.012189345 0.027124802,  Moving Avg Valid Loss: 0.5047937 0.5055723 0.5222678 0.48910934 0.47931057\n",
      "Training Dynamics Ensemble - Epoch #17:Train loss: 0.010304704 0.0123481285 0.017001336 0.014487918 0.026504543, Valid Loss: 0.013775687 0.021819036 0.02461572 0.018201722 0.026852485,  Moving Avg Valid Loss: 0.4802428 0.48138463 0.4973852 0.46556395 0.45668766\n",
      "Training Dynamics Ensemble - Epoch #18:Train loss: 0.014055296 0.01993874 0.023643235 0.020075636 0.024992704, Valid Loss: 0.021950923 0.025003618 0.02349935 0.021408984 0.017982062,  Moving Avg Valid Loss: 0.4573282 0.45856556 0.4736909 0.4433562 0.43475237\n",
      "Training Dynamics Ensemble - Epoch #19:Train loss: 0.021313256 0.023647744 0.022916172 0.021153077 0.016503295, Valid Loss: 0.027001683 0.019021945 0.016904231 0.020363603 0.009197872,  Moving Avg Valid Loss: 0.43581185 0.43658838 0.45085156 0.42220655 0.41347462\n",
      "Training Dynamics Ensemble - Epoch #20:Train loss: 0.024486255 0.01924966 0.016134609 0.017979909 0.0085913455, Valid Loss: 0.023467474 0.012229376 0.009754337 0.016420135 0.0067699603,  Moving Avg Valid Loss: 0.41519463 0.4153704 0.42879668 0.40191722 0.3931394\n",
      "Training Dynamics Ensemble - Epoch #21:Train loss: 0.020356644 0.0134063335 0.008801566 0.013206248 0.006484014, Valid Loss: 0.014584346 0.0095882155 0.0060353717 0.011920514 0.010265624,  Moving Avg Valid Loss: 0.3951641 0.39508128 0.4076586 0.38241738 0.3739957\n",
      "Training Dynamics Ensemble - Epoch #22:Train loss: 0.012312583 0.009965281 0.005286152 0.008754353 0.009553315, Valid Loss: 0.0071111037 0.0098193465 0.0064426237 0.009735988 0.015108226,  Moving Avg Valid Loss: 0.37576142 0.37581816 0.3875978 0.3637833 0.3560513\n",
      "Training Dynamics Ensemble - Epoch #23:Train loss: 0.0060099717 0.008099027 0.0061638514 0.007096048 0.01363426, Valid Loss: 0.0051808045 0.011112873 0.008867564 0.010043467 0.01694577,  Moving Avg Valid Loss: 0.3572324 0.3575829 0.36866128 0.3460963 0.339096\n",
      "Training Dynamics Ensemble - Epoch #24:Train loss: 0.004478219 0.008099382 0.008954217 0.007893026 0.015044172, Valid Loss: 0.008228893 0.012455602 0.011128564 0.010929608 0.014360838,  Moving Avg Valid Loss: 0.3397822 0.34032652 0.35078466 0.32933798 0.32285923\n",
      "Training Dynamics Ensemble - Epoch #25:Train loss: 0.006904396 0.0097928075 0.011007076 0.00877174 0.012767336, Valid Loss: 0.012683156 0.012615971 0.01238096 0.0111864945 0.008938672,  Moving Avg Valid Loss: 0.32342726 0.323941 0.33386448 0.3134304 0.3071632\n",
      "Training Dynamics Ensemble - Epoch #26:Train loss: 0.01025383 0.010737577 0.011174938 0.0089154085 0.008176355, Valid Loss: 0.014979022 0.011016463 0.012262409 0.01051801 0.004003617,  Moving Avg Valid Loss: 0.30800486 0.30829477 0.31778437 0.29828477 0.29200524\n",
      "Training Dynamics Ensemble - Epoch #27:Train loss: 0.01177121 0.009431526 0.009472938 0.008522065 0.003985605, Valid Loss: 0.013735611 0.008417134 0.010613488 0.008838452 0.002401807,  Moving Avg Valid Loss: 0.2932914 0.2933009 0.3024258 0.28381243 0.27752507\n",
      "Training Dynamics Ensemble - Epoch #28:Train loss: 0.010570868 0.007297762 0.0065939478 0.007350928 0.0026148024, Valid Loss: 0.010026628 0.005967717 0.008190321 0.0067645432 0.0042273323,  Moving Avg Valid Loss: 0.27912816 0.27893424 0.28771403 0.26996005 0.26386017\n",
      "Training Dynamics Ensemble - Epoch #29:Train loss: 0.007634594 0.005990845 0.0038381368 0.0056847227 0.0042579407, Valid Loss: 0.0061100153 0.004284233 0.0064063016 0.0052857525 0.0068371324,  Moving Avg Valid Loss: 0.26547727 0.26520175 0.27364865 0.25672632 0.25100902\n",
      "Training Dynamics Ensemble - Epoch #30:Train loss: 0.0046605645 0.0051176576 0.0025078559 0.004423684 0.006690738, Valid Loss: 0.0038119908 0.003810895 0.0060389824 0.00463243 0.0074429014,  Moving Avg Valid Loss: 0.252394 0.2521322 0.26026818 0.24412163 0.2388307\n",
      "Training Dynamics Ensemble - Epoch #31:Train loss: 0.002917788 0.004342883 0.0029511573 0.0036576614 0.0073915883, Valid Loss: 0.0036830069 0.004540847 0.006592023 0.0046488405 0.0055796644,  Moving Avg Valid Loss: 0.23995844 0.23975264 0.24758437 0.23214799 0.22716814\n",
      "Training Dynamics Ensemble - Epoch #32:Train loss: 0.002783648 0.0043677804 0.0043785656 0.0032584898 0.005746256, Valid Loss: 0.0049613183 0.0052612326 0.0069135646 0.0052933204 0.0030369456,  Moving Avg Valid Loss: 0.22820857 0.22802806 0.23555084 0.22080524 0.21596158\n",
      "Training Dynamics Ensemble - Epoch #33:Train loss: 0.003761828 0.00477949 0.0054836604 0.0035949675 0.0032929513, Valid Loss: 0.00628788 0.004910166 0.006135618 0.0059181913 0.0018137856,  Moving Avg Valid Loss: 0.21711254 0.21687217 0.22408007 0.21006088 0.20525418\n",
      "Training Dynamics Ensemble - Epoch #34:Train loss: 0.0048484127 0.0045055607 0.0052927546 0.0042052562 0.0019575472, Valid Loss: 0.0066355043 0.004033206 0.0044606435 0.005684769 0.0023661018,  Moving Avg Valid Loss: 0.20658869 0.20623022 0.21309909 0.19984207 0.19510977\n",
      "Training Dynamics Ensemble - Epoch #35:Train loss: 0.00517729 0.0038411077 0.0039047322 0.0041587604 0.0022722625, Valid Loss: 0.005834977 0.0035451096 0.0029325492 0.0047135563 0.003721924,  Moving Avg Valid Loss: 0.196551 0.19609596 0.20259076 0.19008563 0.18554038\n",
      "Training Dynamics Ensemble - Epoch #36:Train loss: 0.004495674 0.003484727 0.0023366155 0.0035594099 0.0033850297, Valid Loss: 0.0044159694 0.0032921385 0.002379642 0.0036454743 0.0046133185,  Moving Avg Valid Loss: 0.18694425 0.18645577 0.19258021 0.18076362 0.17649403\n",
      "Training Dynamics Ensemble - Epoch #37:Train loss: 0.0032165952 0.0031843614 0.0015126894 0.002787769 0.004140342, Valid Loss: 0.0031048718 0.002859547 0.0029318256 0.0029383833 0.0043354775,  Moving Avg Valid Loss: 0.17775227 0.17727596 0.1830978 0.17187236 0.1678861\n",
      "Training Dynamics Ensemble - Epoch #38:Train loss: 0.0020530669 0.0027229085 0.0016224378 0.001990577 0.0038813266, Valid Loss: 0.0024032537 0.0024474438 0.004210139 0.0028624628 0.0031045133,  Moving Avg Valid Loss: 0.16898482 0.16853452 0.17415342 0.16342187 0.15964702\n",
      "Training Dynamics Ensemble - Epoch #39:Train loss: 0.0015228564 0.0024792454 0.0022710527 0.0016252402 0.0027831804, Valid Loss: 0.0024077287 0.0023009134 0.00550926 0.003259438 0.0018338742,  Moving Avg Valid Loss: 0.16065596 0.16022284 0.16572121 0.15541375 0.15175635\n",
      "Training Dynamics Ensemble - Epoch #40:Train loss: 0.0017082973 0.0025004346 0.0028657955 0.0018659193 0.0016462451, Valid Loss: 0.0028583629 0.0022484828 0.006043876 0.0036019683 0.0013148325,  Moving Avg Valid Loss: 0.15276608 0.15232413 0.15773734 0.14782315 0.14423427\n",
      "Training Dynamics Ensemble - Epoch #41:Train loss: 0.0022836202 0.0023944126 0.00292685 0.0022414827 0.0011911809, Valid Loss: 0.0033088992 0.0021183374 0.005492838 0.003598014 0.0015919389,  Moving Avg Valid Loss: 0.14529322 0.14481384 0.15012512 0.1406119 0.13710216\n",
      "Training Dynamics Ensemble - Epoch #42:Train loss: 0.0027431052 0.0021789193 0.0023728379 0.0024457783 0.0015032078, Valid Loss: 0.0033971716 0.0019570654 0.0043404917 0.0032037876 0.0020829935,  Moving Avg Valid Loss: 0.13819842 0.137671 0.14283589 0.1337415 0.13035119\n",
      "Training Dynamics Ensemble - Epoch #43:Train loss: 0.0027431715 0.0021254746 0.0015817718 0.0023715133 0.0020781336, Valid Loss: 0.0030447755 0.0017652767 0.0033533506 0.0024445266 0.0021654996,  Moving Avg Valid Loss: 0.13144074 0.1308757 0.13586175 0.12717664 0.1239419\n",
      "Training Dynamics Ensemble - Epoch #44:Train loss: 0.002268402 0.002056797 0.0010330701 0.0018842245 0.0022821284, Valid Loss: 0.0024806454 0.0015236748 0.0029289317 0.0016884615 0.0017292524,  Moving Avg Valid Loss: 0.124992736 0.1244081 0.1292151 0.12090223 0.11783127\n",
      "Training Dynamics Ensemble - Epoch #45:Train loss: 0.0015800862 0.0017674301 0.0009635992 0.0012668663 0.0019073886, Valid Loss: 0.0021008202 0.0013323812 0.0029850248 0.0014037555 0.0012070249,  Moving Avg Valid Loss: 0.11884814 0.11825431 0.1229036 0.11492731 0.112000056\n",
      "Training Dynamics Ensemble - Epoch #46:Train loss: 0.0010569966 0.0015118833 0.0012917367 0.0009650527 0.0013146262, Valid Loss: 0.0021710508 0.001253236 0.003122763 0.0016318383 0.0010549256,  Moving Avg Valid Loss: 0.11301428 0.11240426 0.11691456 0.10926253 0.10645279\n",
      "Training Dynamics Ensemble - Epoch #47:Train loss: 0.0009401607 0.0014279145 0.0016646396 0.001022684 0.0009768413, Valid Loss: 0.0026145058 0.0012925094 0.00298328 0.0020794217 0.0013508378,  Moving Avg Valid Loss: 0.107494295 0.10684867 0.11121799 0.103903376 0.10119769\n",
      "Training Dynamics Ensemble - Epoch #48:Train loss: 0.0011824165 0.0013761433 0.0017108808 0.0012720454 0.0010489026, Valid Loss: 0.0030596973 0.0014853178 0.00261808 0.0024267074 0.0017979214,  Moving Avg Valid Loss: 0.10227256 0.10158051 0.105788 0.09882954 0.096227705\n",
      "Training Dynamics Ensemble - Epoch #49:Train loss: 0.0015171195 0.001362592 0.0013946793 0.0015166679 0.0013241589, Valid Loss: 0.00312333 0.0017189176 0.002327087 0.0024436591 0.0019946173,  Moving Avg Valid Loss: 0.097315095 0.09658743 0.10061496 0.09401024 0.091516055\n",
      "Training Dynamics Ensemble - Epoch #50:Train loss: 0.0016343439 0.0014059463 0.0009838485 0.0014938501 0.0014637501, Valid Loss: 0.0027227101 0.0017493727 0.0022867993 0.0021553168 0.001778124,  Moving Avg Valid Loss: 0.092585474 0.09184553 0.09569854 0.089417495 0.08702916\n",
      "Training Dynamics Ensemble - Epoch #51:Train loss: 0.0014197215 0.0013627406 0.00073721027 0.0011827977 0.0013110524, Valid Loss: 0.0021214813 0.0015299229 0.0025090228 0.0017968968 0.0013218159,  Moving Avg Valid Loss: 0.08806227 0.087329745 0.09103907 0.085036464 0.082743794\n",
      "Training Dynamics Ensemble - Epoch #52:Train loss: 0.0010387681 0.0011991861 0.0007498384 0.0008661202 0.0009953099, Valid Loss: 0.0016678629 0.0012627965 0.0028324437 0.0015466204 0.00093433924,  Moving Avg Valid Loss: 0.08374255 0.083026394 0.086628735 0.08086197 0.07865332\n",
      "Training Dynamics Ensemble - Epoch #53:Train loss: 0.00075493194 0.0010485398 0.00093022664 0.00070900953 0.0007589026, Valid Loss: 0.0015344577 0.0011060911 0.0029399432 0.0014965149 0.00080391625,  Moving Avg Valid Loss: 0.07963215 0.07893038 0.082444295 0.076893695 0.07476085\n",
      "Training Dynamics Ensemble - Epoch #54:Train loss: 0.0007171853 0.0009767411 0.0010677283 0.0007375664 0.0007400188, Valid Loss: 0.001638358 0.0010436805 0.0026834633 0.001614787 0.00087799405,  Moving Avg Valid Loss: 0.07573246 0.07503604 0.07845625 0.07312975 0.0710667\n",
      "Training Dynamics Ensemble - Epoch #55:Train loss: 0.00087102386 0.00094382063 0.00103616 0.00091098656 0.0008706095, Valid Loss: 0.0017632663 0.0010063995 0.0022330037 0.0016919622 0.00095669687,  Moving Avg Valid Loss: 0.072034 0.07133456 0.07464509 0.06955786 0.067561194\n",
      "Training Dynamics Ensemble - Epoch #56:Train loss: 0.0010271274 0.00093395996 0.0008758042 0.0010265799 0.00096684555, Valid Loss: 0.0017576644 0.000974467 0.0018312677 0.0015889142 0.0009141944,  Moving Avg Valid Loss: 0.06852018 0.06781656 0.07100439 0.06615941 0.06422884\n",
      "Training Dynamics Ensemble - Epoch #57:Train loss: 0.0010398934 0.0009454959 0.00069257483 0.0009656256 0.00092187105, Valid Loss: 0.0016273325 0.0009377543 0.0016211604 0.001391393 0.00079545594,  Moving Avg Valid Loss: 0.06517554 0.06447262 0.06753522 0.06292101 0.06105717\n",
      "Training Dynamics Ensemble - Epoch #58:Train loss: 0.0009042331 0.00091834617 0.00059167325 0.00081212906 0.0007753835, Valid Loss: 0.0014792177 0.00089369377 0.0016189946 0.0012372481 0.0007298787,  Moving Avg Valid Loss: 0.061990723 0.061293676 0.06423941 0.05983682 0.0580408\n",
      "Training Dynamics Ensemble - Epoch #59:Train loss: 0.0007216661 0.00083519047 0.0006164431 0.0006529906 0.0006473666, Valid Loss: 0.0014090484 0.000872539 0.0017278322 0.0012126974 0.0007834259,  Moving Avg Valid Loss: 0.058961637 0.05827262 0.061113834 0.056905616 0.05517793\n",
      "Training Dynamics Ensemble - Epoch #60:Train loss: 0.0006032652 0.000773797 0.0006981705 0.00057653687 0.0006221395, Valid Loss: 0.0014479384 0.0008806981 0.0018369874 0.0013114708 0.00089550455,  Moving Avg Valid Loss: 0.05608595 0.055403024 0.058149993 0.05412591 0.052463807\n",
      "Training Dynamics Ensemble - Epoch #61:Train loss: 0.0005905841 0.0007591861 0.0007401263 0.00062935316 0.0006749461, Valid Loss: 0.0015628389 0.0008927821 0.0018885998 0.0014222745 0.0009568791,  Moving Avg Valid Loss: 0.053359795 0.052677512 0.055336922 0.051490724 0.04988846\n",
      "Training Dynamics Ensemble - Epoch #62:Train loss: 0.0006539986 0.0007490345 0.0007047198 0.0007091669 0.00072044577, Valid Loss: 0.0016830509 0.00089609635 0.0018935462 0.0014567208 0.0009080785,  Moving Avg Valid Loss: 0.05077596 0.05008844 0.052664753 0.048989024 0.04743944\n",
      "Training Dynamics Ensemble - Epoch #63:Train loss: 0.0007263708 0.0007388142 0.00061259745 0.0007326024 0.00069515454, Valid Loss: 0.0017297623 0.0008800731 0.001930201 0.001394211 0.0007802959,  Moving Avg Valid Loss: 0.048323646 0.04762802 0.050128024 0.046609282 0.04510648\n",
      "Training Dynamics Ensemble - Epoch #64:Train loss: 0.0007442557 0.0007258528 0.0005249623 0.0006927888 0.00060613337, Valid Loss: 0.0016604612 0.0008318377 0.002024999 0.0012625627 0.00067299546,  Moving Avg Valid Loss: 0.045990486 0.04528821 0.047722872 0.044341948 0.042884808\n",
      "Training Dynamics Ensemble - Epoch #65:Train loss: 0.000686508 0.0006783116 0.00049603684 0.0005997375 0.0005268374, Valid Loss: 0.0015075101 0.0007820988 0.0020805812 0.0011467681 0.0006547939,  Moving Avg Valid Loss: 0.043766335 0.043062903 0.045440756 0.04218219 0.040773306\n",
      "Training Dynamics Ensemble - Epoch #66:Train loss: 0.00058475614 0.0006255456 0.0005217402 0.00052769476 0.0005162787, Valid Loss: 0.0013634327 0.00076264277 0.0020091378 0.0010920536 0.00070057355,  Moving Avg Valid Loss: 0.04164619 0.040947888 0.043269172 0.04012768 0.03876967\n",
      "Training Dynamics Ensemble - Epoch #67:Train loss: 0.0005038469 0.0006139528 0.0005583782 0.0005219585 0.0005590393, Valid Loss: 0.0013060393 0.0007505062 0.0018515823 0.0010780437 0.0007316976,  Moving Avg Valid Loss: 0.03962918 0.03893802 0.041198295 0.038175195 0.03686777\n",
      "Training Dynamics Ensemble - Epoch #68:Train loss: 0.00049100193 0.0006139968 0.00056821236 0.0005487391 0.0005898404, Valid Loss: 0.0013307465 0.0007324059 0.0017093094 0.0010872481 0.00069938786,  Moving Avg Valid Loss: 0.037714258 0.03702774 0.039223846 0.036320798 0.03505935\n",
      "Training Dynamics Ensemble - Epoch #69:Train loss: 0.0005347142 0.0006054188 0.00053747866 0.0005781389 0.0005609217, Valid Loss: 0.0013654794 0.00072519825 0.0016404396 0.0010979535 0.00063450896,  Moving Avg Valid Loss: 0.03589682 0.03521261 0.037344676 0.034559652 0.033338107\n",
      "Training Dynamics Ensemble - Epoch #70:Train loss: 0.00057765195 0.0006011884 0.00048525436 0.0005781053 0.00049621, Valid Loss: 0.0013510836 0.0007262851 0.0016352185 0.0010894357 0.00060221314,  Moving Avg Valid Loss: 0.034169532 0.033488292 0.035559203 0.03288614 0.03170131\n",
      "Training Dynamics Ensemble - Epoch #71:Train loss: 0.0005726976 0.00058094686 0.0004484689 0.0005381725 0.00045529078, Valid Loss: 0.0012955773 0.000731968 0.001641866 0.0010748805 0.00062572624,  Moving Avg Valid Loss: 0.032525834 0.031850476 0.033863336 0.031295575 0.030147532\n",
      "Training Dynamics Ensemble - Epoch #72:Train loss: 0.00052405737 0.0005489737 0.00044330818 0.0004949649 0.0004616978, Valid Loss: 0.001252593 0.00074406463 0.0016289472 0.0010802081 0.00066958315,  Moving Avg Valid Loss: 0.030962171 0.030295154 0.032251615 0.029784808 0.028673634\n",
      "Training Dynamics Ensemble - Epoch #73:Train loss: 0.0004725277 0.00053782103 0.00045839927 0.00047158042 0.00048820063, Valid Loss: 0.0012597628 0.0007462278 0.0016096281 0.0011144086 0.0006813635,  Moving Avg Valid Loss: 0.029477049 0.028817706 0.030719515 0.028351288 0.02727402\n",
      "Training Dynamics Ensemble - Epoch #74:Train loss: 0.0004513893 0.0005363237 0.00047206922 0.00047025204 0.0004926332, Valid Loss: 0.0013079932 0.00073187007 0.0015984554 0.0011577795 0.0006476192,  Moving Avg Valid Loss: 0.028068595 0.027413413 0.029263461 0.026991613 0.025942698\n",
      "Training Dynamics Ensemble - Epoch #75:Train loss: 0.00046021864 0.0005279245 0.00046479196 0.00048687757 0.00046516, Valid Loss: 0.0013578546 0.0007143679 0.0015888071 0.001169043 0.00059828564,  Moving Avg Valid Loss: 0.026733058 0.02607846 0.027879728 0.025700483 0.024675477\n",
      "Training Dynamics Ensemble - Epoch #76:Train loss: 0.00047716853 0.00051886274 0.00043764693 0.0004941598 0.00043116283, Valid Loss: 0.0013750984 0.0006992936 0.0015624808 0.0011348618 0.00056764437,  Moving Avg Valid Loss: 0.02546516 0.024809502 0.026563866 0.024472203 0.023470087\n",
      "Training Dynamics Ensemble - Epoch #77:Train loss: 0.00048193082 0.0005036079 0.0004109586 0.00048233016 0.0004168306, Valid Loss: 0.0013479881 0.0006888274 0.0015085838 0.001075975 0.0005629953,  Moving Avg Valid Loss: 0.024259303 0.02360347 0.025311101 0.023302391 0.022324732\n",
      "Training Dynamics Ensemble - Epoch #78:Train loss: 0.00046741436 0.000483917 0.0003997632 0.00046250387 0.0004247674, Valid Loss: 0.001286812 0.0006860283 0.0014488806 0.0010156065 0.0005635483,  Moving Avg Valid Loss: 0.023110678 0.022457596 0.02411799 0.02218805 0.021236673\n",
      "Training Dynamics Ensemble - Epoch #79:Train loss: 0.00044189865 0.00047662255 0.0004061515 0.00044164484 0.0004349046, Valid Loss: 0.0012136301 0.00068128284 0.0014146512 0.00097431906 0.0005507947,  Moving Avg Valid Loss: 0.022015825 0.02136878 0.02298282 0.021127364 0.020202378\n",
      "Training Dynamics Ensemble - Epoch #80:Train loss: 0.00042054837 0.00047733475 0.0004178571 0.00043441527 0.00042915312, Valid Loss: 0.0011527141 0.0006677801 0.0014117287 0.0009551097 0.00053031795,  Moving Avg Valid Loss: 0.02097267 0.02033373 0.021904266 0.020118752 0.019218775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=92237)\u001b[0m 2022-08-18 10:36:20,611\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=92238)\u001b[0m 2022-08-18 10:36:20,611\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dynamics Ensemble - Epoch #81:Train loss: 0.0004141019 0.0004730763 0.00041678973 0.0004386034 0.00040851044, Valid Loss: 0.0011155477 0.0006556312 0.001426249 0.00095005863 0.0005228154,  Moving Avg Valid Loss: 0.019979812 0.019349823 0.020880366 0.019160317 0.018283976\n",
      "Training Dynamics Ensemble - Epoch #82:Train loss: 0.00042029502 0.00046653402 0.00040059345 0.0004414736 0.00038908617, Valid Loss: 0.0010964075 0.0006518551 0.001434425 0.00095292483 0.00053932174,  Moving Avg Valid Loss: 0.019035641 0.018414924 0.019908069 0.018249948 0.017396742\n",
      "Training Dynamics Ensemble - Epoch #83:Train loss: 0.000426437 0.00045715805 0.00038110162 0.00043967765 0.00038452464, Valid Loss: 0.0010850073 0.00065231795 0.0014225678 0.00095474906 0.0005673046,  Moving Avg Valid Loss: 0.018138109 0.017526794 0.018983794 0.017385188 0.01655527\n",
      "Training Dynamics Ensemble - Epoch #84:Train loss: 0.00042267307 0.00044385766 0.00037109785 0.00042914768 0.00039109113, Valid Loss: 0.0010795647 0.00065341167 0.0014028257 0.00095511024 0.00058328966,  Moving Avg Valid Loss: 0.017285181 0.016683126 0.018104747 0.016563686 0.015756672\n",
      "Training Dynamics Ensemble - Epoch #85:Train loss: 0.00040914855 0.00043630524 0.00037416807 0.00041617124 0.00039443054, Valid Loss: 0.0010868474 0.00065222575 0.0013931886 0.00095876877 0.00057372253,  Moving Avg Valid Loss: 0.016475264 0.015881581 0.017269168 0.01578344 0.014997524\n",
      "Training Dynamics Ensemble - Epoch #86:Train loss: 0.00039398443 0.00043400197 0.00038034734 0.00040927166 0.00038555195, Valid Loss: 0.0011103495 0.0006482513 0.0013932505 0.0009654095 0.0005473905,  Moving Avg Valid Loss: 0.015707018 0.015119915 0.016475372 0.015042539 0.014275017\n",
      "Training Dynamics Ensemble - Epoch #87:Train loss: 0.00038521257 0.00042991026 0.0003785713 0.00040709533 0.00037031274, Valid Loss: 0.0011404844 0.00064499036 0.0013837473 0.00096974906 0.0005242656,  Moving Avg Valid Loss: 0.014978691 0.014396169 0.01572079 0.014338899 0.0135874795\n",
      "Training Dynamics Ensemble - Epoch #88:Train loss: 0.0003848934 0.0004257915 0.00036840246 0.00040866737 0.00036130354, Valid Loss: 0.0011606921 0.0006408369 0.0013523666 0.000962009 0.0005143712,  Moving Avg Valid Loss: 0.01428779 0.013708402 0.015002369 0.013670054 0.012933824\n",
      "Training Dynamics Ensemble - Epoch #89:Train loss: 0.000388382 0.00041986513 0.0003569569 0.00040799085 0.00036216952, Valid Loss: 0.0011603506 0.00063371804 0.0013161062 0.00094080245 0.00051272515,  Moving Avg Valid Loss: 0.013631418 0.013054668 0.0143180555 0.013033591 0.012312769\n",
      "Training Dynamics Ensemble - Epoch #90:Train loss: 0.00038820063 0.00041088113 0.0003513179 0.00040196822 0.0003654734, Valid Loss: 0.0011416683 0.00062758994 0.0013031932 0.0009166664 0.0005093567,  Moving Avg Valid Loss: 0.013006931 0.012433314 0.013667312 0.012427744 0.011722598\n",
      "Training Dynamics Ensemble - Epoch #91:Train loss: 0.00038084303 0.00040547957 0.00035210076 0.00039434346 0.0003621198, Valid Loss: 0.0011131888 0.00062318344 0.001318283 0.0008993266 0.0005022635,  Moving Avg Valid Loss: 0.012412244 0.011842807 0.013049861 0.011851323 0.011161582\n",
      "Training Dynamics Ensemble - Epoch #92:Train loss: 0.00036985663 0.0004025625 0.00035345936 0.00038744643 0.0003522466, Valid Loss: 0.0010830014 0.00061930914 0.0013393506 0.0008934118 0.0004978525,  Moving Avg Valid Loss: 0.011845782 0.011281632 0.012464336 0.011303428 0.010628395\n",
      "Training Dynamics Ensemble - Epoch #93:Train loss: 0.00036212342 0.00039888005 0.00035089083 0.00038437746 0.00034327232, Valid Loss: 0.0010577245 0.0006169497 0.0013416838 0.000895984 0.0005003674,  Moving Avg Valid Loss: 0.011306379 0.010748398 0.011908203 0.010783056 0.010121993\n",
      "Training Dynamics Ensemble - Epoch #94:Train loss: 0.00036045807 0.00039603122 0.0003444584 0.00038445895 0.00034031426, Valid Loss: 0.0010405168 0.0006145817 0.0013228003 0.00089941703 0.000505417,  Moving Avg Valid Loss: 0.010793085 0.010241707 0.011378933 0.010288874 0.009641164\n",
      "Training Dynamics Ensemble - Epoch #95:Train loss: 0.00036150243 0.00039094305 0.00033747763 0.00038348784 0.00034150117, Valid Loss: 0.001029912 0.00061217666 0.0013006078 0.00089895306 0.00050446286,  Moving Avg Valid Loss: 0.010304927 0.00976023 0.010875016 0.009819377 0.009184329\n",
      "Training Dynamics Ensemble - Epoch #96:Train loss: 0.00036045242 0.00038421951 0.00033374393 0.0003804445 0.00034077535, Valid Loss: 0.0010219439 0.0006113094 0.0012873895 0.0008928935 0.0004951134,  Moving Avg Valid Loss: 0.009840777 0.009302784 0.010395635 0.009373053 0.008749868\n",
      "Training Dynamics Ensemble - Epoch #97:Train loss: 0.00035566714 0.00037975932 0.00033321758 0.00037472998 0.00033546775, Valid Loss: 0.0010153814 0.00061024795 0.0012792107 0.00088413246 0.00048310283,  Moving Avg Valid Loss: 0.009399507 0.008868156 0.009939813 0.008948607 0.008336529\n",
      "Training Dynamics Ensemble - Epoch #98:Train loss: 0.0003493019 0.0003764362 0.0003329325 0.00036929047 0.0003283437, Valid Loss: 0.0010126443 0.0006070033 0.0012681198 0.0008759536 0.00047601224,  Moving Avg Valid Loss: 0.008980164 0.008455098 0.009506228 0.008544974 0.007943504\n",
      "Training Dynamics Ensemble - Epoch #99:Train loss: 0.00034412785 0.0003739477 0.00033054757 0.0003666257 0.0003240307, Valid Loss: 0.0010151865 0.0006012728 0.00125326 0.0008682984 0.00047517839,  Moving Avg Valid Loss: 0.008581915 0.008062406 0.00909358 0.00816114 0.0075700874\n",
      "Training Dynamics Ensemble - Epoch #100:Train loss: 0.0003413051 0.00037162268 0.00032573755 0.00036561894 0.0003232715, Valid Loss: 0.0010198638 0.0005948835 0.0012408686 0.0008609027 0.00047535586,  Moving Avg Valid Loss: 0.008203813 0.00768903 0.0087009445 0.007796128 0.007215351\n",
      "Training Dynamics Ensemble - Epoch #101:Train loss: 0.00034008655 0.00036728117 0.00032096604 0.00036481765 0.0003224825, Valid Loss: 0.0010206788 0.0005912298 0.0012376808 0.0008541959 0.00047234242,  Moving Avg Valid Loss: 0.007844656 0.00733414 0.00832778 0.0074490313 0.0068782\n",
      "Training Dynamics Ensemble - Epoch #102:Train loss: 0.00033845406 0.00036237438 0.00031827175 0.0003618237 0.0003187782, Valid Loss: 0.0010147718 0.000590292 0.0012445556 0.0008498027 0.000467844,  Moving Avg Valid Loss: 0.007503161 0.006996948 0.00797362 0.00711907 0.006557682\n",
      "Training Dynamics Ensemble - Epoch #103:Train loss: 0.00033509685 0.00035854088 0.0003173404 0.00035742173 0.0003132747, Valid Loss: 0.0010038113 0.0005893294 0.0012529999 0.00084731384 0.0004663261,  Moving Avg Valid Loss: 0.0071781934 0.006676567 0.007637589 0.0068054823 0.006253114\n",
      "Training Dynamics Ensemble - Epoch #104:Train loss: 0.00033045138 0.00035543484 0.00031639167 0.00035377598 0.00030920672, Valid Loss: 0.0009904394 0.00058765366 0.0012496393 0.00084509904 0.00046840427,  Moving Avg Valid Loss: 0.0068688057 0.006372121 0.007318191 0.0065074633 0.0059638787\n",
      "Training Dynamics Ensemble - Epoch #105:Train loss: 0.00032633363 0.0003531848 0.0003137853 0.00035164127 0.00030758927, Valid Loss: 0.00097605854 0.00058649865 0.0012314739 0.00084311195 0.00047034252,  Moving Avg Valid Loss: 0.006574168 0.0060828403 0.0070138555 0.0062242453 0.005689202\n",
      "Training Dynamics Ensemble - Epoch #106:Train loss: 0.00032392298 0.0003507489 0.0003099208 0.00035069414 0.0003065136, Valid Loss: 0.0009622809 0.0005865053 0.0012102788 0.0008399577 0.00046870366,  Moving Avg Valid Loss: 0.0062935734 0.0058080237 0.006723677 0.005955031 0.005428177\n",
      "Training Dynamics Ensemble - Epoch #107:Train loss: 0.00032255577 0.0003471267 0.0003065461 0.00034897332 0.0003038879, Valid Loss: 0.00095153105 0.00058674056 0.0011969696 0.00083385955 0.00046388232,  Moving Avg Valid Loss: 0.0060264715 0.0055469596 0.0064473418 0.0056989724 0.005179962\n",
      "Training Dynamics Ensemble - Epoch #108:Train loss: 0.00032074604 0.00034339394 0.00030459644 0.00034606844 0.00029991785, Valid Loss: 0.000945212 0.0005845365 0.0011906584 0.0008249969 0.00045858714,  Moving Avg Valid Loss: 0.005772408 0.0052988385 0.0061845076 0.005455273 0.0049438933\n",
      "Training Dynamics Ensemble - Epoch #109:Train loss: 0.0003177184 0.00034006004 0.00030356477 0.0003427943 0.00029626267, Valid Loss: 0.0009425794 0.0005791976 0.0011831432 0.0008171506 0.00045442523,  Moving Avg Valid Loss: 0.0055309166 0.0050628562 0.005934439 0.005223367 0.00471942\n",
      "Training Dynamics Ensemble - Epoch #110:Train loss: 0.00031407914 0.00033723406 0.00030199965 0.00034008766 0.00029396857, Valid Loss: 0.00094290735 0.00057331164 0.001173424 0.0008132669 0.00045092948,  Moving Avg Valid Loss: 0.005301516 0.004838379 0.005696388 0.005002862 0.004505995\n",
      "Training Dynamics Ensemble - Epoch #111:Train loss: 0.00031088426 0.00033496547 0.00029929803 0.00033844743 0.00029238142, Valid Loss: 0.0009452811 0.0005693218 0.0011687146 0.00081173616 0.0004475485,  Moving Avg Valid Loss: 0.0050837044 0.004624926 0.0054700044 0.004793306 0.0043030726\n",
      "Training Dynamics Ensemble - Epoch #112:Train loss: 0.0003086372 0.00033223457 0.00029625918 0.0003369811 0.00029016362, Valid Loss: 0.00094685535 0.0005674965 0.001172637 0.00080987485 0.00044516474,  Moving Avg Valid Loss: 0.004876862 0.004422054 0.005255136 0.0045941346 0.004110177\n",
      "Training Dynamics Ensemble - Epoch #113:Train loss: 0.0003068749 0.00032903245 0.00029391792 0.0003350846 0.00028701665, Valid Loss: 0.0009435149 0.00056584895 0.0011787819 0.00080705417 0.00044481276,  Moving Avg Valid Loss: 0.0046801944 0.004229244 0.0050513186 0.0044047805 0.0039269086\n",
      "Training Dynamics Ensemble - Epoch #114:Train loss: 0.00030483617 0.00032598383 0.00029244725 0.00033266988 0.00028389992, Valid Loss: 0.00093374064 0.0005629186 0.001178152 0.000803444 0.00044583072,  Moving Avg Valid Loss: 0.004492872 0.0040459274 0.0048576603 0.0042247134 0.0037528547\n",
      "Training Dynamics Ensemble - Epoch #115:Train loss: 0.00030220006 0.00032306422 0.0002910606 0.00033017373 0.00028165727, Valid Loss: 0.00092100236 0.00055991457 0.0011685529 0.0007985424 0.0004460616,  Moving Avg Valid Loss: 0.0043142783 0.0038716267 0.004673205 0.004053405 0.0035875149\n",
      "Training Dynamics Ensemble - Epoch #116:Train loss: 0.00029933435 0.00032058073 0.00028903165 0.00032816586 0.00027992408, Valid Loss: 0.00090982404 0.00055812986 0.0011559993 0.0007921105 0.0004440844,  Moving Avg Valid Loss: 0.004144056 0.0037059516 0.004497344 0.0038903402 0.0034303432\n",
      "Training Dynamics Ensemble - Epoch #117:Train loss: 0.0002967879 0.00031823368 0.00028658062 0.00032641104 0.0002778065, Valid Loss: 0.00090202625 0.0005568701 0.0011462934 0.0007852236 0.0004404337,  Moving Avg Valid Loss: 0.003981954 0.0035484976 0.0043297913 0.0037350843 0.0032808476\n",
      "Training Dynamics Ensemble - Epoch #118:Train loss: 0.00029468912 0.0003156644 0.00028431095 0.0003247527 0.00027511554, Valid Loss: 0.00089736097 0.0005544201 0.0011403279 0.00077845424 0.00043663764,  Moving Avg Valid Loss: 0.0038277244 0.0033987937 0.004170318 0.003587253 0.003138637\n",
      "Training Dynamics Ensemble - Epoch #119:Train loss: 0.00029276503 0.00031307456 0.00028253344 0.00032279556 0.00027245705, Valid Loss: 0.0008953422 0.0005500372 0.0011351274 0.0007720751 0.00043363808,  Moving Avg Valid Loss: 0.003681105 0.0032563559 0.004018558 0.003446494 0.003003387\n",
      "Training Dynamics Ensemble - Epoch #120:Train loss: 0.00029067576 0.00031044733 0.00028096713 0.00032067328 0.00027030107, Valid Loss: 0.0008951006 0.00054507644 0.0011286503 0.00076723483 0.00043149252,  Moving Avg Valid Loss: 0.0035418049 0.0031207919 0.0038740628 0.003312531 0.002874792\n",
      "Training Dynamics Ensemble - Epoch #121:Train loss: 0.00028832318 0.0003079848 0.00027922794 0.00031863234 0.0002684554, Valid Loss: 0.00089450995 0.0005413987 0.0011237388 0.0007652485 0.00043001896,  Moving Avg Valid Loss: 0.0034094402 0.002991822 0.0037365465 0.0031851667 0.0027525534\n",
      "Training Dynamics Ensemble - Epoch #122:Train loss: 0.0002858964 0.000305762 0.00027723232 0.00031676074 0.0002664379, Valid Loss: 0.0008918907 0.00053929887 0.0011233101 0.0007650574 0.00042910432,  Moving Avg Valid Loss: 0.0032835626 0.002869196 0.0036058847 0.0030641612 0.002636381\n",
      "Training Dynamics Ensemble - Epoch #123:Train loss: 0.0002836606 0.00030353307 0.00027517206 0.0003150622 0.00026410492, Valid Loss: 0.0008878706 0.00053767505 0.0011243578 0.00076436356 0.00042840652,  Moving Avg Valid Loss: 0.003163778 0.00275262 0.0034818084 0.0029491712 0.0025259822\n",
      "Training Dynamics Ensemble - Epoch #124:Train loss: 0.00028170733 0.00030125616 0.00027333666 0.00031331633 0.00026175694, Valid Loss: 0.0008833056 0.00053567265 0.0011206112 0.00076228566 0.0004275192,  Moving Avg Valid Loss: 0.0030497543 0.0026417726 0.0033637483 0.002839827 0.002421059\n",
      "Training Dynamics Ensemble - Epoch #125:Train loss: 0.00027985513 0.00029892754 0.0002717166 0.0003114912 0.00025968932, Valid Loss: 0.0008781508 0.0005336595 0.0011117259 0.00075924484 0.00042615397,  Moving Avg Valid Loss: 0.002941174 0.0025363672 0.003251147 0.002735798 0.0023213136\n",
      "Training Dynamics Ensemble - Epoch #126:Train loss: 0.00027784024 0.00029656128 0.0002701152 0.00030958018 0.00025781099, Valid Loss: 0.0008725743 0.00053236296 0.0011028817 0.00075521925 0.0004243323,  Moving Avg Valid Loss: 0.002837744 0.0024361669 0.0031437336 0.002636769 0.0022264647\n",
      "Training Dynamics Ensemble - Epoch #127:Train loss: 0.0002756568 0.0002943626 0.0002683695 0.0003077172 0.00025583123, Valid Loss: 0.0008670474 0.00053148164 0.0010966037 0.0007495499 0.00042222458,  Moving Avg Valid Loss: 0.0027392092 0.0023409326 0.003041377 0.0025424082 0.0021362526\n",
      "Training Dynamics Ensemble - Epoch #128:Train loss: 0.00027351212 0.00029228823 0.00026653564 0.00030598528 0.00025367254, Valid Loss: 0.00086160476 0.00053033937 0.0010909435 0.0007429725 0.00041998705,  Moving Avg Valid Loss: 0.0026453289 0.002250403 0.0029438552 0.0024524364 0.0020504394\n",
      "Training Dynamics Ensemble - Epoch #129:Train loss: 0.00027153848 0.00029023815 0.0002647612 0.00030429004 0.00025152825, Valid Loss: 0.00085558137 0.00052859157 0.001084375 0.00073731143 0.00041774934,  Moving Avg Valid Loss: 0.0025558416 0.0021643124 0.0028508813 0.00236668 0.0019688047\n",
      "Training Dynamics Ensemble - Epoch #130:Train loss: 0.00026967857 0.00028815045 0.00026313594 0.00030260824 0.0002495747, Valid Loss: 0.0008491832 0.00052646175 0.0010781429 0.0007335207 0.00041570584,  Moving Avg Valid Loss: 0.0024705087 0.0020824198 0.0027622443 0.0022850218 0.0018911498\n",
      "Training Dynamics Ensemble - Epoch #131:Train loss: 0.00026781618 0.00028598035 0.0002615712 0.00030084592 0.00024771495, Valid Loss: 0.00084389216 0.00052419055 0.0010733808 0.0007309805 0.00041393604,  Moving Avg Valid Loss: 0.0023891777 0.0020045084 0.002677801 0.0022073197 0.001817289\n",
      "Training Dynamics Ensemble - Epoch #132:Train loss: 0.00026588194 0.00028386092 0.00025995125 0.00029909765 0.00024579512, Valid Loss: 0.00084056164 0.0005220084 0.0010697348 0.00072889763 0.0004125616,  Moving Avg Valid Loss: 0.0023117468 0.0019303834 0.0025973977 0.0021333988 0.0017470527\n",
      "Training Dynamics Ensemble - Epoch #133:Train loss: 0.00026388778 0.000281849 0.0002582497 0.0002974029 0.00024377526, Valid Loss: 0.0008384282 0.00052001746 0.0010653993 0.0007270564 0.00041157327,  Moving Avg Valid Loss: 0.0022380808 0.001859865 0.0025207978 0.0020630816 0.0016802786\n",
      "Training Dynamics Ensemble - Epoch #134:Train loss: 0.00026192708 0.00027988633 0.00025656656 0.0002957904 0.00024180968, Valid Loss: 0.00083658117 0.0005183494 0.0010590774 0.00072492985 0.00041072056,  Moving Avg Valid Loss: 0.0021680058 0.0017927892 0.0024477118 0.001996174 0.0016168007\n",
      "Training Dynamics Ensemble - Epoch #135:Train loss: 0.00026008015 0.000277948 0.00025497103 0.00029420073 0.00023996577, Valid Loss: 0.0008344164 0.00051684293 0.0010516947 0.00072173675 0.00040955216,  Moving Avg Valid Loss: 0.0021013264 0.0017289919 0.002377911 0.0019324522 0.0015564382\n",
      "Training Dynamics Ensemble - Epoch #136:Train loss: 0.00025829644 0.00027595847 0.00025344736 0.00029256925 0.0002381656, Valid Loss: 0.0008313312 0.0005151769 0.0010455346 0.0007173592 0.00040787947,  Moving Avg Valid Loss: 0.0020378265 0.0016683011 0.002311292 0.0018716975 0.0014990102\n",
      "Training Dynamics Ensemble - Epoch #137:Train loss: 0.0002564867 0.00027397234 0.0002519223 0.00029089683 0.00023631452, Valid Loss: 0.0008266495 0.00051335525 0.0010415871 0.0007123883 0.00040581642,  Moving Avg Valid Loss: 0.0019772677 0.0016105537 0.0022478069 0.001813732 0.0014443506\n",
      "Training Dynamics Ensemble - Epoch #138:Train loss: 0.00025461722 0.00027205245 0.00025034964 0.00028927118 0.00023443413, Valid Loss: 0.00082121056 0.0005115687 0.001038759 0.0007079652 0.00040363477,  Moving Avg Valid Loss: 0.0019194648 0.0015556044 0.0021873545 0.0017584437 0.0013923148\n",
      "Training Dynamics Ensemble - Epoch #139:Train loss: 0.0002527497 0.00027018407 0.00024875905 0.0002876958 0.00023259287, Valid Loss: 0.0008161563 0.00050981744 0.0010354709 0.0007043154 0.0004015549,  Moving Avg Valid Loss: 0.0018642993 0.001503315 0.0021297603 0.0017057372 0.0013427768\n",
      "Training Dynamics Ensemble - Epoch #140:Train loss: 0.0002509563 0.00026834127 0.00024721352 0.000286143 0.00023082067, Valid Loss: 0.00081177364 0.0005077434 0.0010319265 0.0007009862 0.00039977056,  Moving Avg Valid Loss: 0.0018116729 0.0014535364 0.0020748687 0.0016554996 0.0012956265\n",
      "Training Dynamics Ensemble - Epoch #141:Train loss: 0.00024921412 0.00026647377 0.00024572032 0.00028458037 0.00022906058, Valid Loss: 0.0008081467 0.0005053305 0.0010288907 0.0006978244 0.0003984953,  Moving Avg Valid Loss: 0.0017614965 0.0014061262 0.0020225698 0.0016076157 0.00125077\n",
      "Training Dynamics Ensemble - Epoch #142:Train loss: 0.00024747232 0.00026460184 0.00024424694 0.00028299628 0.00022727894, Valid Loss: 0.00080540875 0.0005030193 0.001026096 0.00069519173 0.00039742453,  Moving Avg Valid Loss: 0.0017136921 0.0013609708 0.001972746 0.0015619945 0.0012081027\n",
      "Training Dynamics Ensemble - Epoch #143:Train loss: 0.00024572373 0.00026278538 0.00024276374 0.0002814216 0.00022548813, Valid Loss: 0.00080294226 0.0005012372 0.0010218531 0.0006929349 0.0003961025,  Moving Avg Valid Loss: 0.0016681546 0.0013179841 0.0019252015 0.0015185415 0.0011675027\n",
      "Training Dynamics Ensemble - Epoch #144:Train loss: 0.0002439774 0.00026102297 0.00024126896 0.0002798772 0.00022373929, Valid Loss: 0.0007999243 0.00049975654 0.0010164047 0.0006903487 0.00039443982,  Moving Avg Valid Loss: 0.0016247431 0.0012770727 0.0018797617 0.0014771319 0.0011288496\n",
      "Training Dynamics Ensemble - Epoch #145:Train loss: 0.000242261 0.0002593021 0.00023979621 0.000278355 0.00022203001, Valid Loss: 0.0007965619 0.00049795833 0.0010109765 0.0006873539 0.00039268666,  Moving Avg Valid Loss: 0.0015833341 0.0012381169 0.0018363224 0.001437643 0.0010920415\n",
      "Training Dynamics Ensemble - Epoch #146:Train loss: 0.00024057885 0.00025759978 0.0002383732 0.00027683418 0.00022032404, Valid Loss: 0.0007933766 0.000495796 0.0010066383 0.00068391586 0.0003909935,  Moving Avg Valid Loss: 0.0015438362 0.0012010009 0.0017948381 0.0013999566 0.0010569891\n",
      "Training Dynamics Ensemble - Epoch #147:Train loss: 0.00023891841 0.00025588932 0.00023696598 0.00027530896 0.00021861684, Valid Loss: 0.00079007144 0.00049377664 0.0010037275 0.00068012223 0.00038927622,  Moving Avg Valid Loss: 0.0015061479 0.0011656396 0.0017552826 0.0013639649 0.0010236035\n",
      "Training Dynamics Ensemble - Epoch #148:Train loss: 0.00023725882 0.000254206 0.00023554536 0.0002737875 0.00021692153, Valid Loss: 0.00078643626 0.0004921503 0.0010011388 0.0006760183 0.0003875459,  Moving Avg Valid Loss: 0.0014701623 0.0011319651 0.0017175755 0.0013295675 0.0009918006\n",
      "Training Dynamics Ensemble - Epoch #149:Train loss: 0.00023559306 0.0002525454 0.00023412492 0.00027227987 0.00021527012, Valid Loss: 0.00078276254 0.000490491 0.0009972618 0.0006722915 0.00038601147,  Moving Avg Valid Loss: 0.0014357923 0.0010998914 0.0016815598 0.0012967037 0.0009615111\n",
      "Training Dynamics Ensemble - Epoch #150:Train loss: 0.00023393787 0.00025091317 0.00023271132 0.00027079467 0.00021364134, Valid Loss: 0.00077933475 0.0004885367 0.0009921725 0.00066908996 0.00038462074,  Moving Avg Valid Loss: 0.0014029695 0.0010693236 0.0016470904 0.001265323 0.0009326666\n",
      "Training Dynamics Ensemble - Epoch #151:Train loss: 0.00023231392 0.0002492922 0.00023131877 0.0002693085 0.00021201835, Valid Loss: 0.00077567674 0.00048662318 0.0009873143 0.000666089 0.00038315365,  Moving Avg Valid Loss: 0.0013716049 0.0010401886 0.0016141016 0.0012353613 0.0009051909\n",
      "Training Dynamics Ensemble - Epoch #152:Train loss: 0.00023071837 0.00024768 0.00022995984 0.00026782154 0.00021040557, Valid Loss: 0.000771924 0.00048498876 0.0009836478 0.0006634138 0.0003816714,  Moving Avg Valid Loss: 0.0013416208 0.0010124285 0.0015825788 0.0012067639 0.0008790149\n",
      "Training Dynamics Ensemble - Epoch #153:Train loss: 0.00022914012 0.0002460971 0.00022860749 0.00026633838 0.0002088198, Valid Loss: 0.00076864165 0.0004833488 0.0009795987 0.0006608616 0.00038033613,  Moving Avg Valid Loss: 0.0013129718 0.0009859746 0.0015524296 0.0011794688 0.00085408095\n",
      "Training Dynamics Ensemble - Epoch #154:Train loss: 0.00022756106 0.00024452532 0.00022724894 0.00026486843 0.00020726195, Valid Loss: 0.0007660199 0.00048155888 0.00097467465 0.00065819145 0.00037908062,  Moving Avg Valid Loss: 0.0012856242 0.00096075376 0.0015235419 0.0011534049 0.00083033094\n",
      "Training Dynamics Ensemble - Epoch #155:Train loss: 0.00022598158 0.00024296614 0.00022589357 0.00026341138 0.00020572224, Valid Loss: 0.00076357834 0.0004796375 0.00097097014 0.000655282 0.00037764857,  Moving Avg Valid Loss: 0.0012595218 0.00093669794 0.0014959134 0.0011284987 0.00080769684\n",
      "Training Dynamics Ensemble - Epoch #156:Train loss: 0.00022441949 0.00024141038 0.00022456686 0.000261955 0.00020418777, Valid Loss: 0.000761196 0.00047791775 0.00096879306 0.00065218686 0.00037607172,  Moving Avg Valid Loss: 0.0012346054 0.0009137589 0.0014695573 0.001104683 0.0007861156\n",
      "Training Dynamics Ensemble - Epoch #157:Train loss: 0.00022287556 0.00023987149 0.0002232605 0.00026051365 0.00020267056, Valid Loss: 0.0007588922 0.0004764411 0.00096596876 0.0006488963 0.0003744176,  Moving Avg Valid Loss: 0.0012108198 0.000891893 0.0014443778 0.0010818937 0.0007655307\n",
      "Training Dynamics Ensemble - Epoch #158:Train loss: 0.00022134291 0.00023834963 0.00022194946 0.0002590722 0.0002011671, Valid Loss: 0.0007564083 0.0004750426 0.00096250785 0.00064549583 0.0003726838,  Moving Avg Valid Loss: 0.0011880993 0.00087105046 0.0014202843 0.0010600737 0.00074588833\n",
      "Training Dynamics Ensemble - Epoch #159:Train loss: 0.00021981227 0.00023683571 0.00022063023 0.00025763188 0.00019968051, Valid Loss: 0.0007534215 0.0004736703 0.00095922715 0.0006422512 0.0003709653,  Moving Avg Valid Loss: 0.0011663653 0.00085118145 0.0013972314 0.0010391827 0.0007271422\n",
      "Training Dynamics Ensemble - Epoch #160:Train loss: 0.00021830265 0.000235342 0.00021930959 0.0002562104 0.0001982064, Valid Loss: 0.00074988574 0.00047228928 0.0009558915 0.0006394104 0.0003693953,  Moving Avg Valid Loss: 0.0011455413 0.00083223684 0.0013751644 0.001019194 0.0007092548\n",
      "Training Dynamics Ensemble - Epoch #161:Train loss: 0.0002168022 0.00023386364 0.0002179989 0.00025480325 0.00019674114, Valid Loss: 0.0007462131 0.00047090338 0.0009528485 0.0006368801 0.00036806994,  Moving Avg Valid Loss: 0.0011255749 0.00081417017 0.0013540485 0.0010000783 0.0006921956\n",
      "Training Dynamics Ensemble - Epoch #162:Train loss: 0.00021531021 0.0002323945 0.00021670178 0.00025340597 0.0001952922, Valid Loss: 0.0007428165 0.0004695526 0.0009493091 0.00063434156 0.00036684005,  Moving Avg Valid Loss: 0.001106437 0.0007969393 0.0013338114 0.0009817914 0.0006759278\n",
      "Training Dynamics Ensemble - Epoch #163:Train loss: 0.00021383155 0.00023094141 0.00021541966 0.00025202925 0.00019385523, Valid Loss: 0.00073994807 0.00046810796 0.00094537553 0.0006314843 0.00036552807,  Moving Avg Valid Loss: 0.0010881125 0.00078049774 0.0013143896 0.000964276 0.00066040776\n",
      "Training Dynamics Ensemble - Epoch #164:Train loss: 0.00021235428 0.00022951154 0.00021413201 0.00025064748 0.00019242441, Valid Loss: 0.0007373947 0.0004665558 0.00094205816 0.00062859553 0.00036410074,  Moving Avg Valid Loss: 0.0010705766 0.0007648006 0.0012957731 0.00094749196 0.0006455924\n",
      "Training Dynamics Ensemble - Epoch #165:Train loss: 0.00021087633 0.00022810088 0.00021284688 0.00024927506 0.00019100173, Valid Loss: 0.00073487597 0.00046506137 0.00093923387 0.000625657 0.00036259362,  Moving Avg Valid Loss: 0.0010537916 0.0007498136 0.0012779462 0.00093140017 0.00063144247\n",
      "Training Dynamics Ensemble - Epoch #166:Train loss: 0.00020940804 0.00022670052 0.00021159297 0.00024790733 0.00018959289, Valid Loss: 0.00073230965 0.00046354963 0.00093614584 0.0006227422 0.0003610697,  Moving Avg Valid Loss: 0.0010377176 0.0007355004 0.0012608562 0.0009159673 0.0006179238\n",
      "Training Dynamics Ensemble - Epoch #167:Train loss: 0.00020796599 0.00022530988 0.00021036096 0.00024655368 0.00018819592, Valid Loss: 0.0007296062 0.000462042 0.00093174266 0.00062018033 0.0003596266,  Moving Avg Valid Loss: 0.001022312 0.0007218275 0.0012444004 0.00090117793 0.0006050089\n",
      "Training Dynamics Ensemble - Epoch #168:Train loss: 0.00020653153 0.00022393561 0.00020914718 0.00024521622 0.0001868231, Valid Loss: 0.00072685396 0.0004607043 0.00092845235 0.00061769976 0.0003583028,  Moving Avg Valid Loss: 0.001007539 0.00070877135 0.001228603 0.000887004 0.0005926736\n",
      "Training Dynamics Ensemble - Epoch #169:Train loss: 0.00020510933 0.00022257787 0.00020793042 0.00024389611 0.00018546495, Valid Loss: 0.0007239716 0.00045950525 0.0009264593 0.00061515265 0.00035706052,  Moving Avg Valid Loss: 0.0009933605 0.00069630804 0.0012134957 0.0008734114 0.00058089296\n",
      "Training Dynamics Ensemble - Epoch #170:Train loss: 0.0002036861 0.00022123952 0.00020671026 0.0002425796 0.00018411249, Valid Loss: 0.0007209076 0.00045820326 0.0009235094 0.0006127155 0.0003559407,  Moving Avg Valid Loss: 0.0009797378 0.0006844028 0.0011989963 0.00086037663 0.0005696454\n",
      "Training Dynamics Ensemble - Epoch #171:Train loss: 0.00020227356 0.00021991011 0.00020549836 0.00024128596 0.00018276881, Valid Loss: 0.0007177841 0.00045667117 0.00091995485 0.00061025814 0.00035476874,  Moving Avg Valid Loss: 0.00096664013 0.00067301624 0.0011850443 0.0008478707 0.0005589015\n",
      "Training Dynamics Ensemble - Epoch #172:Train loss: 0.00020086991 0.00021858857 0.000204295 0.00024000715 0.00018143587, Valid Loss: 0.00071464985 0.00045509578 0.0009172714 0.00060737063 0.0003532676,  Moving Avg Valid Loss: 0.0009540406 0.0006621202 0.0011716556 0.00083584565 0.00054861984\n",
      "Training Dynamics Ensemble - Epoch #173:Train loss: 0.00019947567 0.00021727913 0.00020309784 0.00023873139 0.00018011071, Valid Loss: 0.00071169145 0.00045352982 0.0009147947 0.0006046768 0.00035165198,  Moving Avg Valid Loss: 0.0009419231 0.00065169064 0.0011588125 0.0008242872 0.00053877145\n",
      "Training Dynamics Ensemble - Epoch #174:Train loss: 0.00019808834 0.00021598373 0.00020191056 0.00023746003 0.00017880039, Valid Loss: 0.00070925924 0.00045183106 0.0009122088 0.00060208066 0.00035015683,  Moving Avg Valid Loss: 0.0009302899 0.00064169767 0.0011464824 0.00081317686 0.0005293407\n",
      "Training Dynamics Ensemble - Epoch #175:Train loss: 0.00019671091 0.00021470513 0.00020073258 0.00023620165 0.00017749931, Valid Loss: 0.0007071168 0.00045013105 0.0009093999 0.0005991302 0.0003488036,  Moving Avg Valid Loss: 0.0009191313 0.00063211937 0.0011346282 0.0008024745 0.00052031386\n",
      "Training Dynamics Ensemble - Epoch #176:Train loss: 0.00019534507 0.00021343416 0.00019956571 0.00023496672 0.00017620662, Valid Loss: 0.00070475717 0.00044863432 0.0009066843 0.00059645827 0.00034743152,  Moving Avg Valid Loss: 0.00090841256 0.0006229451 0.001123231 0.00079217367 0.0005116697\n",
      "Training Dynamics Ensemble - Epoch #177:Train loss: 0.00019398061 0.0002121753 0.00019840438 0.00023374606 0.00017492077, Valid Loss: 0.0007020967 0.0004473471 0.00090382976 0.0005938292 0.00034595202,  Moving Avg Valid Loss: 0.0008980967 0.00061416515 0.001112261 0.0007822564 0.00050338387\n",
      "Training Dynamics Ensemble - Epoch #178:Train loss: 0.00019261545 0.00021092623 0.00019724756 0.00023252712 0.00017364066, Valid Loss: 0.00069918344 0.00044605075 0.0009005327 0.00059131597 0.000344595,  Moving Avg Valid Loss: 0.00088815106 0.00060575944 0.0011016745 0.00077270943 0.0004954444\n",
      "Training Dynamics Ensemble - Epoch #179:Train loss: 0.00019124438 0.0002096919 0.00019609941 0.00023131297 0.00017237074, Valid Loss: 0.0006961358 0.00044475571 0.0008981605 0.0005889473 0.0003432785,  Moving Avg Valid Loss: 0.0008785503 0.0005977092 0.0010914988 0.0007635213 0.0004878361\n",
      "Training Dynamics Ensemble - Epoch #180:Train loss: 0.00018991053 0.00020846559 0.00019496462 0.00023009945 0.00017110695, Valid Loss: 0.0006934437 0.00044348396 0.0008962263 0.00058664876 0.00034185793,  Moving Avg Valid Loss: 0.000869295 0.000589998 0.0010817351 0.00075467763 0.0004805372\n",
      "Training Dynamics Ensemble - Epoch #181:Train loss: 0.00018863233 0.00020725277 0.00019383938 0.00022890249 0.00016985014, Valid Loss: 0.0006911549 0.00044207746 0.0008937713 0.0005841491 0.00034037553,  Moving Avg Valid Loss: 0.000860388 0.00058260193 0.0010723369 0.0007461512 0.0004735291\n",
      "Training Dynamics Ensemble - Epoch #182:Train loss: 0.00018735777 0.00020606219 0.00019272573 0.00022772557 0.0001686041, Valid Loss: 0.0006887696 0.00044051712 0.0008911252 0.0005816085 0.00033897624,  Moving Avg Valid Loss: 0.00085180707 0.0005754977 0.0010632763 0.00073792407 0.00046680146\n",
      "Training Dynamics Ensemble - Epoch #183:Train loss: 0.00018609215 0.00020488733 0.00019160958 0.0002265383 0.00016736687, Valid Loss: 0.0006860514 0.00043892744 0.0008887024 0.0005789167 0.000337539,  Moving Avg Valid Loss: 0.0008435193 0.0005686692 0.0010545476 0.0007299737 0.00046033834\n",
      "Training Dynamics Ensemble - Epoch #184:Train loss: 0.00018482975 0.00020371753 0.0001905044 0.00022535512 0.00016613794, Valid Loss: 0.00068357785 0.00043752755 0.0008860718 0.0005762492 0.00033592802,  Moving Avg Valid Loss: 0.0008355222 0.0005621121 0.0010461238 0.00072228746 0.00045411784\n",
      "Training Dynamics Ensemble - Epoch #185:Train loss: 0.00018357327 0.00020255658 0.00018940451 0.00022419174 0.00016492023, Valid Loss: 0.00068147044 0.00043621394 0.00088340905 0.00057388155 0.00033436538,  Moving Avg Valid Loss: 0.00082781963 0.00055581715 0.001037988 0.00071486714 0.0004481302\n",
      "Training Dynamics Ensemble - Epoch #186:Train loss: 0.00018232594 0.00020140654 0.00018831629 0.00022302991 0.00016370894, Valid Loss: 0.00067926635 0.00043493812 0.0008811155 0.000571578 0.00033286345,  Moving Avg Valid Loss: 0.0008203919 0.0005497732 0.0010301443 0.0007077027 0.00044236684\n",
      "Training Dynamics Ensemble - Epoch #187:Train loss: 0.00018108731 0.0002002636 0.00018723914 0.00022186148 0.00016250505, Valid Loss: 0.00067701394 0.00043371718 0.0008787704 0.0005693325 0.00033133873,  Moving Avg Valid Loss: 0.0008132231 0.0005439704 0.0010225755 0.0007007842 0.00043681543\n",
      "Training Dynamics Ensemble - Epoch #188:Train loss: 0.00017984986 0.00019912676 0.00018616965 0.00022070778 0.00016130383, Valid Loss: 0.0006745136 0.00043234357 0.0008761715 0.0005669153 0.00032983298,  Moving Avg Valid Loss: 0.00080628763 0.000538389 0.0010152553 0.0006940908 0.00043146632\n",
      "Training Dynamics Ensemble - Epoch #189:Train loss: 0.00017861866 0.00019799176 0.00018510621 0.00021956369 0.00016011126, Valid Loss: 0.0006713726 0.00043070197 0.00087379984 0.00056442874 0.00032839083,  Moving Avg Valid Loss: 0.0007995419 0.00053300464 0.0010081825 0.0006876077 0.00042631253\n",
      "Training Dynamics Ensemble - Epoch #190:Train loss: 0.00017739242 0.00019686046 0.00018404073 0.00021842466 0.00015893331, Valid Loss: 0.0006680488 0.00042903228 0.00087130716 0.00056184886 0.00032694187,  Moving Avg Valid Loss: 0.0007929673 0.000527806 0.0010013388 0.00068131974 0.00042134398\n",
      "Training Dynamics Ensemble - Epoch #191:Train loss: 0.00017617455 0.00019573598 0.00018298873 0.00021728661 0.00015776427, Valid Loss: 0.0006651657 0.00042759255 0.0008688623 0.0005590956 0.00032549028,  Moving Avg Valid Loss: 0.0007865772 0.0005227953 0.000994715 0.0006752085 0.00041655128\n",
      "Training Dynamics Ensemble - Epoch #192:Train loss: 0.00017495481 0.00019461798 0.00018195028 0.00021615591 0.00015659405, Valid Loss: 0.0006623439 0.00042620825 0.00086651975 0.00055653154 0.00032402645,  Moving Avg Valid Loss: 0.0007803655 0.00051796593 0.0009883052 0.00066927465 0.00041192502\n",
      "Training Dynamics Ensemble - Epoch #193:Train loss: 0.00017374227 0.00019351287 0.00018090515 0.00021501427 0.00015543052, Valid Loss: 0.00065948535 0.00042479028 0.0008646978 0.0005542979 0.00032265863,  Moving Avg Valid Loss: 0.0007743215 0.00051330717 0.0009821248 0.0006635258 0.0004074617\n",
      "Training Dynamics Ensemble - Epoch #194:Train loss: 0.0001725418 0.00019240892 0.00017988 0.00021388798 0.00015428248, Valid Loss: 0.0006569778 0.0004233757 0.0008617187 0.00055198604 0.0003213031,  Moving Avg Valid Loss: 0.00076845434 0.00050881057 0.0009761045 0.0006579488 0.00040315377\n",
      "Training Dynamics Ensemble - Epoch #195:Train loss: 0.00017135135 0.00019131092 0.00017886216 0.00021277231 0.00015313689, Valid Loss: 0.00065421115 0.0004218512 0.00085895526 0.0005497755 0.000319894,  Moving Avg Valid Loss: 0.0007627422 0.0005044626 0.000970247 0.0006525401 0.0003989908\n",
      "Training Dynamics Ensemble - Epoch #196:Train loss: 0.00017016826 0.00019022853 0.00017785782 0.00021165931 0.0001519985, Valid Loss: 0.0006512749 0.00042021234 0.0008565301 0.0005474745 0.00031839364,  Moving Avg Valid Loss: 0.0007571688 0.0005002501 0.0009645612 0.0006472868 0.00039496092\n",
      "Training Dynamics Ensemble - Epoch #197:Train loss: 0.00016900015 0.00018915378 0.00017684845 0.00021054709 0.00015086925, Valid Loss: 0.00064897287 0.0004186836 0.00085391867 0.0005448415 0.00031694467,  Moving Avg Valid Loss: 0.000751759 0.00049617176 0.0009590291 0.00064216455 0.0003910601\n",
      "Training Dynamics Ensemble - Epoch #198:Train loss: 0.00016783792 0.0001880806 0.00017585138 0.00020943285 0.00014974292, Valid Loss: 0.0006467577 0.000417348 0.0008518479 0.00054240343 0.00031549338,  Moving Avg Valid Loss: 0.00074650894 0.0004922306 0.00095367 0.0006371765 0.00038728176\n",
      "Training Dynamics Ensemble - Epoch #199:Train loss: 0.00016667898 0.00018701343 0.00017485849 0.00020832826 0.00014862853, Valid Loss: 0.0006444319 0.00042282953 0.0008494069 0.0005401418 0.00031392602,  Moving Avg Valid Loss: 0.0007414051 0.00048876053 0.0009484569 0.0006323247 0.00038361398\n",
      "Training Dynamics Ensemble - Epoch #200:Train loss: 0.00016552313 0.00018590818 0.000173867 0.00020723304 0.00014751941, Valid Loss: 0.0006423011 0.0004142137 0.00084664015 0.0005376306 0.00031226865,  Moving Avg Valid Loss: 0.0007364499 0.0004850332 0.00094336603 0.00062759 0.0003800467\n",
      "Training Dynamics Ensemble - Epoch #201:Train loss: 0.00016437816 0.00018478505 0.00017288848 0.00020614712 0.0001464182, Valid Loss: 0.00064031925 0.0004131645 0.00084409595 0.0005351746 0.0003106786,  Moving Avg Valid Loss: 0.00073164335 0.00048143975 0.00093840255 0.00062296924 0.0003765783\n",
      "Training Dynamics Ensemble - Epoch #202:Train loss: 0.0001632368 0.0001836375 0.00017191659 0.0002050633 0.00014532424, Valid Loss: 0.00063843024 0.00041063683 0.0008410967 0.0005325987 0.0003090833,  Moving Avg Valid Loss: 0.00072698266 0.00047789962 0.00093353726 0.0006184507 0.00037320354\n",
      "Training Dynamics Ensemble - Epoch #203:Train loss: 0.00016211062 0.00018263057 0.0001709456 0.00020400333 0.00014423866, Valid Loss: 0.00063692825 0.0004094436 0.00083813845 0.0005302887 0.00030747,  Moving Avg Valid Loss: 0.00072247995 0.00047447684 0.00092876726 0.0006140426 0.00036991684\n",
      "Training Dynamics Ensemble - Epoch #204:Train loss: 0.0001609958 0.00018158008 0.00016998706 0.00020292994 0.00014316576, Valid Loss: 0.00063577975 0.0004108174 0.00083657476 0.0005284115 0.0003059896,  Moving Avg Valid Loss: 0.00071814493 0.00047129387 0.0009241576 0.00060976105 0.0003667205\n",
      "Training Dynamics Ensemble - Epoch #205:Train loss: 0.00015989479 0.00018087735 0.00016901708 0.00020185967 0.00014210136, Valid Loss: 0.00063423545 0.0004037329 0.0008344102 0.00052634435 0.0003046295,  Moving Avg Valid Loss: 0.00071394944 0.00046791582 0.0009196702 0.0006055902 0.00036361592\n",
      "Training Dynamics Ensemble - Epoch #206:Train loss: 0.00015879942 0.00018022806 0.00016804702 0.00020079908 0.00014104306, Valid Loss: 0.0006322788 0.00040562588 0.00083146384 0.0005237875 0.000303327,  Moving Avg Valid Loss: 0.0007098659 0.00046480133 0.0009152599 0.00060150004 0.00036060147\n",
      "Training Dynamics Ensemble - Epoch #207:Train loss: 0.00015771005 0.00017855133 0.00016708768 0.00019974115 0.00013998857, Valid Loss: 0.0006305284 0.00040946112 0.00082939665 0.0005214382 0.00030198248,  Moving Avg Valid Loss: 0.00070589903 0.0004620343 0.0009109667 0.0005974969 0.0003576705\n",
      "Training Dynamics Ensemble - Epoch #208:Train loss: 0.00015662934 0.0001782086 0.00016608287 0.0001986904 0.00013894071, Valid Loss: 0.00062881294 0.00040451478 0.00082810124 0.0005189202 0.00030051713,  Moving Avg Valid Loss: 0.0007020447 0.00045915833 0.00090682344 0.0005935681 0.00035481283\n",
      "Training Dynamics Ensemble - Epoch #209:Train loss: 0.00015556032 0.00017647159 0.00016506904 0.00019765172 0.0001379074, Valid Loss: 0.00062676694 0.00040758343 0.00082571513 0.00051642425 0.00029909558,  Moving Avg Valid Loss: 0.0006982808 0.00045657958 0.000902768 0.0005897109 0.00035202695\n",
      "Training Dynamics Ensemble - Epoch #210:Train loss: 0.00015449182 0.00017523867 0.00016404864 0.00019661857 0.00013688438, Valid Loss: 0.00062490394 0.00041279203 0.00082311116 0.00051416864 0.0002977504,  Moving Avg Valid Loss: 0.0006946119 0.0004543902 0.00089878513 0.0005859338 0.0003493131\n",
      "Training Dynamics Ensemble - Epoch #211:Train loss: 0.0001534303 0.00017460897 0.0001630245 0.00019559413 0.00013587045, Valid Loss: 0.0006230944 0.00040322533 0.0008213899 0.0005117615 0.0002963209,  Moving Avg Valid Loss: 0.00069103605 0.00045183193 0.00089491537 0.0005822252 0.0003466635\n",
      "Training Dynamics Ensemble - Epoch #212:Train loss: 0.00015238227 0.0001729216 0.00016199212 0.00019458921 0.00013486638, Valid Loss: 0.0006209321 0.00039685983 0.00081904966 0.00050963234 0.00029494747,  Moving Avg Valid Loss: 0.00068753085 0.0004490833 0.00089112204 0.00057859556 0.0003440777\n",
      "Training Dynamics Ensemble - Epoch #213:Train loss: 0.00015133955 0.00017224342 0.00016095808 0.00019358307 0.00013386813, Valid Loss: 0.00061895273 0.0004020257 0.0008166381 0.00050743786 0.00029368157,  Moving Avg Valid Loss: 0.0006841019 0.00044673044 0.00088739785 0.0005750377 0.0003415579\n",
      "Training Dynamics Ensemble - Epoch #214:Train loss: 0.00015030548 0.00017091114 0.00015999294 0.00019258408 0.0001328768, Valid Loss: 0.000617079 0.0004056555 0.0008138665 0.00050511595 0.0002923365,  Moving Avg Valid Loss: 0.00068075076 0.0004446767 0.0008837213 0.00057154155 0.00033909682\n",
      "Training Dynamics Ensemble - Epoch #215:Train loss: 0.00014927697 0.00016990051 0.00015906674 0.00019159634 0.00013189681, Valid Loss: 0.00061488943 0.00039978613 0.0008110436 0.00050319266 0.00029087416,  Moving Avg Valid Loss: 0.00067745766 0.00044243215 0.0008800874 0.00056812406 0.00033668568\n",
      "Training Dynamics Ensemble - Epoch #216:Train loss: 0.00014826146 0.00016929735 0.00015814372 0.0001906249 0.00013092544, Valid Loss: 0.00061308156 0.00039793696 0.00080827216 0.0005013275 0.00028945046,  Moving Avg Valid Loss: 0.00067423884 0.00044020737 0.00087649666 0.0005647842 0.0003343239\n",
      "Training Dynamics Ensemble - Epoch #217:Train loss: 0.0001472386 0.00016762638 0.00015722086 0.00018965702 0.00012995703, Valid Loss: 0.00061157637 0.0003936274 0.0008060328 0.0004987305 0.00028809631,  Moving Avg Valid Loss: 0.0006711057 0.00043787836 0.00087297347 0.0005614815 0.00033201254\n",
      "Training Dynamics Ensemble - Epoch #218:Train loss: 0.00014622789 0.00016669622 0.00015630003 0.00018868972 0.00012900106, Valid Loss: 0.00060952443 0.00038641412 0.00080384227 0.00049659365 0.00028670253,  Moving Avg Valid Loss: 0.0006680266 0.00043530515 0.00086951687 0.00055823714 0.00032974704\n",
      "Training Dynamics Ensemble - Epoch #219:Train loss: 0.00014522456 0.00016564045 0.00015538806 0.00018773066 0.00012805652, Valid Loss: 0.0006073002 0.00038896443 0.0008016289 0.0004945287 0.00028535933,  Moving Avg Valid Loss: 0.0006649903 0.0004329881 0.0008661225 0.0005550517 0.00032752767\n",
      "Training Dynamics Ensemble - Epoch #220:Train loss: 0.00014422642 0.00016415176 0.00015447206 0.00018676922 0.00012711572, Valid Loss: 0.000605638 0.00039363262 0.0007993484 0.00049218175 0.00028416535,  Moving Avg Valid Loss: 0.0006620227 0.00043102034 0.00086278375 0.0005519082 0.00032535955\n",
      "Training Dynamics Ensemble - Epoch #221:Train loss: 0.00014323671 0.0001632369 0.00015355332 0.00018581885 0.00012618069, Valid Loss: 0.00060394587 0.00038863285 0.00079720095 0.0004902788 0.0002829715,  Moving Avg Valid Loss: 0.0006591189 0.00042890097 0.00085950457 0.0005488267 0.00032324012\n",
      "Training Dynamics Ensemble - Epoch #222:Train loss: 0.00014224705 0.00016206199 0.0001526331 0.00018487002 0.00012525001, Valid Loss: 0.00060222496 0.00038313703 0.00079503265 0.0004883632 0.0002817036,  Moving Avg Valid Loss: 0.00065627415 0.00042661277 0.00085628097 0.0005458035 0.0003211633\n",
      "Training Dynamics Ensemble - Epoch #223:Train loss: 0.00014126099 0.00016090089 0.00015171616 0.00018392397 0.00012432529, Valid Loss: 0.0006006596 0.00038379102 0.0007932366 0.00048657838 0.00028042853,  Moving Avg Valid Loss: 0.00065349345 0.00042447168 0.00085312873 0.00054284226 0.0003191266\n",
      "Training Dynamics Ensemble - Epoch #224:Train loss: 0.00014028404 0.00016002898 0.00015081065 0.00018298287 0.00012341287, Valid Loss: 0.0005986566 0.0003817453 0.00079152477 0.0004847036 0.00027916595,  Moving Avg Valid Loss: 0.0006507516 0.00042233535 0.00085004856 0.0005399353 0.00031712855\n",
      "Training Dynamics Ensemble - Epoch #225:Train loss: 0.00013931902 0.00015874246 0.00014990907 0.00018204865 0.00012250071, Valid Loss: 0.0005967151 0.0003797282 0.0007901441 0.00048243566 0.0002778837,  Moving Avg Valid Loss: 0.00064804975 0.00042020497 0.00084705336 0.0005370603 0.0003151663\n",
      "Training Dynamics Ensemble - Epoch #226:Train loss: 0.00013835191 0.00015775472 0.00014899949 0.00018111717 0.00012159051, Valid Loss: 0.0005953937 0.00038090322 0.0007880442 0.00048044516 0.00027650013,  Moving Avg Valid Loss: 0.0006454169 0.00041823988 0.00084410293 0.00053422956 0.000313233\n",
      "Training Dynamics Ensemble - Epoch #227:Train loss: 0.0001373871 0.00015675927 0.00014809222 0.00018018702 0.00012068887, Valid Loss: 0.00059371325 0.00037664143 0.00078530627 0.00047854564 0.00027523696,  Moving Avg Valid Loss: 0.0006428317 0.00041615995 0.0008411631 0.0005314454 0.00031133322\n",
      "Training Dynamics Ensemble - Epoch #228:Train loss: 0.00013643166 0.00015555251 0.0001471955 0.00017925997 0.00011979556, Valid Loss: 0.0005919972 0.00037255115 0.0007834213 0.0004766061 0.00027404618,  Moving Avg Valid Loss: 0.00064029003 0.0004139795 0.000838276 0.00052870344 0.00030946886\n",
      "Training Dynamics Ensemble - Epoch #229:Train loss: 0.00013548267 0.00015468041 0.000146294 0.00017833487 0.00011890466, Valid Loss: 0.0005902118 0.0003725613 0.0007816146 0.00047484995 0.00027277693,  Moving Avg Valid Loss: 0.0006377861 0.00041190855 0.0008354429 0.00052601076 0.00030763424\n",
      "Training Dynamics Ensemble - Epoch #230:Train loss: 0.00013453877 0.00015359925 0.00014539668 0.00017741404 0.000118007374, Valid Loss: 0.0005880104 0.0003724795 0.00077900087 0.0004729046 0.00027145306,  Moving Avg Valid Loss: 0.0006352973 0.00040993709 0.00083262083 0.00052335544 0.00030582518\n",
      "Training Dynamics Ensemble - Epoch #231:Train loss: 0.00013359806 0.00015251292 0.0001444978 0.00017651166 0.00011711396, Valid Loss: 0.00058629585 0.00037034004 0.0007769562 0.00047083714 0.0002702672,  Moving Avg Valid Loss: 0.00063284725 0.0004079572 0.0008298376 0.0005207295 0.00030404725\n",
      "Training Dynamics Ensemble - Epoch #232:Train loss: 0.00013265962 0.00015162645 0.00014360277 0.00017561649 0.00011622546, Valid Loss: 0.00058514334 0.0003694974 0.0007756217 0.00046897898 0.0002690154,  Moving Avg Valid Loss: 0.000630462 0.00040603423 0.0008271268 0.000518142 0.00030229567\n",
      "Training Dynamics Ensemble - Epoch #233:Train loss: 0.00013172512 0.00015052273 0.00014270915 0.00017472569 0.00011534534, Valid Loss: 0.00058387767 0.00036634767 0.00077306986 0.00046707893 0.00026765236,  Moving Avg Valid Loss: 0.0006281328 0.00040404988 0.0008244239 0.00051558885 0.0003005635\n",
      "Training Dynamics Ensemble - Epoch #234:Train loss: 0.00013079241 0.00014955224 0.00014182365 0.00017384077 0.000114466886, Valid Loss: 0.00058215164 0.00036346458 0.0007706625 0.00046535573 0.00026624615,  Moving Avg Valid Loss: 0.0006258337 0.00040202058 0.0008217358 0.0005130772 0.00029884762\n",
      "Training Dynamics Ensemble - Epoch #235:Train loss: 0.00012986295 0.00014860203 0.00014094396 0.0001729548 0.00011359326, Valid Loss: 0.0005799814 0.0003644586 0.00076965377 0.00046379297 0.00026495112,  Moving Avg Valid Loss: 0.00062354107 0.00040014248 0.00081913173 0.00051061297 0.00029715282\n",
      "Training Dynamics Ensemble - Epoch #236:Train loss: 0.00012893368 0.00014754126 0.00014007301 0.00017207411 0.00011272665, Valid Loss: 0.00057788024 0.0003630162 0.0007679356 0.0004618728 0.00026362741,  Moving Avg Valid Loss: 0.000621258 0.00039828615 0.00081657193 0.00050817593 0.00029547652\n",
      "Training Dynamics Ensemble - Epoch #237:Train loss: 0.00012800972 0.00014660202 0.00013920692 0.00017120384 0.00011186615, Valid Loss: 0.0005762683 0.0003610489 0.0007656508 0.00046013424 0.00026234367,  Moving Avg Valid Loss: 0.0006190085 0.00039642426 0.0008140259 0.0005057738 0.00029381987\n",
      "Training Dynamics Ensemble - Epoch #238:Train loss: 0.00012707638 0.00014561528 0.00013834477 0.00017033504 0.00011100957, Valid Loss: 0.00057470874 0.00036002553 0.00076393376 0.00045837002 0.00026118322,  Moving Avg Valid Loss: 0.0006167935 0.0003946043 0.00081152125 0.0005034036 0.00029218802\n",
      "Training Dynamics Ensemble - Epoch #239:Train loss: 0.00012614744 0.00014464038 0.00013748331 0.00016947454 0.00011015789, Valid Loss: 0.0005724608 0.00035779038 0.00076255604 0.00045658345 0.00026003216,  Moving Avg Valid Loss: 0.00061457686 0.0003927636 0.000809073 0.0005010626 0.00029058024\n",
      "Training Dynamics Ensemble - Epoch #240:Train loss: 0.0001252136 0.00014368747 0.00013662002 0.0001686132 0.00010931015, Valid Loss: 0.0005701302 0.0003556307 0.00076033856 0.00045518237 0.00025886908,  Moving Avg Valid Loss: 0.0006123545 0.00039090696 0.00080663624 0.0004987686 0.0002889947\n",
      "Training Dynamics Ensemble - Epoch #241:Train loss: 0.00012428181 0.00014273841 0.0001357595 0.00016775794 0.00010846813, Valid Loss: 0.0005681715 0.00035662766 0.00075869483 0.00045346073 0.000257636,  Moving Avg Valid Loss: 0.00061014533 0.000389193 0.0008042392 0.0004965032 0.00028742675\n",
      "Training Dynamics Ensemble - Epoch #242:Train loss: 0.00012334662 0.00014179685 0.00013491373 0.00016691918 0.00010763182, Valid Loss: 0.0005662439 0.00035411835 0.0007568374 0.00045162305 0.00025640527,  Moving Avg Valid Loss: 0.00060795026 0.00038743927 0.0008018691 0.0004942592 0.00028587566\n",
      "Training Dynamics Ensemble - Epoch #243:Train loss: 0.00012241548 0.00014081727 0.00013408942 0.00016607696 0.00010680035, Valid Loss: 0.000564661 0.00035239317 0.0007546366 0.00044979705 0.00025518934,  Moving Avg Valid Loss: 0.0006057858 0.00038568696 0.0007995075 0.00049203605 0.00028434134\n",
      "Training Dynamics Ensemble - Epoch #244:Train loss: 0.00012149169 0.00013986866 0.00013325352 0.0001652307 0.00010597405, Valid Loss: 0.0005632328 0.00035196988 0.00075308763 0.00044755754 0.00025401634,  Moving Avg Valid Loss: 0.00060365815 0.00038400112 0.00079718645 0.0004898121 0.0002828251\n",
      "Training Dynamics Ensemble - Epoch #245:Train loss: 0.000120576115 0.00013890385 0.00013242767 0.00016438842 0.000105154366, Valid Loss: 0.0005613123 0.0003489968 0.0007513772 0.0004458812 0.00025285836,  Moving Avg Valid Loss: 0.00060154084 0.0003822509 0.000794896 0.00048761556 0.00028132673\n",
      "Training Dynamics Ensemble - Epoch #246:Train loss: 0.00011968556 0.00013793648 0.00013160337 0.00016355823 0.000104338884, Valid Loss: 0.0005594406 0.00034766446 0.00074962963 0.00044447152 0.000251745,  Moving Avg Valid Loss: 0.0005994358 0.00038052158 0.00079263264 0.00048545835 0.00027984765\n",
      "Training Dynamics Ensemble - Epoch #247:Train loss: 0.00011879433 0.000137 0.00013078774 0.000162733 0.000103532206, Valid Loss: 0.0005578773 0.00034623718 0.0007480595 0.00044279452 0.00025050767,  Moving Avg Valid Loss: 0.00059735787 0.00037880737 0.000790404 0.00048332516 0.00027838064\n",
      "Training Dynamics Ensemble - Epoch #248:Train loss: 0.000117910546 0.0001360399 0.00012996481 0.00016190283 0.00010273157, Valid Loss: 0.0005557916 0.00034556576 0.0007465082 0.00044126378 0.00024926843,  Moving Avg Valid Loss: 0.0005952795 0.00037714528 0.0007882092 0.0004812221 0.00027692504\n",
      "Training Dynamics Ensemble - Epoch #249:Train loss: 0.000117029085 0.00013510443 0.00012914579 0.0001610747 0.00010194218, Valid Loss: 0.0005537571 0.0003441914 0.0007446483 0.00043935474 0.00024810046,  Moving Avg Valid Loss: 0.0005932034 0.00037549756 0.00078603113 0.00047912874 0.0002754838\n",
      "Training Dynamics Ensemble - Epoch #250:Train loss: 0.00011615004 0.00013417957 0.00012833155 0.00016025415 0.00010115279, Valid Loss: 0.0005517581 0.0003430258 0.00074260426 0.00043761157 0.0002468901,  Moving Avg Valid Loss: 0.00059113116 0.00037387398 0.00078385975 0.00047705288 0.0002740541\n",
      "Training Dynamics Ensemble - Epoch #251:Train loss: 0.000115291434 0.00013324444 0.00012751017 0.0001594385 0.00010037255, Valid Loss: 0.00054951507 0.00034071459 0.00074054155 0.00043605245 0.0002456408,  Moving Avg Valid Loss: 0.00058905035 0.000372216 0.0007816938 0.00047500283 0.00027263345\n",
      "Training Dynamics Ensemble - Epoch #252:Train loss: 0.00011444338 0.00013232592 0.0001266906 0.00015862167 9.959388e-05, Valid Loss: 0.00054777146 0.00033975285 0.0007389672 0.00043417083 0.0002444807,  Moving Avg Valid Loss: 0.00058698637 0.00037059284 0.00077955745 0.00047296123 0.0002712258\n",
      "Training Dynamics Ensemble - Epoch #253:Train loss: 0.00011359906 0.00013140975 0.0001258778 0.00015781497 9.8817916e-05, Valid Loss: 0.0005459752 0.0003389602 0.00073740847 0.0004328366 0.00024330823,  Moving Avg Valid Loss: 0.00058493577 0.0003690112 0.00077745 0.000470955 0.0002698299\n",
      "Training Dynamics Ensemble - Epoch #254:Train loss: 0.00011276119 0.00013049037 0.00012506919 0.00015700968 9.804731e-05, Valid Loss: 0.0005439602 0.00033723688 0.00073557446 0.0004311066 0.00024212447,  Moving Avg Valid Loss: 0.000582887 0.00036742247 0.0007753562 0.0004689626 0.00026844465\n",
      "Training Dynamics Ensemble - Epoch #255:Train loss: 0.00011193185 0.00012959682 0.00012426365 0.0001562122 9.72811e-05, Valid Loss: 0.0005423903 0.00033712087 0.0007337571 0.0004293883 0.00024098271,  Moving Avg Valid Loss: 0.00058086216 0.00036590738 0.00077327626 0.00046698388 0.00026707153\n",
      "Training Dynamics Ensemble - Epoch #256:Train loss: 0.00011110272 0.00012871303 0.00012346031 0.00015541592 9.652165e-05, Valid Loss: 0.00054043665 0.00033318778 0.0007323929 0.00042779226 0.00023975072,  Moving Avg Valid Loss: 0.0005788409 0.0003642714 0.0007712321 0.00046502432 0.0002657055\n",
      "Training Dynamics Ensemble - Epoch #257:Train loss: 0.00011028718 0.00012779867 0.00012266498 0.00015462229 9.577056e-05, Valid Loss: 0.00053858943 0.00033335766 0.000729945 0.00042556803 0.00023854189,  Moving Avg Valid Loss: 0.0005768283 0.0003627257 0.00076916773 0.0004630515 0.0002643473\n",
      "Training Dynamics Ensemble - Epoch #258:Train loss: 0.00010947346 0.00012690469 0.00012187061 0.0001538342 9.502204e-05, Valid Loss: 0.0005368491 0.00033079926 0.00072817807 0.0004243213 0.00023742375,  Moving Avg Valid Loss: 0.00057482935 0.00036112938 0.00076711824 0.00046111495 0.00026300113\n",
      "Training Dynamics Ensemble - Epoch #259:Train loss: 0.00010866141 0.000125996 0.00012107494 0.00015303364 9.427656e-05, Valid Loss: 0.0005343131 0.0003287869 0.00072709017 0.00042273145 0.00023622916,  Moving Avg Valid Loss: 0.0005728035 0.00035951225 0.0007651168 0.00045919575 0.00026166253\n",
      "Training Dynamics Ensemble - Epoch #260:Train loss: 0.00010785643 0.00012512789 0.00012027674 0.00015223684 9.35362e-05, Valid Loss: 0.00053266296 0.00033034856 0.0007251072 0.0004210048 0.00023496934,  Moving Avg Valid Loss: 0.00057079643 0.00035805407 0.0007631163 0.00045728622 0.00026032786\n",
      "Training Dynamics Ensemble - Epoch #261:Train loss: 0.000107052925 0.00012428066 0.00011947535 0.00015144359 9.2800045e-05, Valid Loss: 0.00053079706 0.0003267518 0.00072344346 0.00041937584 0.00023373285,  Moving Avg Valid Loss: 0.0005687964 0.00035648895 0.00076113263 0.0004553907 0.0002589981\n",
      "Training Dynamics Ensemble - Epoch #262:Train loss: 0.000106258805 0.00012337875 0.000118678625 0.00015065273 9.20679e-05, Valid Loss: 0.00052880414 0.0003274092 0.00072213967 0.00041736645 0.00023251954,  Moving Avg Valid Loss: 0.00056679675 0.00035503498 0.00075918296 0.00045348948 0.0002576742\n",
      "Training Dynamics Ensemble - Epoch #263:Train loss: 0.000105467705 0.00012247998 0.000117890726 0.00014986112 9.134724e-05, Valid Loss: 0.0005276342 0.0003254883 0.000721082 0.00041589388 0.0002313323,  Moving Avg Valid Loss: 0.0005648386 0.00035355764 0.00075727794 0.0004516097 0.0002563571\n",
      "Training Dynamics Ensemble - Epoch #264:Train loss: 0.00010468328 0.00012159104 0.00011709925 0.0001490663 9.062908e-05, Valid Loss: 0.00052552327 0.00032314402 0.00071923283 0.00041419468 0.00023019008,  Moving Avg Valid Loss: 0.0005628728 0.00035203694 0.00075537566 0.00044973893 0.00025504874\n",
      "Training Dynamics Ensemble - Epoch #265:Train loss: 0.000103901584 0.000120741955 0.00011630017 0.00014826983 8.9913854e-05, Valid Loss: 0.00052386295 0.0003243133 0.00071703206 0.0004125543 0.00022909099,  Moving Avg Valid Loss: 0.0005609223 0.00035065075 0.0007534585 0.0004478797 0.00025375086\n",
      "Training Dynamics Ensemble - Epoch #266:Train loss: 0.00010312471 0.0001198917 0.00011549524 0.00014747845 8.92046e-05, Valid Loss: 0.0005218962 0.00032092415 0.0007152861 0.00041112056 0.00022798739,  Moving Avg Valid Loss: 0.00055897096 0.00034916442 0.00075154984 0.00044604173 0.00025246266\n",
      "Training Dynamics Ensemble - Epoch #267:Train loss: 0.00010234028 0.000119007105 0.00011470433 0.00014669445 8.85047e-05, Valid Loss: 0.0005190284 0.00032130044 0.00071358634 0.00040936616 0.00022689482,  Moving Avg Valid Loss: 0.0005569738 0.00034777122 0.00074965163 0.00044420795 0.00025118428\n",
      "Training Dynamics Ensemble - Epoch #268:Train loss: 0.000101540005 0.000118148084 0.00011393381 0.00014590894 8.7805136e-05, Valid Loss: 0.0005175121 0.00031800655 0.0007121783 0.00040798727 0.00022577283,  Moving Avg Valid Loss: 0.00055500073 0.00034628296 0.000747778 0.0004423969 0.0002499137\n",
      "Training Dynamics Ensemble - Epoch #269:Train loss: 0.00010070414 0.00011727167 0.00011315659 0.00014511154 8.7105174e-05, Valid Loss: 0.0005155896 0.00031743274 0.0007108624 0.00040645053 0.00022457924,  Moving Avg Valid Loss: 0.0005530302 0.00034484043 0.00074593216 0.0004405996 0.00024864697\n",
      "Training Dynamics Ensemble - Epoch #270:Train loss: 9.9836914e-05 0.00011641091 0.00011238369 0.00014431265 8.6412896e-05, Valid Loss: 0.0005132921 0.0003155502 0.0007089713 0.0004047829 0.0002233549,  Moving Avg Valid Loss: 0.0005510433 0.00034337593 0.00074408413 0.00043880875 0.00024738236\n",
      "Training Dynamics Ensemble - Epoch #271:Train loss: 9.8958524e-05 0.00011557908 0.00011161922 0.0001435206 8.5725726e-05, Valid Loss: 0.0005117078 0.0003165022 0.0007077766 0.00040308802 0.000222233,  Moving Avg Valid Loss: 0.00054907653 0.00034203226 0.0007422687 0.0004370227 0.00024612487\n",
      "Training Dynamics Ensemble - Epoch #272:Train loss: 9.812518e-05 0.00011474752 0.000110885296 0.00014272079 8.503905e-05, Valid Loss: 0.00050940353 0.0003126442 0.00070550555 0.0004008926 0.0002210826,  Moving Avg Valid Loss: 0.0005470929 0.00034056287 0.00074043055 0.0004352162 0.00024487276\n",
      "Training Dynamics Ensemble - Epoch #273:Train loss: 9.726995e-05 0.00011392937 0.00011014834 0.00014192726 8.435033e-05, Valid Loss: 0.00050825696 0.0003135878 0.0007034667 0.00039936235 0.000219851,  Moving Avg Valid Loss: 0.00054515107 0.0003392141 0.00073858234 0.0004334235 0.00024362166\n",
      "Training Dynamics Ensemble - Epoch #274:Train loss: 9.644427e-05 0.00011307365 0.00010941214 0.00014115393 8.366492e-05, Valid Loss: 0.0005069629 0.00031091657 0.0007024687 0.00039754502 0.00021863644,  Moving Avg Valid Loss: 0.0005432417 0.00033779923 0.0007367766 0.00043162957 0.00024237239\n",
      "Training Dynamics Ensemble - Epoch #275:Train loss: 9.5603566e-05 0.00011220591 0.00010867919 0.0001404068 8.298006e-05, Valid Loss: 0.00050445826 0.0003091331 0.0007011488 0.00039607572 0.00021740595,  Moving Avg Valid Loss: 0.0005413025 0.00033636592 0.00073499524 0.00042985188 0.00024112407\n",
      "Training Dynamics Ensemble - Epoch #276:Train loss: 9.474933e-05 0.00011139139 0.00010795254 0.00013965352 8.229921e-05, Valid Loss: 0.00050293794 0.00031145551 0.0006997834 0.00039473997 0.00021623062,  Moving Avg Valid Loss: 0.00053938426 0.00033512042 0.0007332346 0.00042809627 0.0002398794\n",
      "Training Dynamics Ensemble - Epoch #277:Train loss: 9.3893526e-05 0.00011066847 0.00010722899 0.00013889736 8.1625345e-05, Valid Loss: 0.0005009241 0.00030506606 0.0006980767 0.0003927021 0.00021510983,  Moving Avg Valid Loss: 0.00053746125 0.00033361767 0.0007314767 0.00042632656 0.00023864092\n",
      "Training Dynamics Ensemble - Epoch #278:Train loss: 9.3090246e-05 0.00010994661 0.00010650974 0.0001381492 8.0961865e-05, Valid Loss: 0.0004993313 0.0003120977 0.0006966697 0.00039169352 0.00021395528,  Moving Avg Valid Loss: 0.0005355547 0.00033254168 0.00072973635 0.00042459488 0.00023740664\n",
      "Training Dynamics Ensemble - Epoch #279:Train loss: 9.2343456e-05 0.000109446686 0.00010578851 0.00013739581 8.0300226e-05, Valid Loss: 0.0004983492 0.00030291078 0.0006947889 0.00038996464 0.00021266665,  Moving Avg Valid Loss: 0.00053369446 0.00033106015 0.00072798895 0.00042286335 0.00023616964\n",
      "Training Dynamics Ensemble - Epoch #280:Train loss: 9.16013e-05 0.00010847938 0.00010507124 0.00013664213 7.963517e-05, Valid Loss: 0.0004963809 0.00030445415 0.0006934033 0.00038903943 0.00021138469,  Moving Avg Valid Loss: 0.0005318288 0.00032972984 0.00072625966 0.00042117215 0.00023493038\n",
      "Training Dynamics Ensemble - Epoch #281:Train loss: 9.087758e-05 0.00010739191 0.000104357336 0.00013590555 7.897892e-05, Valid Loss: 0.0004954186 0.00030359873 0.0006924824 0.00038734055 0.00021021327,  Moving Avg Valid Loss: 0.0005300082 0.00032842328 0.0007245708 0.00041948058 0.00023369452\n",
      "Training Dynamics Ensemble - Epoch #282:Train loss: 9.016562e-05 0.000106566964 0.00010366483 0.00013516066 7.8333775e-05, Valid Loss: 0.00049375405 0.0002996251 0.00069130375 0.0003855269 0.00020909063,  Moving Avg Valid Loss: 0.0005281955 0.00032698337 0.0007229074 0.0004177829 0.00023246433\n",
      "Training Dynamics Ensemble - Epoch #283:Train loss: 8.946008e-05 0.00010588996 0.00010296577 0.00013443225 7.768466e-05, Valid Loss: 0.00049157056 0.00030495497 0.00069026725 0.00038449618 0.00020798393,  Moving Avg Valid Loss: 0.00052636425 0.00032588196 0.0007212754 0.00041611854 0.0002312403\n",
      "Training Dynamics Ensemble - Epoch #284:Train loss: 8.8762165e-05 0.000105232866 0.00010227168 0.00013370063 7.703562e-05, Valid Loss: 0.0004901474 0.00029724694 0.0006884828 0.0003824214 0.00020695977,  Moving Avg Valid Loss: 0.00052455335 0.0003244502 0.00071963575 0.00041443369 0.00023002626\n",
      "Training Dynamics Ensemble - Epoch #285:Train loss: 8.806794e-05 0.00010422549 0.00010157791 0.0001329757 7.639636e-05, Valid Loss: 0.00048791905 0.00030122226 0.00068758044 0.0003814677 0.00020588134,  Moving Avg Valid Loss: 0.0005227216 0.0003232888 0.00071803294 0.0004127854 0.00022881902\n",
      "Training Dynamics Ensemble - Epoch #286:Train loss: 8.7377724e-05 0.000103302875 0.0001009016 0.00013224824 7.576019e-05, Valid Loss: 0.00048653333 0.00029740646 0.0006855038 0.0003793684 0.00020477256,  Moving Avg Valid Loss: 0.0005209122 0.00032199468 0.00071640644 0.00041111454 0.00022761669\n",
      "Training Dynamics Ensemble - Epoch #287:Train loss: 8.669064e-05 0.000102407146 0.00010022164 0.0001315271 7.5129225e-05, Valid Loss: 0.0004854456 0.0002947516 0.0006842332 0.00037866188 0.00020368083,  Moving Avg Valid Loss: 0.0005191389 0.0003206325 0.00071479776 0.00040949188 0.0002264199\n",
      "Training Dynamics Ensemble - Epoch #288:Train loss: 8.6009095e-05 0.000101659 9.953212e-05 0.00013080597 7.45008e-05, Valid Loss: 0.00048348488 0.0002974331 0.0006831146 0.0003770312 0.00020264661,  Moving Avg Valid Loss: 0.00051735615 0.0003194725 0.0007132136 0.00040786885 0.00022523123\n",
      "Training Dynamics Ensemble - Epoch #289:Train loss: 8.533652e-05 0.00010095957 9.8869146e-05 0.0001301001 7.387672e-05, Valid Loss: 0.0004822032 0.00029098237 0.00068161497 0.0003760793 0.00020153794,  Moving Avg Valid Loss: 0.00051559845 0.000318048 0.00071163365 0.00040627935 0.00022404655\n",
      "Training Dynamics Ensemble - Epoch #290:Train loss: 8.4661915e-05 0.00010024877 9.8196426e-05 0.00012938287 7.325748e-05, Valid Loss: 0.00048006477 0.0002945912 0.00068103056 0.00037427765 0.00020038408,  Moving Avg Valid Loss: 0.0005138217 0.00031687517 0.0007101035 0.00040467925 0.00022286343\n",
      "Training Dynamics Ensemble - Epoch #291:Train loss: 8.399455e-05 9.9315206e-05 9.7524906e-05 0.00012866946 7.264263e-05, Valid Loss: 0.00047885076 0.00028933902 0.0006790214 0.00037313395 0.00019925516,  Moving Avg Valid Loss: 0.00051207317 0.00031549836 0.0007085494 0.00040310196 0.000221683\n",
      "Training Dynamics Ensemble - Epoch #292:Train loss: 8.332626e-05 9.8446726e-05 9.685793e-05 0.0001279518 7.203008e-05, Valid Loss: 0.0004775083 0.00029122707 0.00067765336 0.00037128959 0.0001981302,  Moving Avg Valid Loss: 0.0005103449 0.00031428479 0.0007070046 0.00040151135 0.00022050536\n",
      "Training Dynamics Ensemble - Epoch #293:Train loss: 8.266464e-05 9.761294e-05 9.6181626e-05 0.00012721817 7.1418304e-05, Valid Loss: 0.00047530571 0.00028728807 0.0006766106 0.00037053108 0.0001969687,  Moving Avg Valid Loss: 0.00050859293 0.00031293495 0.00070548494 0.00039996236 0.00021932852\n",
      "Training Dynamics Ensemble - Epoch #294:Train loss: 8.2006845e-05 9.6748816e-05 9.552038e-05 0.00012649184 7.080871e-05, Valid Loss: 0.00047412337 0.00028451797 0.0006749397 0.0003687397 0.00019582093,  Moving Avg Valid Loss: 0.00050686946 0.0003115141 0.0007039577 0.00039840123 0.00021815315\n",
      "Training Dynamics Ensemble - Epoch #295:Train loss: 8.1351674e-05 9.593243e-05 9.486348e-05 0.00012577452 7.020574e-05, Valid Loss: 0.00047224102 0.00028474414 0.00067366834 0.00036782326 0.00019471494,  Moving Avg Valid Loss: 0.000505138 0.00031017562 0.00070244324 0.00039687235 0.00021698122\n",
      "Training Dynamics Ensemble - Epoch #296:Train loss: 8.0699414e-05 9.512412e-05 9.419185e-05 0.0001250509 6.96099e-05, Valid Loss: 0.00047095076 0.00028313848 0.0006726256 0.0003663092 0.00019357227,  Moving Avg Valid Loss: 0.00050342863 0.00030882374 0.00070095237 0.00039534416 0.00021581077\n",
      "Training Dynamics Ensemble - Epoch #297:Train loss: 8.005248e-05 9.431989e-05 9.353821e-05 0.00012432707 6.901832e-05, Valid Loss: 0.00046920023 0.00028422102 0.0006715038 0.00036518442 0.00019244007,  Moving Avg Valid Loss: 0.0005017172 0.0003075936 0.0006994799 0.00039383618 0.00021464223\n",
      "Training Dynamics Ensemble - Epoch #298:Train loss: 7.9408e-05 9.355453e-05 9.287977e-05 0.00012361482 6.843331e-05, Valid Loss: 0.00046708994 0.00028071948 0.0006701884 0.00036400577 0.00019142142,  Moving Avg Valid Loss: 0.0004999858 0.0003062499 0.00069801527 0.00039234463 0.0002134812\n",
      "Training Dynamics Ensemble - Epoch #299:Train loss: 7.87668e-05 9.2777846e-05 9.222753e-05 0.00012291464 6.7855486e-05, Valid Loss: 0.00046587983 0.00028234994 0.00066918146 0.00036252372 0.00019038787,  Moving Avg Valid Loss: 0.0004982805 0.00030505488 0.0006965735 0.0003908536 0.00021232653\n",
      "Training Dynamics Ensemble - Epoch #300:Train loss: 7.8132434e-05 9.201656e-05 9.157791e-05 0.00012220845 6.727911e-05, Valid Loss: 0.00046376433 0.00027678633 0.00066796987 0.0003609571 0.00018928193,  Moving Avg Valid Loss: 0.0004965547 0.00030364146 0.00069514336 0.00038935876 0.0002111743\n",
      "Training Dynamics Ensemble - Epoch #301:Train loss: 7.749941e-05 9.1284914e-05 9.092052e-05 0.00012150449 6.670316e-05, Valid Loss: 0.00046278044 0.00027881993 0.00066691753 0.00035985647 0.00018818596,  Moving Avg Valid Loss: 0.000494866 0.00030240038 0.00069373206 0.00038788366 0.00021002487\n",
      "Training Dynamics Ensemble - Epoch #302:Train loss: 7.6871234e-05 9.058437e-05 9.02615e-05 0.00012080299 6.612361e-05, Valid Loss: 0.00046135086 0.00027224136 0.0006656128 0.00035810613 0.00018710169,  Moving Avg Valid Loss: 0.0004931902 0.00030089243 0.0006923261 0.0003863948 0.00020887872\n",
      "Training Dynamics Ensemble - Epoch #303:Train loss: 7.6246724e-05 8.9892106e-05 8.9607536e-05 0.000120101984 6.5541906e-05, Valid Loss: 0.00045991477 0.00027893926 0.0006639557 0.00035786344 0.00018600021,  Moving Avg Valid Loss: 0.0004915264 0.00029979477 0.0006909076 0.00038496824 0.00020773479\n",
      "Training Dynamics Ensemble - Epoch #304:Train loss: 7.562734e-05 8.9262554e-05 8.894644e-05 0.000119417695 6.495979e-05, Valid Loss: 0.00045833515 0.00027022738 0.0006629179 0.00035563653 0.00018487709,  Moving Avg Valid Loss: 0.0004898668 0.0002983164 0.0006895081 0.00038350164 0.00020659191\n",
      "Training Dynamics Ensemble - Epoch #305:Train loss: 7.500927e-05 8.862026e-05 8.828682e-05 0.000118750046 6.4377105e-05, Valid Loss: 0.00045653456 0.00027806702 0.0006620892 0.0003559541 0.0001838059,  Moving Avg Valid Loss: 0.0004882002 0.0002973039 0.00068813714 0.00038212427 0.0002054526\n",
      "Training Dynamics Ensemble - Epoch #306:Train loss: 7.439485e-05 8.811397e-05 8.762204e-05 0.00011808995 6.3795895e-05, Valid Loss: 0.00045588898 0.00026700142 0.00066080375 0.00035309893 0.00018274278,  Moving Avg Valid Loss: 0.0004865846 0.00029578878 0.0006867705 0.00038067298 0.0002043171\n",
      "Training Dynamics Ensemble - Epoch #307:Train loss: 7.378473e-05 8.738335e-05 8.697875e-05 0.00011746426 6.321888e-05, Valid Loss: 0.0004542162 0.0002731068 0.00065975875 0.0003538349 0.0001816924,  Moving Avg Valid Loss: 0.0004849662 0.0002946547 0.0006854199 0.0003793311 0.00020318586\n",
      "Training Dynamics Ensemble - Epoch #308:Train loss: 7.317944e-05 8.63491e-05 8.634366e-05 0.000116870804 6.264489e-05, Valid Loss: 0.00045328357 0.0002671291 0.0006582074 0.00035013797 0.00018060971,  Moving Avg Valid Loss: 0.00048338206 0.0002932784 0.0006840593 0.00037787142 0.00020205705\n",
      "Training Dynamics Ensemble - Epoch #309:Train loss: 7.257591e-05 8.523945e-05 8.571687e-05 0.000116334806 6.2084764e-05, Valid Loss: 0.0004507696 0.0002679465 0.0006570094 0.00035159275 0.00017960949,  Moving Avg Valid Loss: 0.00048175143 0.0002920118 0.00068270677 0.0003765575 0.00020093468\n",
      "Training Dynamics Ensemble - Epoch #310:Train loss: 7.1976756e-05 8.440279e-05 8.509268e-05 0.00011587132 6.153022e-05, Valid Loss: 0.0004496128 0.00026900994 0.0006556821 0.0003469175 0.00017866923,  Moving Avg Valid Loss: 0.0004801445 0.0002908617 0.00068135554 0.0003750755 0.00019982141\n",
      "Training Dynamics Ensemble - Epoch #311:Train loss: 7.138095e-05 8.3789426e-05 8.447326e-05 0.000115489485 6.0979666e-05, Valid Loss: 0.00044802847 0.0002633271 0.0006554288 0.00035042487 0.00017768287,  Moving Avg Valid Loss: 0.00047853868 0.00028948497 0.0006800592 0.00037384295 0.0001987145\n",
      "Training Dynamics Ensemble - Epoch #312:Train loss: 7.0792215e-05 8.3398845e-05 8.386841e-05 0.000115279705 6.043283e-05, Valid Loss: 0.00044702485 0.00026988986 0.0006547051 0.00034373 0.00017671965,  Moving Avg Valid Loss: 0.000476963 0.0002885052 0.00067879143 0.00037233732 0.00019761475\n",
      "Training Dynamics Ensemble - Epoch #313:Train loss: 7.0203954e-05 8.2702856e-05 8.326034e-05 0.000115298026 5.9887534e-05, Valid Loss: 0.00044549356 0.00026268334 0.000652529 0.000350438 0.00017581016,  Moving Avg Valid Loss: 0.00047538953 0.00028721412 0.00067747827 0.00037124235 0.00019652452\n",
      "Training Dynamics Ensemble - Epoch #314:Train loss: 6.9617585e-05 8.194053e-05 8.2648774e-05 0.00011568613 5.9348997e-05, Valid Loss: 0.00044371493 0.00026600654 0.000651805 0.00034062477 0.00017486166,  Moving Avg Valid Loss: 0.0004738058 0.00028615375 0.00067619456 0.00036971146 0.00019544137\n",
      "Training Dynamics Ensemble - Epoch #315:Train loss: 6.903584e-05 8.0977414e-05 8.2048755e-05 0.0001166197 5.8818485e-05, Valid Loss: 0.0004423341 0.00026156823 0.00064952736 0.0003528005 0.00017388635,  Moving Avg Valid Loss: 0.0004722322 0.00028492446 0.0006748612 0.0003688659 0.00019436362\n",
      "Training Dynamics Ensemble - Epoch #316:Train loss: 6.8461e-05 8.014288e-05 8.144513e-05 0.00011833581 5.8282418e-05, Valid Loss: 0.0004406226 0.00026196265 0.00064818736 0.0003388105 0.00017290862,  Moving Avg Valid Loss: 0.00047065172 0.00028377635 0.00067352754 0.00036736313 0.00019329088\n",
      "Training Dynamics Ensemble - Epoch #317:Train loss: 6.788654e-05 7.940523e-05 8.086071e-05 0.00012125337 5.7756595e-05, Valid Loss: 0.0004394543 0.00026317697 0.00064736046 0.000359022 0.00017189083,  Moving Avg Valid Loss: 0.00046909184 0.0002827464 0.00067221915 0.00036694607 0.00019222086\n",
      "Training Dynamics Ensemble - Epoch #318:Train loss: 6.731549e-05 7.877899e-05 8.027748e-05 0.0001258537 5.723827e-05, Valid Loss: 0.0004375368 0.0002580829 0.000646236 0.000339158 0.00017092169,  Moving Avg Valid Loss: 0.0004675141 0.0002815132 0.00067092 0.00036555665 0.0001911559\n",
      "Training Dynamics Ensemble - Epoch #319:Train loss: 6.674723e-05 7.825395e-05 7.9690915e-05 0.00013282444 5.672399e-05, Valid Loss: 0.00043628356 0.000263385 0.00064538367 0.00037170242 0.00016998404,  Moving Avg Valid Loss: 0.00046595256 0.0002806068 0.00066964317 0.00036586393 0.0001900973\n",
      "Stopping Training of Model 3\n",
      "Training Dynamics Ensemble - Epoch #320:Train loss: 6.618227e-05 7.781113e-05 7.9109705e-05 0.00014285032 5.6213776e-05, Valid Loss: 0.0004346688 0.00025471614 0.0006427405 0.00037170242 0.00016903212,  Moving Avg Valid Loss: 0.00046438834 0.00027931225 0.00066829805 0.00036615584 0.00018904403\n",
      "Training Dynamics Ensemble - Epoch #321:Train loss: 6.5618966e-05 7.733708e-05 7.853709e-05 0.00014285032 5.570631e-05, Valid Loss: 0.00043337332 0.00026283594 0.00064211106 0.00037170242 0.00016806179,  Moving Avg Valid Loss: 0.0004628376 0.00027848844 0.00066698866 0.00036643317 0.00018799491\n",
      "Training Dynamics Ensemble - Epoch #322:Train loss: 6.505988e-05 7.7014076e-05 7.796849e-05 0.0001428503 5.520859e-05, Valid Loss: 0.00043196656 0.0002512466 0.000640151 0.00037170242 0.00016715712,  Moving Avg Valid Loss: 0.00046129405 0.00027712632 0.00066564674 0.00036669662 0.00018695302\n",
      "Training Dynamics Ensemble - Epoch #323:Train loss: 6.45036e-05 7.6549004e-05 7.739874e-05 0.0001428503 5.472111e-05, Valid Loss: 0.00043031716 0.00026060088 0.0006389509 0.00037170242 0.00016625323,  Moving Avg Valid Loss: 0.0004597452 0.00027630004 0.000664312 0.00036694692 0.00018591803\n",
      "Training Dynamics Ensemble - Epoch #324:Train loss: 6.3952815e-05 7.584912e-05 7.682849e-05 0.0001428503 5.4241584e-05, Valid Loss: 0.0004289405 0.00025138387 0.00063790387 0.00037170242 0.00016526601,  Moving Avg Valid Loss: 0.00045820497 0.00027505422 0.00066299154 0.0003671847 0.00018488543\n",
      "Training Dynamics Ensemble - Epoch #325:Train loss: 6.3402105e-05 7.463068e-05 7.627193e-05 0.0001428503 5.3751537e-05, Valid Loss: 0.0004270104 0.00025396343 0.0006360276 0.00037170242 0.00016430447,  Moving Avg Valid Loss: 0.00045664524 0.00027399967 0.00066164334 0.00036741057 0.00018385638\n",
      "Training Dynamics Ensemble - Epoch #326:Train loss: 6.285265e-05 7.3435556e-05 7.571656e-05 0.00014285033 5.326126e-05, Valid Loss: 0.00042602955 0.0002526538 0.0006361781 0.00037170242 0.00016339631,  Moving Avg Valid Loss: 0.00045511444 0.00027293238 0.0006603701 0.00036762515 0.00018283336\n",
      "Training Dynamics Ensemble - Epoch #327:Train loss: 6.230564e-05 7.2726245e-05 7.516509e-05 0.0001428503 5.2771553e-05, Valid Loss: 0.00042426292 0.00024976334 0.00063334854 0.00037170242 0.00016248801,  Moving Avg Valid Loss: 0.00045357185 0.00027177393 0.000659019 0.00036782902 0.0001818161\n",
      "Training Dynamics Ensemble - Epoch #328:Train loss: 6.176318e-05 7.235261e-05 7.4622156e-05 0.00014285032 5.229046e-05, Valid Loss: 0.00042349694 0.0002572254 0.0006338636 0.00037170242 0.0001615867,  Moving Avg Valid Loss: 0.00045206808 0.0002710465 0.00065776124 0.00036802268 0.00018080464\n",
      "Training Dynamics Ensemble - Epoch #329:Train loss: 6.122467e-05 7.2413815e-05 7.40707e-05 0.0001428503 5.180734e-05, Valid Loss: 0.0004216479 0.00024633465 0.00063174526 0.00037170242 0.00016070448,  Moving Avg Valid Loss: 0.0004505471 0.00026981093 0.0006564604 0.00036820667 0.00017979962\n",
      "Training Dynamics Ensemble - Epoch #330:Train loss: 6.068387e-05 7.1971546e-05 7.353902e-05 0.0001428503 5.131799e-05, Valid Loss: 0.00042094564 0.0002556471 0.00063119037 0.00037170242 0.00015978255,  Moving Avg Valid Loss: 0.000449067 0.00026910272 0.0006551969 0.00036838147 0.00017879877\n",
      "Training Dynamics Ensemble - Epoch #331:Train loss: 6.0147133e-05 7.1649076e-05 7.298007e-05 0.00014285032 5.0825605e-05, Valid Loss: 0.00041895013 0.0002440908 0.0006293349 0.00037170242 0.00015887419,  Moving Avg Valid Loss: 0.00044756118 0.00026785213 0.0006539038 0.0003685475 0.00017780255\n",
      "Training Dynamics Ensemble - Epoch #332:Train loss: 5.9613187e-05 7.064115e-05 7.246868e-05 0.00014285029 5.0334427e-05, Valid Loss: 0.00041764366 0.000249937 0.0006289042 0.00037170242 0.00015797673,  Moving Avg Valid Loss: 0.0004460653 0.00026695634 0.00065265386 0.00036870525 0.00017681126\n",
      "Training Dynamics Ensemble - Epoch #333:Train loss: 5.9079954e-05 6.933305e-05 7.1919116e-05 0.00014285029 4.9854352e-05, Valid Loss: 0.0004157553 0.00024572355 0.00062761747 0.00037170242 0.00015709733,  Moving Avg Valid Loss: 0.00044454978 0.0002658947 0.000651402 0.0003688551 0.00017582555\n",
      "Training Dynamics Ensemble - Epoch #334:Train loss: 5.854786e-05 6.823577e-05 7.141847e-05 0.0001428503 4.939058e-05, Valid Loss: 0.00041480293 0.00024467913 0.00062621455 0.00037170242 0.00015619144,  Moving Avg Valid Loss: 0.00044306242 0.0002648339 0.0006501426 0.00036899748 0.00017484385\n",
      "Training Dynamics Ensemble - Epoch #335:Train loss: 5.8015947e-05 6.76618e-05 7.087004e-05 0.00014285032 4.893423e-05, Valid Loss: 0.0004132088 0.00024730092 0.00062490563 0.00037170242 0.00015529318,  Moving Avg Valid Loss: 0.00044156972 0.00026395728 0.0006488808 0.00036913273 0.00017386631\n",
      "Training Dynamics Ensemble - Epoch #336:Train loss: 5.748965e-05 6.736709e-05 7.037209e-05 0.0001428503 4.8480957e-05, Valid Loss: 0.00041195116 0.00024014639 0.0006237616 0.00037170242 0.0001543892,  Moving Avg Valid Loss: 0.0004400888 0.00026276673 0.00064762484 0.00036926122 0.00017289245\n",
      "Training Dynamics Ensemble - Epoch #337:Train loss: 5.6968714e-05 6.709789e-05 6.9830385e-05 0.0001428503 4.8031536e-05, Valid Loss: 0.00041036773 0.00024796478 0.0006222481 0.00037170242 0.00015349957,  Moving Avg Valid Loss: 0.00043860273 0.00026202662 0.00064635597 0.00036938328 0.00017192282\n",
      "Training Dynamics Ensemble - Epoch #338:Train loss: 5.645326e-05 6.669107e-05 6.9316106e-05 0.0001428503 4.7585207e-05, Valid Loss: 0.00040933557 0.00023878785 0.00062166486 0.00037170242 0.00015266403,  Moving Avg Valid Loss: 0.00043713936 0.00026086468 0.0006451214 0.00036949923 0.00017095989\n",
      "Training Dynamics Ensemble - Epoch #339:Train loss: 5.593792e-05 6.59374e-05 6.881007e-05 0.00014285032 4.713833e-05, Valid Loss: 0.00040780974 0.0002435083 0.0006203625 0.00037170242 0.00015180519,  Moving Avg Valid Loss: 0.00043567288 0.00025999686 0.0006438834 0.0003696094 0.00017000215\n",
      "Training Dynamics Ensemble - Epoch #340:Train loss: 5.5428434e-05 6.496554e-05 6.828025e-05 0.0001428503 4.6693065e-05, Valid Loss: 0.00040648007 0.00023890717 0.00061850034 0.00037170242 0.00015083623,  Moving Avg Valid Loss: 0.00043421323 0.00025894237 0.00064261426 0.00036971405 0.00016904385\n",
      "Training Dynamics Ensemble - Epoch #341:Train loss: 5.492038e-05 6.397311e-05 6.779748e-05 0.00014285032 4.6251247e-05, Valid Loss: 0.00040459158 0.00024023674 0.0006175076 0.00037170242 0.00014987845,  Moving Avg Valid Loss: 0.00043273214 0.0002580071 0.0006413589 0.00036981347 0.00016808558\n",
      "Training Dynamics Ensemble - Epoch #342:Train loss: 5.441735e-05 6.324161e-05 6.72676e-05 0.00014285032 4.5812416e-05, Valid Loss: 0.00040361614 0.0002402855 0.0006163734 0.00037170242 0.00014894934,  Moving Avg Valid Loss: 0.00043127633 0.000257121 0.00064010965 0.0003699079 0.00016712876\n",
      "Training Dynamics Ensemble - Epoch #343:Train loss: 5.3914675e-05 6.271965e-05 6.6784305e-05 0.00014285033 4.536998e-05, Valid Loss: 0.0004018172 0.00023462459 0.0006159251 0.00037170242 0.0001479749,  Moving Avg Valid Loss: 0.0004298034 0.00025599616 0.00063890044 0.00036999764 0.00016617107\n",
      "Training Dynamics Ensemble - Epoch #344:Train loss: 5.341445e-05 6.2395666e-05 6.627934e-05 0.00014285032 4.4926528e-05, Valid Loss: 0.00040107823 0.00024102276 0.00061406323 0.00037170242 0.0001469533,  Moving Avg Valid Loss: 0.00042836712 0.0002552475 0.0006376586 0.00037008288 0.00016521018\n",
      "Training Dynamics Ensemble - Epoch #345:Train loss: 5.2917756e-05 6.2187195e-05 6.581151e-05 0.0001428503 4.4476466e-05, Valid Loss: 0.00039869445 0.00023237904 0.0006137087 0.00037170242 0.00014599637,  Moving Avg Valid Loss: 0.0004268835 0.00025410406 0.0006364611 0.00037016385 0.00016424949\n",
      "Training Dynamics Ensemble - Epoch #346:Train loss: 5.2419928e-05 6.199841e-05 6.530226e-05 0.00014285032 4.401074e-05, Valid Loss: 0.00039831802 0.0002409279 0.0006108763 0.00037170242 0.00014511964,  Moving Avg Valid Loss: 0.00042545522 0.00025344524 0.00063518184 0.00037024077 0.00016329299\n",
      "Training Dynamics Ensemble - Epoch #347:Train loss: 5.1926134e-05 6.166906e-05 6.48381e-05 0.00014285032 4.35451e-05, Valid Loss: 0.00039572868 0.00023085841 0.000612342 0.00037170242 0.00014422314,  Moving Avg Valid Loss: 0.0004239689 0.0002523159 0.00063403987 0.00037031385 0.0001623395\n",
      "Training Dynamics Ensemble - Epoch #348:Train loss: 5.1436033e-05 6.111004e-05 6.437262e-05 0.0001428503 4.3100754e-05, Valid Loss: 0.00039674627 0.00024038595 0.0006083663 0.00037170242 0.00014333517,  Moving Avg Valid Loss: 0.00042260776 0.00025171938 0.0006327562 0.00037038326 0.00016138928\n",
      "Training Dynamics Ensemble - Epoch #349:Train loss: 5.095957e-05 6.0463597e-05 6.393826e-05 0.0001428503 4.2662356e-05, Valid Loss: 0.00039182106 0.00023024152 0.0006100349 0.00037170242 0.00014248153,  Moving Avg Valid Loss: 0.0004210684 0.00025064548 0.0006316201 0.0003704492 0.0001604439\n",
      "Training Dynamics Ensemble - Epoch #350:Train loss: 5.051139e-05 5.945192e-05 6.362289e-05 0.0001428503 4.224478e-05, Valid Loss: 0.0003949181 0.00023360254 0.00060526194 0.00037170242 0.00014166826,  Moving Avg Valid Loss: 0.00041976088 0.00024979332 0.0006303022 0.00037051187 0.00015950511\n",
      "Training Dynamics Ensemble - Epoch #351:Train loss: 5.013794e-05 5.828083e-05 6.345365e-05 0.0001428503 4.1842362e-05, Valid Loss: 0.00038710076 0.00022912488 0.0006103243 0.00037170242 0.00014088959,  Moving Avg Valid Loss: 0.00041812786 0.0002487599 0.0006293033 0.0003705714 0.00015857433\n",
      "Training Dynamics Ensemble - Epoch #352:Train loss: 4.9901035e-05 5.7299567e-05 6.3679145e-05 0.00014285033 4.1445513e-05, Valid Loss: 0.00039628486 0.00023107087 0.00060528127 0.00037170242 0.00014012381,  Moving Avg Valid Loss: 0.0004170357 0.00024787543 0.00062810216 0.00037062794 0.00015765181\n",
      "Training Dynamics Ensemble - Epoch #353:Train loss: 4.9955783e-05 5.6624296e-05 6.4566135e-05 0.00014285032 4.1053056e-05, Valid Loss: 0.00038089545 0.00023066218 0.0006182947 0.00037170242 0.00013932996,  Moving Avg Valid Loss: 0.0004152287 0.00024701477 0.00062761176 0.00037068166 0.00015673571\n",
      "Training Dynamics Ensemble - Epoch #354:Train loss: 5.0642706e-05 5.611357e-05 6.7044595e-05 0.00014285032 4.0660467e-05, Valid Loss: 0.00040287516 0.00022635132 0.000612851 0.00037170242 0.0001384667,  Moving Avg Valid Loss: 0.000414611 0.0002459816 0.0006268737 0.0003707327 0.00015582226\n",
      "Training Dynamics Ensemble - Epoch #355:Train loss: 5.269932e-05 5.5636076e-05 7.281071e-05 0.0001428503 4.0263003e-05, Valid Loss: 0.0003738527 0.00022973193 0.00065282313 0.00037170242 0.00013758437,  Moving Avg Valid Loss: 0.00041257308 0.0002451691 0.00062817114 0.0003707812 0.00015491036\n",
      "Stopping Training of Model 2\n",
      "Training Dynamics Ensemble - Epoch #356:Train loss: 5.779952e-05 5.5252025e-05 8.4688036e-05 0.00014285032 3.987134e-05, Valid Loss: 0.00042986596 0.00022598085 0.00065282313 0.00037170242 0.00013669861,  Moving Avg Valid Loss: 0.00041343772 0.0002442097 0.00062940374 0.00037082727 0.00015399978\n",
      "Stopping Training of Model 0\n",
      "Training Dynamics Ensemble - Epoch #357:Train loss: 6.9482696e-05 5.4693104e-05 8.468802e-05 0.0001428503 3.9487768e-05, Valid Loss: 0.00042986596 0.00023091721 0.00065282313 0.00037170242 0.00013586444,  Moving Avg Valid Loss: 0.00041425912 0.00024354507 0.0006305747 0.000370871 0.00015309302\n",
      "Training Dynamics Ensemble - Epoch #358:Train loss: 6.9482696e-05 5.4183958e-05 8.4688036e-05 0.00014285032 3.9109254e-05, Valid Loss: 0.00042986596 0.00022426143 0.00065282313 0.00037170242 0.000135086,  Moving Avg Valid Loss: 0.00041503945 0.00024258088 0.0006316871 0.00037091257 0.00015219266\n",
      "Training Dynamics Ensemble - Epoch #359:Train loss: 6.9482696e-05 5.3533244e-05 8.4688036e-05 0.00014285033 3.873759e-05, Valid Loss: 0.00042986596 0.00022813033 0.00065282313 0.00037170242 0.00013431131,  Moving Avg Valid Loss: 0.00041578076 0.00024185835 0.00063274393 0.00037095207 0.00015129859\n",
      "Training Dynamics Ensemble - Epoch #360:Train loss: 6.94827e-05 5.312208e-05 8.468803e-05 0.00014285032 3.8376795e-05, Valid Loss: 0.00042986596 0.00022179067 0.00065282313 0.00037170242 0.00013358313,  Moving Avg Valid Loss: 0.000416485 0.00024085496 0.0006337479 0.00037098958 0.00015041282\n",
      "Training Dynamics Ensemble - Epoch #361:Train loss: 6.94827e-05 5.2691736e-05 8.4688036e-05 0.00014285032 3.8025624e-05, Valid Loss: 0.00042986596 0.00023043083 0.00065282313 0.00037170242 0.00013283876,  Moving Avg Valid Loss: 0.00041715405 0.00024033374 0.0006347017 0.00037102523 0.00014953411\n",
      "Training Dynamics Ensemble - Epoch #362:Train loss: 6.9482696e-05 5.2703166e-05 8.4688036e-05 0.00014285032 3.7693993e-05, Valid Loss: 0.00042986596 0.00022066796 0.00065282313 0.00037170242 0.00013219399,  Moving Avg Valid Loss: 0.00041778965 0.00023935044 0.00063560775 0.00037105908 0.00014866711\n",
      "Training Dynamics Ensemble - Epoch #363:Train loss: 6.9482696e-05 5.261686e-05 8.4688036e-05 0.00014285032 3.7394973e-05, Valid Loss: 0.00042986596 0.00022862504 0.00065282313 0.00037170242 0.0001316046,  Moving Avg Valid Loss: 0.00041839347 0.00023881417 0.0006364685 0.00037109124 0.00014781399\n",
      "Training Dynamics Ensemble - Epoch #364:Train loss: 6.9482696e-05 5.293794e-05 8.4688036e-05 0.00014285032 3.7156766e-05, Valid Loss: 0.00042986596 0.00021745784 0.00065282313 0.00037170242 0.0001311149,  Moving Avg Valid Loss: 0.00041896707 0.00023774635 0.0006372863 0.0003711218 0.00014697903\n",
      "Training Dynamics Ensemble - Epoch #365:Train loss: 6.94827e-05 5.324793e-05 8.4688036e-05 0.00014285032 3.703641e-05, Valid Loss: 0.00042986596 0.00023342225 0.00065282313 0.00037170242 0.00013089894,  Moving Avg Valid Loss: 0.000419512 0.00023753016 0.0006380631 0.00037115082 0.00014617502\n",
      "Training Dynamics Ensemble - Epoch #366:Train loss: 6.948269e-05 5.377507e-05 8.4688036e-05 0.0001428503 3.71308e-05, Valid Loss: 0.00042986596 0.00021873212 0.00065282313 0.00037170242 0.0001309715,  Moving Avg Valid Loss: 0.0004200297 0.00023659025 0.00063880114 0.0003711784 0.00014541484\n",
      "Training Dynamics Ensemble - Epoch #367:Train loss: 6.948269e-05 5.3829048e-05 8.4688036e-05 0.00014285032 3.7654787e-05, Valid Loss: 0.00042986596 0.00022844595 0.00065282313 0.00037170242 0.00013205342,  Moving Avg Valid Loss: 0.0004205215 0.00023618303 0.00063950225 0.0003712046 0.00014474677\n",
      "Training Dynamics Ensemble - Epoch #368:Train loss: 6.948269e-05 5.298006e-05 8.4688036e-05 0.00014285032 3.9102506e-05, Valid Loss: 0.00042986596 0.00021449718 0.00065282313 0.00037170242 0.0001347935,  Moving Avg Valid Loss: 0.0004209887 0.00023509873 0.0006401683 0.0003712295 0.0001442491\n",
      "Training Dynamics Ensemble - Epoch #369:Train loss: 6.94827e-05 5.1322077e-05 8.4688036e-05 0.00014285032 4.2362422e-05, Valid Loss: 0.00042986596 0.00022476914 0.00065282313 0.00037170242 0.00014129069,  Moving Avg Valid Loss: 0.00042143257 0.00023458226 0.00064080104 0.00037125312 0.00014410118\n",
      "Training Dynamics Ensemble - Epoch #370:Train loss: 6.94827e-05 4.909721e-05 8.468802e-05 0.0001428503 4.937942e-05, Valid Loss: 0.00042986596 0.00021624468 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042185423 0.00023366537 0.00064140215 0.0003712756 0.00014462671\n",
      "Stopping Training of Model 4\n",
      "Training Dynamics Ensemble - Epoch #371:Train loss: 6.94827e-05 4.732341e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00021501673 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042225482 0.00023273294 0.0006419732 0.00037129692 0.00014512596\n",
      "Training Dynamics Ensemble - Epoch #372:Train loss: 6.94827e-05 4.613904e-05 8.4688036e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.00021477569 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042263538 0.00023183509 0.0006425157 0.0003713172 0.00014560025\n",
      "Training Dynamics Ensemble - Epoch #373:Train loss: 6.948269e-05 4.593864e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00021136075 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.0004229969 0.00023081138 0.0006430311 0.00037133647 0.00014605082\n",
      "Training Dynamics Ensemble - Epoch #374:Train loss: 6.9482696e-05 4.6228506e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00022075059 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042334036 0.00023030833 0.0006435207 0.00037135478 0.00014647887\n",
      "Training Dynamics Ensemble - Epoch #375:Train loss: 6.9482696e-05 4.6974183e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00021093177 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042366664 0.0002293395 0.0006439858 0.00037137215 0.0001468855\n",
      "Training Dynamics Ensemble - Epoch #376:Train loss: 6.9482696e-05 4.7101556e-05 8.468803e-05 0.00014285033 6.392351e-05, Valid Loss: 0.00042986596 0.00021764878 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.0004239766 0.00022875494 0.00064442767 0.00037138865 0.00014727181\n",
      "Training Dynamics Ensemble - Epoch #377:Train loss: 6.9482696e-05 4.6858546e-05 8.468803e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020870232 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042427107 0.00022775232 0.00064484746 0.00037140434 0.00014763881\n",
      "Training Dynamics Ensemble - Epoch #378:Train loss: 6.94827e-05 4.581556e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00021858957 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042455082 0.00022729418 0.00064524624 0.00037141924 0.00014798746\n",
      "Training Dynamics Ensemble - Epoch #379:Train loss: 6.9482696e-05 4.4500575e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00021044986 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042481656 0.00022645196 0.0006456251 0.0003714334 0.00014831868\n",
      "Training Dynamics Ensemble - Epoch #380:Train loss: 6.9482696e-05 4.3059357e-05 8.468803e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.0002089445 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042506904 0.00022557659 0.000645985 0.00037144683 0.00014863333\n",
      "Training Dynamics Ensemble - Epoch #381:Train loss: 6.948269e-05 4.1879746e-05 8.4688036e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.0002063332 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042530888 0.00022461443 0.0006463269 0.0003714596 0.00014893226\n",
      "Training Dynamics Ensemble - Epoch #382:Train loss: 6.9482696e-05 4.13233e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020644271 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042553674 0.00022370585 0.0006466517 0.00037147175 0.00014921624\n",
      "Training Dynamics Ensemble - Epoch #383:Train loss: 6.94827e-05 4.0975374e-05 8.468803e-05 0.00014285029 6.39235e-05, Valid Loss: 0.00042986596 0.00020945327 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042575318 0.00022299321 0.0006469603 0.00037148327 0.00014948602\n",
      "Training Dynamics Ensemble - Epoch #384:Train loss: 6.9482696e-05 4.0857365e-05 8.4688036e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.0002043742 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.0004259588 0.00022206226 0.0006472534 0.0003714942 0.0001497423\n",
      "Training Dynamics Ensemble - Epoch #385:Train loss: 6.94827e-05 4.0777104e-05 8.4688036e-05 0.00014285029 6.39235e-05, Valid Loss: 0.00042986596 0.00020800883 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042615415 0.00022135959 0.0006475319 0.00037150463 0.00014998578\n",
      "Training Dynamics Ensemble - Epoch #386:Train loss: 6.94827e-05 4.0817908e-05 8.468802e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020260796 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042633974 0.000220422 0.00064779643 0.00037151453 0.00015021708\n",
      "Training Dynamics Ensemble - Epoch #387:Train loss: 6.9482696e-05 4.104194e-05 8.4688036e-05 0.00014285033 6.39235e-05, Valid Loss: 0.00042986596 0.00021497214 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042651605 0.00022014952 0.0006480478 0.00037152393 0.00015043681\n",
      "Training Dynamics Ensemble - Epoch #388:Train loss: 6.94827e-05 4.1952586e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020353995 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042668355 0.00021931904 0.00064828654 0.00037153286 0.00015064556\n",
      "Training Dynamics Ensemble - Epoch #389:Train loss: 6.9482696e-05 4.274057e-05 8.4688036e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.00021213974 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042684266 0.00021896008 0.0006485134 0.00037154133 0.00015084387\n",
      "Training Dynamics Ensemble - Epoch #390:Train loss: 6.948269e-05 4.3773936e-05 8.468803e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020027452 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042699382 0.0002180258 0.00064872886 0.0003715494 0.00015103226\n",
      "Training Dynamics Ensemble - Epoch #391:Train loss: 6.94827e-05 4.4797547e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00021626617 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042713742 0.00021793782 0.0006489336 0.00037155705 0.00015121124\n",
      "Training Dynamics Ensemble - Epoch #392:Train loss: 6.9482696e-05 4.544528e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020142454 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042727383 0.00021711215 0.00064912805 0.00037156433 0.00015138126\n",
      "Training Dynamics Ensemble - Epoch #393:Train loss: 6.948269e-05 4.565855e-05 8.468802e-05 0.00014285029 6.39235e-05, Valid Loss: 0.00042986596 0.0002113188 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042740343 0.00021682247 0.0006493128 0.00037157122 0.00015154279\n",
      "Training Dynamics Ensemble - Epoch #394:Train loss: 6.9482696e-05 4.508127e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00019800548 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042752654 0.00021588162 0.0006494883 0.00037157777 0.00015169624\n",
      "Training Dynamics Ensemble - Epoch #395:Train loss: 6.948269e-05 4.3899978e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020923263 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.0004276435 0.00021554917 0.00064965506 0.000371584 0.00015184202\n",
      "Training Dynamics Ensemble - Epoch #396:Train loss: 6.94827e-05 4.1700816e-05 8.468803e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.00019808499 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042775462 0.00021467597 0.00064981345 0.0003715899 0.00015198051\n",
      "Training Dynamics Ensemble - Epoch #397:Train loss: 6.9482696e-05 3.9267907e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020457429 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042786018 0.00021417088 0.0006499639 0.00037159552 0.00015211207\n",
      "Training Dynamics Ensemble - Epoch #398:Train loss: 6.94827e-05 3.7208112e-05 8.4688036e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.0001958775 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042796048 0.00021325621 0.0006501069 0.00037160088 0.00015223706\n",
      "Training Dynamics Ensemble - Epoch #399:Train loss: 6.9482696e-05 3.544079e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00019892822 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042805573 0.0002125398 0.00065024267 0.00037160594 0.00015235579\n",
      "Training Dynamics Ensemble - Epoch #400:Train loss: 6.9482696e-05 3.4323864e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00019632615 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042814625 0.00021172912 0.0006503717 0.00037161077 0.00015246858\n",
      "Training Dynamics Ensemble - Epoch #401:Train loss: 6.9482696e-05 3.3551907e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00019591069 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042823222 0.00021093819 0.0006504943 0.00037161534 0.00015257574\n",
      "Training Dynamics Ensemble - Epoch #402:Train loss: 6.94827e-05 3.3000582e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00019489389 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042831388 0.00021013597 0.0006506108 0.0003716197 0.00015267754\n",
      "Training Dynamics Ensemble - Epoch #403:Train loss: 6.94827e-05 3.275418e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00019268805 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042839147 0.00020926357 0.00065072137 0.00037162384 0.00015277426\n",
      "Training Dynamics Ensemble - Epoch #404:Train loss: 6.9482696e-05 3.261085e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00019713622 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.0004284652 0.0002086572 0.00065082643 0.00037162777 0.00015286614\n",
      "Training Dynamics Ensemble - Epoch #405:Train loss: 6.9482696e-05 3.2753924e-05 8.4688036e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00019219975 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042853522 0.00020783432 0.00065092626 0.0003716315 0.00015295342\n",
      "Training Dynamics Ensemble - Epoch #406:Train loss: 6.94827e-05 3.302377e-05 8.468803e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.0001982768 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042860175 0.00020735645 0.0006510211 0.00037163505 0.00015303634\n",
      "Training Dynamics Ensemble - Epoch #407:Train loss: 6.9482696e-05 3.3894765e-05 8.4688036e-05 0.00014285029 6.39235e-05, Valid Loss: 0.00042986596 0.00019156103 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042866496 0.00020656668 0.0006511112 0.00037163842 0.0001531151\n",
      "Training Dynamics Ensemble - Epoch #408:Train loss: 6.9482696e-05 3.525421e-05 8.468803e-05 0.0001428503 6.39235e-05, Valid Loss: 0.00042986596 0.00020340025 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.000428725 0.00020640835 0.0006511968 0.00037164162 0.00015318993\n",
      "Training Dynamics Ensemble - Epoch #409:Train loss: 6.9482696e-05 3.7123467e-05 8.4688036e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.00019229334 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042878205 0.0002057026 0.0006512781 0.00037164465 0.00015326102\n",
      "Training Dynamics Ensemble - Epoch #410:Train loss: 6.948269e-05 3.9739545e-05 8.4688036e-05 0.00014285032 6.39235e-05, Valid Loss: 0.00042986596 0.00020645568 0.00065282313 0.00037170242 0.00015461173,  Moving Avg Valid Loss: 0.00042883624 0.00020574025 0.00065135537 0.00037164753 0.00015332855\n",
      "Stopping Training of Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 10:36:43,849\tINFO trainable.py:159 -- Trainable.setup took 30.261 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-08-18 10:36:43,851\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer trained: 1 Epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer trained: 2 Epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer trained: 3 Epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer trained: 4 Epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n",
      "/Users/felix/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/mbmpo/utils.py:36: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  self._coeffs = np.linalg.lstsq(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer trained: 5 Epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = MBMPOTrainer(\n",
    "    config=config,\n",
    "    env=\"ray.rllib.examples.env.mbmpo_env.CartPoleWrapper\")\n",
    "\n",
    "env = CartPoleWrapper()\n",
    "#env = gym.make('LunarL')\n",
    "#env.render()\n",
    "# run until episode ends\n",
    "# list that lists all actions\n",
    "iteration_list=[]\n",
    "epoch_nr=0\n",
    "for _ in range(5):\n",
    "    epoch_nr+=1\n",
    "    with suppress_stdout():\n",
    "        trainer.train()\n",
    "    print(f\"trainer trained: {epoch_nr} Epochs\")\n",
    "    trainer.save(\"/Users/felix/sciebo/masterarbeit/progra/model-based_rl/mbmpo_check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.0\n"
     ]
    }
   ],
   "source": [
    "env = CartPoleWrapper()\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "while not done:\n",
    "    action = trainer.compute_action(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    env.render()\n",
    "env.close()\n",
    "print(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    analysis=tune.run(\n",
    "        \"MBMPO\",\n",
    "        local_dir=\"mbmpo_check\",\n",
    "        stop={\"training_iteration\": 1},\n",
    "        checkpoint_freq = 1,\n",
    "        max_failures=0,\n",
    "        config=config,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.contrib.alpha_zero.core.alpha_zero_trainer import AlphaZeroTrainer\n",
    "from ray.rllib.policy.sample_batch import DEFAULT_POLICY_ID\n",
    "from ray.rllib.policy.policy_map import PolicyMap\n",
    "from ray.rllib.evaluation.episode import MultiAgentEpisode\n",
    "\n",
    "agent = AlphaZeroTrainer (env = CartPole, config = config)\n",
    "env=CartPole()\n",
    "agent.restore ('tune_check/contrib/AlphaZero/contrib_AlphaZero_CartPole_dede1_00000_0_2022-08-17_20-46-14/checkpoint_000040/checkpoint-40')\n",
    "\n",
    "reward_list=[]\n",
    "for i in range(20):\n",
    "    obs = env.reset()\n",
    "    policy = agent.get_policy(DEFAULT_POLICY_ID)\n",
    "    episode = MultiAgentEpisode(\n",
    "        PolicyMap(0,0),\n",
    "        lambda _, __: DEFAULT_POLICY_ID,\n",
    "        lambda: None,\n",
    "        lambda _: None,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    episode.user_data['initial_state'] = env.get_state()\n",
    "\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _, _ = policy.compute_single_action(obs, episode=episode)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        #print(reward)\n",
    "        #env.render()\n",
    "        #time.sleep(0.1)\n",
    "        episode.length += 1\n",
    "        \n",
    "    reward_list.append(reward)\n",
    "    print(f\"episode {i} finished\")\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(reward_list,'bs')\n",
    "plt.ylabel('gained reward')\n",
    "plt.xlabel('runs')\n",
    "plt.title('AlphaZero reward in Cartpole Environment over different runs checkpoint_40')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76fe728b8cb1294c4ac65d2fab506d621708da3fbbfb70b14417e3341c6f7935"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}