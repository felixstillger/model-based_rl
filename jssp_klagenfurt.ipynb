{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import JSSEnv # an ongoing issue with OpenAi's gym causes it to not import automatically external modules, see: https://github.com/openai/gym/issues/2809\n",
    "from wrapper.jssp_wrapper_klagenfurt import jssp_klagenfurt_obs_wrapper\n",
    "from ray.rllib.contrib.alpha_zero.core.alpha_zero_trainer import AlphaZeroTrainer\n",
    "import gym\n",
    "from ray import tune\n",
    "from ray.rllib.contrib.alpha_zero.models.custom_torch_models import DenseModel\n",
    "from ray.rllib.models.catalog import ModelCatalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.tune.registry import register_env\n",
    "import JSSEnv\n",
    "# Configure the algorithm.\n",
    "def env_creator(env_config):\n",
    "    import JSSEnv\n",
    "    env = jssp_klagenfurt_obs_wrapper(gym.make('jss-v1', env_config={'instance_path': 'resources/jsp_instances/standard/abz8.txt'}))\n",
    "    return env\n",
    "\n",
    "# use tune to register the custom environment for the ppo trainer\n",
    "register_env('jssp_klagenfurt',env_creator)\n",
    "\n",
    "config = {\n",
    "    \"env\": \"jssp_klagenfurt\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 1,\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"tf\",\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    #\"horizon\":1,\n",
    "    \"evaluation_duration\":10,\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": True,\n",
    "    },\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = PPOTrainer(config=config)\n",
    "import time\n",
    "\n",
    "print(\"start training\")\n",
    "for _ in range(0,200):\n",
    "    tmp=time.time()\n",
    "    trainer.train()\n",
    "    print(f\"training iteration {_} finished after {time.time() - tmp} seconds\")\n",
    "    trainer.save_checkpoint(f\"training_checkpoints/checkpoints_ppo_jsp_klagenfurt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 7)\n"
     ]
    }
   ],
   "source": [
    "env = env_creator('test')\n",
    "\n",
    "print(env.observation_space['obs'].shape)\n",
    "print(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_reward = 0\n",
    "env = env_creator('test')\n",
    "\n",
    "done = False\n",
    "obs = env.reset()\n",
    "iterations=0\n",
    "env.render()\n",
    "while not done:\n",
    "    print(f\"start with {iterations} iteration and episode reward {episode_reward}\")\n",
    "    action = trainer.compute_action(obs)\n",
    "    #print(f\"action: {action}\")\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    env.render()\n",
    "    iterations += 1\n",
    "env.render()\n",
    "env.close()\n",
    "print(episode_reward)\n",
    "print(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(obs)\n",
    "print(obs['action_mask'][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_agent=True\n",
    "config = {\n",
    "    \"framework\": \"torch\",\n",
    "    \"disable_env_checking\":False,\n",
    "    \"num_workers\"       : 4,\n",
    "    \"rollout_fragment_length\": 50,\n",
    "    \"train_batch_size\"  : 500,\n",
    "    \"sgd_minibatch_size\": 64,\n",
    "    \"lr\"                : 0.0001,\n",
    "    \"num_sgd_iter\"      : 1,\n",
    "    \"mcts_config\"       : {\n",
    "        \"puct_coefficient\"   : 1.5,\n",
    "        \"num_simulations\"    : 100,\n",
    "        \"temperature\"        : 1.0,\n",
    "        \"dirichlet_epsilon\"  : 0.20,\n",
    "        \"dirichlet_noise\"    : 0.03,\n",
    "        \"argmax_tree_policy\" : False,\n",
    "        \"add_dirichlet_noise\": True,\n",
    "    },\n",
    "    \"ranked_rewards\"    : {\n",
    "        \"enable\": True,\n",
    "    },\n",
    "    \"model\"             : {\n",
    "        \"custom_model\": \"dense_model\",\n",
    "\n",
    "    },\n",
    "}\n",
    "\n",
    "def env_creator(config):\n",
    "    import JSSEnv\n",
    "    env = jssp_klagenfurt_obs_wrapper(gym.make('jss-v1', env_config={'instance_path': 'resources/jsp_instances/standard/abz8.txt'}))\n",
    "    return env\n",
    "\n",
    "ModelCatalog.register_custom_model(\"dense_model\", DenseModel)    \n",
    "tune.register_env('jssp_klagenfurt',env_creator)\n",
    "\n",
    "agent = AlphaZeroTrainer( config=config, env='jssp_klagenfurt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "if train_agent:\n",
    "    print(\"start training\")\n",
    "    for _ in range(0,1):\n",
    "        tmp=time.time()\n",
    "        agent.train()\n",
    "        print(f\"training iteration {_} finished after {time.time() - tmp} seconds\")\n",
    "        #agent.save(f\"save_az/rllib_checkpoint{_}\")\n",
    "        agent.save_checkpoint(f\"training_checkpoints/checkpoints_az_jsp_klagenfurt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "legal_action=state['action_mask']\n",
    "action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "new_state, reward, done, info=env.step(action)\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "finished_after=[]\n",
    "for j in range(1):\n",
    "    state=env.reset()\n",
    "    for i in range(9999):\n",
    "        legal_action=state['action_mask']\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        state, reward, done, info=env.step(action)\n",
    "        if done==True:\n",
    "            print(f\"finished! no legal actions possible after {i} steps\")\n",
    "            finished_after.append(i)\n",
    "            break\n",
    "\n",
    "        #sleep(1)\n",
    "import time\n",
    "env.render()\n",
    "x=time.time()\n",
    "env_tmp=copy.deepcopy(env)\n",
    "y=time.time()\n",
    "print(y-x)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished_after.sort()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(finished_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('customjssp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7344f7b5995cbf62a990a56ee6eec8bd53f41a3aff848cd18f1feb05905aa9e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
