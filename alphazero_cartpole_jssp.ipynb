{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "2\n",
      "(4, 0)\n",
      "(4, 2)\n",
      "(4, 0)\n",
      "3\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "[0. 1. 1. 1. 0. 0.]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from wrapper.taxi_wrapper import discretetobox\n",
    "env=discretetobox(gym.make('Taxi-v3'))\n",
    "state=env.reset()\n",
    "\n",
    "taxi_row, taxi_col, pass_loc, dest_idx = env.decode(env.s)\n",
    "print(taxi_row)\n",
    "print(taxi_col)\n",
    "print(pass_loc)\n",
    "print(env.locs[pass_loc])\n",
    "print((taxi_row,taxi_col))\n",
    "print(env.locs[pass_loc])\n",
    "print(dest_idx)\n",
    "env.render()\n",
    "print(state['action_mask'])\n",
    "\"\"\"\n",
    "    - 0: move south\n",
    "    - 1: move north\n",
    "    - 2: move east\n",
    "    - 3: move west\n",
    "    - 4: pickup passenger\n",
    "    - 5: drop off passenger\n",
    "\"\"\"\n",
    "print(True) if (taxi_row,taxi_col) == env.locs[pass_loc] else print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import rllib, tune\n",
    "from ray.rllib.contrib.alpha_zero.core.alpha_zero_trainer import AlphaZeroTrainer\n",
    "from ray.rllib.policy.sample_batch import DEFAULT_POLICY_ID\n",
    "from ray.rllib.policy.policy_map import PolicyMap\n",
    "from ray.rllib.evaluation.episode import MultiAgentEpisode\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.contrib.alpha_zero.environments.cartpole import CartPole\n",
    "from ray.rllib.contrib.alpha_zero.models.custom_torch_models import DenseModel\n",
    "from ray.rllib.models.catalog import ModelCatalog\n",
    "from wrapper.jssp_wrapper import Jssp_wrapper\n",
    "import gym\n",
    "from wrapper.taxi_wrapper import discretetobox\n",
    "#from wrapper.taxi_wrapper import TaxiTaxi\n",
    "ModelCatalog.register_custom_model(\"dense_model\", DenseModel)\n",
    "register_env(\"CartPoleEnv\", lambda _: CartPole())\n",
    "register_env(\"JsspEnv\", lambda _: Jssp_wrapper())\n",
    "register_env(\"Taxi-v3\", lambda _:discretetobox())\n",
    "#register_env(\"Taxi-v3\", lambda _:TaxiTaxi())\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "config = {\n",
    "    \"framework\": \"torch\",\n",
    "    \"disable_env_checking\":True,\n",
    "    \"num_workers\"       : 6,\n",
    "    \"rollout_fragment_length\": 50,\n",
    "    \"train_batch_size\"  : 500,\n",
    "    \"sgd_minibatch_size\": 64,\n",
    "    \"lr\"                : 0.0001,\n",
    "    \"num_sgd_iter\"      : 1,\n",
    "    \"mcts_config\"       : {\n",
    "        \"puct_coefficient\"   : 1.5,\n",
    "        \"num_simulations\"    : 100,\n",
    "        \"temperature\"        : 1.0,\n",
    "        \"dirichlet_epsilon\"  : 0.20,\n",
    "        \"dirichlet_noise\"    : 0.03,\n",
    "        \"argmax_tree_policy\" : False,\n",
    "        \"add_dirichlet_noise\": True,\n",
    "    },\n",
    "    \"ranked_rewards\"    : {\n",
    "        \"enable\": True,\n",
    "    },\n",
    "    \"model\"             : {\n",
    "        \"custom_model\": \"dense_model\",\n",
    "\n",
    "    },\n",
    "}\n",
    "\n",
    "def env_creator(env_config):\n",
    "    env = discretetobox(gym.make(\"Taxi-v3\"))\n",
    "    #env = gym.make('LunarLander-v2')\n",
    "    return env\n",
    "\n",
    "# use tune to register the custom environment for the ppo trainer\n",
    "tune.register_env('TaxiTaxi',env_creator)\n",
    "\n",
    "#env = discretetobox(gym.make(\"Taxi-v3\"))\n",
    "#env2 = CartPole()\n",
    "\n",
    "#print(env2.observation_space)\n",
    "\n",
    "#print(env2.env.observation_space)\n",
    "\n",
    "\n",
    "\n",
    "#print(env.observation_space['obs'])\n",
    "\n",
    "#print(env.env.observation_space)\n",
    "\n",
    "\n",
    "#tmp=(env.observation_space['action_mask'])\n",
    "#tmp2=(env2.observation_space['action_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 20:38:47,848\tWARNING deprecation.py:46 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "2022-08-27 20:38:47,855\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2022-08-27 20:39:18,839\tINFO trainable.py:159 -- Trainable.setup took 30.993 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_path = analysis.get_last_checkpoint() or args.checkpoint\n",
    "\n",
    "#agent = AlphaZeroTrainer(env=Jssp_wrapper, config=config)\n",
    "#agent = AlphaZeroTrainer( config=config,env=CartPole)\n",
    "agent = AlphaZeroTrainer( config=config, env='TaxiTaxi')\n",
    "#agent = AlphaZeroTrainer( config=config, env=TaxiTaxi)\n",
    "# use string number to restore\n",
    "# nr_restore=\"10\"\n",
    "#checkpoint_path=f'checkpoints_az/rllib_checkpoint{nr_restore}/checkpoint_{nr_restore.zfill(6)}/checkpoint-{nr_restore}'\n",
    "#agent.load_checkpoint(\"checkpoints_az/rllib_checkpoint1\")\n",
    "#print(\"awd\")\n",
    "#agent.restore(\"checkpoints_az/rllib_checkpoint1/checkpoint_000001/checkpoint-1\")\n",
    "agent.load_checkpoint(\"checkpoint-10\")\n",
    "print(\"start training\")\n",
    "for _ in range(0,0):\n",
    "    agent.train()\n",
    "    print(f\"training iteration {_} finished\")\n",
    "    #agent.save(f\"save_az/rllib_checkpoint{_}\")\n",
    "    agent.save_checkpoint(f\"training_checkpoints/checkpoints_az_taxi\")\n",
    "    #agent.save_to_object(f\"objects_az/rllib_checkpoint{_}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray 1.13.0 ezpip uninstall -y ray\n",
    "#agent = AlphaZeroTrainer( config=config,env=CartPole)\n",
    "#agent.load_checkpoint(\"checkpoints_az/checkpoint-0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "3\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "199\n",
      "-200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "policy = agent.get_policy(DEFAULT_POLICY_ID)\n",
    "\n",
    "#env = CartPole()\n",
    "#env = Jssp_wrapper()\n",
    "env = discretetobox(gym.make(\"Taxi-v3\"))\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "episode = MultiAgentEpisode(\n",
    "    PolicyMap(0,0),\n",
    "    lambda _, __: DEFAULT_POLICY_ID,\n",
    "    lambda: None,\n",
    "    lambda _: None,\n",
    "    0,\n",
    ")\n",
    "\n",
    "episode.user_data['initial_state'] = env.get_state()\n",
    "\n",
    "\n",
    "action, _, _ = policy.compute_single_action(obs, episode=episode)\n",
    "print(action)\n",
    "obs, reward, done, _ = env.step(action)\n",
    "\n",
    "\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _, _ = policy.compute_single_action(obs, episode=episode)\n",
    "    print(action)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    #print(obs)\n",
    "    #env.render()\n",
    "    #time.sleep(0.1)\n",
    "    episode.length += 1\n",
    "\n",
    "print(episode.length)\n",
    "print(reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('customjssp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7344f7b5995cbf62a990a56ee6eec8bd53f41a3aff848cd18f1feb05905aa9e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
