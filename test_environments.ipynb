{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "t=np.empty((4,1),dtype=object)\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import dummy\n",
    "import numpy as np\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "t=np.empty((4,1),dtype=object)\n",
    "import time\n",
    "import os\n",
    "from random import randrange\n",
    "env=jss_lite(instance_path='resources/jsp_instances/standard/ft06.txt')\n",
    "state=env.get_state()\n",
    "\n",
    "env.set_state(state)\n",
    "token=False\n",
    "for _ in range(1):\n",
    "    state=env.reset()\n",
    "    #print(state)\n",
    "    done=False\n",
    "    i=0\n",
    "    #print(state['obs'].shape)\n",
    "    #for i in range(150):\n",
    "    dummy_counter=0\n",
    "    #print(env.get_legal_actions(state))\n",
    "    while not done:\n",
    "        i+=1\n",
    "        legal_action=env.get_legal_actions(state)\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        #action=randrange(env.action_space.n)\n",
    "        #print(action)\n",
    "        if action < env.action_space.n/2:\n",
    "    \n",
    "\n",
    "            #print(\"before:\")\n",
    "            #env.render(start_count=1,x_bar=\"Job\",y_bar=\"Machine\")\n",
    "            state, reward, done, info=env.step(action)\n",
    "            if token==True:\n",
    "                token=False\n",
    "               # env.render()\n",
    "            #print(state['obs'].shape)\n",
    "\n",
    "        else:\n",
    "            dummy_counter+=1\n",
    "            #print(\"dummy action\")\n",
    "            #env.render()\n",
    "            #print(action)\n",
    "            #print(i)\n",
    "            print(env.get_legal_actions(\"obs\"))\n",
    "            #env.render()\n",
    "            state, reward, done, info=env.step(action)  \n",
    "\n",
    "            #print(state['obs'].shape)\n",
    "            token=True\n",
    "                #print(\"after:\")\n",
    "                #env.render(start_count=1,x_bar=\"Job\",y_bar=\"Machine\")\n",
    "        #print(action)\n",
    "        #tmp=(env.processed_and_max_time_job_matrix)\n",
    "        #print(env.count_finished_tasks_machine_matrix)\n",
    "        #print(env.production_list)\n",
    "        #print(state)\n",
    "        #env.render()\n",
    "        if done==True:\n",
    "            print(f\"finished! no legal actions possible after {i+1} steps\")\n",
    "            #print(env.timestemp_list)\n",
    "            break\n",
    "    print(dummy_counter)\n",
    "    #env.render(start_count=1,x_bar=\"Job\",y_bar=\"Machine\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dummy_counter)\n",
    "env.render(start_count=1,x_bar=\"Job\",y_bar=\"Machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.production_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(env.production_list[1,1])==tuple)\n",
    "for entry in env.production_list:\n",
    "    for p in (entry):\n",
    "        print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.processed_and_max_time_job_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "x_bar=\"Machine\"\n",
    "y_bar=\"Job\"\n",
    "df.sort_values(inplace=True,by=\"Job\")\n",
    "fig = px.timeline(df, x_start=\"Start\", x_end=\"Finish\", color=x_bar, y=y_bar)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action)\n",
    "\n",
    "print(env.get_legal_actions(state))\n",
    "print(env.job_machine_matrix[action,env.count_finished_tasks_job_matrix[action]])\n",
    "cur_machine=env.current_machines_status\n",
    "job_ma=env.job_machine_matrix\n",
    "print(env.count_finished_tasks_job_matrix[action])\n",
    "#print(env.current_machines_status[env.job_machine_matrix[action,env.count_finished_tasks_job_matrix[action]],:])\n",
    "#print(env.job_machine_matrix[action,env.count_finished_tasks_job_matrix[action]])\n",
    "#print(env.current_machines_status)\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ale_py as ale\n",
    "ale.importroms('/Users/felix/sciebo/masterarbeit/progra/model-based_rl/roms/Space Invaders.bin')\n",
    "import gym\n",
    "env = gym.make('SpaceInvaders-v4')\n",
    "env.reset()\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import JSSEnv\n",
    "import src.jss_graph_env.disjunctive_graph_jss_env as jss_env\n",
    "from wrapper.jssplight_wrapper import jssp_light_obs_wrapper_multi_instances\n",
    "\n",
    "import src.jsp_instance_parser \n",
    "import time\n",
    "import gym\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "\n",
    "index=['klagenfurt','alex','lite']\n",
    "df=pd.DataFrame(np.zeros((3,5)),columns=['setuptime','resettime','50xactiontime','col4','col5'],index=index)\n",
    "#df=pd.DataFrame\n",
    "#df.set_index('index')\n",
    "for i in range(100):\n",
    "\n",
    "    def timer(innerfun):\n",
    "        tmp_t=time.time()\n",
    "        tmp_r=innerfun()\n",
    "        return time.time()-tmp_t,tmp_r\n",
    "\n",
    "    tmp_t=time.time()\n",
    "    env2=gym.make('jss-v1', env_config={'instance_path': 'resources/jsp_instances/standard/dmu79.txt'})\n",
    "    t_1=(time.time()-tmp_t)\n",
    "    df['setuptime']['klagenfurt']+=t_1/100\n",
    "    tmp_t=time.time()\n",
    "    instance_list=['resources/jsp_instances/standard/ft06.txt','resources/jsp_instances/standard/ft10.txt','resources/jsp_instances/standard/ft20.txt','resources/jsp_instances/standard/abz5.txt','resources/jsp_instances/standard/abz6.txt','resources/jsp_instances/standard/abz7.txt']\n",
    "#instance_list=['resources/jsp_instances/standard/ft06.txt']\n",
    "    env_3=jssp_light_obs_wrapper_multi_instances(instances_list=instance_list)\n",
    "    #env_3=jss_lite(instance_path='resources/jsp_instances/standard/dmu79.txt')\n",
    "    t_1=time.time()-tmp_t\n",
    "    df['setuptime']['lite']+=t_1/100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tmp_t=time.time()\n",
    "    path='resources/jsp_instances/standard/dmu79.txt'\n",
    "    curr_instance=src.jsp_instance_parser.parse_jps_standard_specification(path)\n",
    "    res,std_matrix=curr_instance\n",
    "    env_alex = jss_env.DisjunctiveGraphJssEnv(res,default_visualisations='gantt_console')\n",
    "    t_2=(time.time()-tmp_t)\n",
    "    df['setuptime']['alex']+=t_2/100\n",
    "    tmp_t=time.time()\n",
    "    t=env2.reset()\n",
    "    t_1=(time.time()-tmp_t)\n",
    "    df['resettime']['klagenfurt']+=t_1/100\n",
    "    tmp_t=time.time()\n",
    "    t2=env_alex.reset()\n",
    "    t_2=(time.time()-tmp_t)\n",
    "    df['resettime']['alex']+=t_2/100\n",
    "    tmp_t=time.time()\n",
    "    t=env_3.reset()\n",
    "    t_1=(time.time()-tmp_t)\n",
    "    df['resettime']['lite']+=t_1/100\n",
    "\n",
    "\n",
    "    state=env2.reset()\n",
    "    for i in range(50):\n",
    "        legal_action=state['action_mask']\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        tmp_t=time.time()\n",
    "        state, reward, done, info=env2.step(action)\n",
    "        t_1=(time.time()-tmp_t)\n",
    "        df['50xactiontime']['klagenfurt']+=t_1/50\n",
    "\n",
    "        if done==True:\n",
    "            print(f\"finished! no legal actions possible after {i} steps\")\n",
    "            break\n",
    "    state=env_3.reset()\n",
    "    for i in range(50):\n",
    "        legal_action=env_3.get_legal_actions()\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        tmp_t=time.time()\n",
    "        state, reward, done, info=env_3.step(action)\n",
    "        t_1=(time.time()-tmp_t)\n",
    "        df['50xactiontime']['lite']+=t_1/50\n",
    "\n",
    "        if done==True:\n",
    "            print(f\"finished! no legal actions possible after {i} steps\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "    action_list=np.arange(0,env_alex.n_jobs*env_alex.n_machines)\n",
    "    for i in range(50):\n",
    "        action_mask=env_alex.valid_action_mask()\n",
    "        actions=action_list[action_mask]\n",
    "        next_action=random.choice(actions)\n",
    "        #next_action=actions[action_mask[0]]\n",
    "        #print(next_action)\n",
    "        tmp_t=time.time()\n",
    "        state,reward,done,info =env_alex.step(next_action)\n",
    "        t_2=(time.time()-tmp_t)\n",
    "        df['50xactiontime']['alex']+=t_2/50\n",
    "        if done == True:\n",
    "            print(f\"finished after {i} steps\")\n",
    "            break\n",
    "        #env.render()\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.jss_lite.jss_lite import jss_lite\n",
    "import time\n",
    "env_3=jss_lite(instance_path='resources/jsp_instances/standard/dmu79.txt')\n",
    "\n",
    "state=env_3.reset()\n",
    "t=time.time()\n",
    "legal_action=env_3.get_legal_actions()\n",
    "print((time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "legal_action=env_3.get_legal_actions(state)\n",
    "print((time.time()-t)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_3=jss_lite(instance_path='resources/jsp_instances/standard/dmu80.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "instance_path = \"/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/ft06.txt\"\n",
    "ins=instance_path.replace('/', ' ').split(' ')[-1].split('.')[-2]\n",
    "\n",
    "df=pd.read_csv('resources/jps_instances_metadata/instances_metadata.csv',index_col='Unnamed: 0')\n",
    "print(df['Optimal value'][ins])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.jssplight_wrapper import jssp_light_obs_wrapper_multi_instances\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "import numpy as np\n",
    "#env=jss_lite(instance_path='resources/jsp_instances/standard/ft06.txt')\n",
    "#print(env.observation_space)\n",
    "#state=env.reset()\n",
    "\n",
    "#legal_action_old=state['action_mask']\n",
    "#instance_list=['resources/jsp_instances/standard/ft06.txt','resources/jsp_instances/standard/ft10.txt','resources/jsp_instances/standard/ft20.txt','resources/jsp_instances/standard/abz5.txt','resources/jsp_instances/standard/abz6.txt','resources/jsp_instances/standard/abz7.txt']\n",
    "p1='/Users/felix/sciebo/masterarbeit/progra/model-based_rl'\n",
    "instance_list=['/resources/jsp_instances/standard/la01.txt','/resources/jsp_instances/standard/la02.txt','/resources/jsp_instances/standard/la03.txt','/resources/jsp_instances/standard/la04.txt','/resources/jsp_instances/standard/la05.txt']\n",
    "instance_list=[p1 + s for s in instance_list]\n",
    "#instance_list=['resources/jsp_instances/standard/ft06.txt']\n",
    "env=jssp_light_obs_wrapper_multi_instances(instances_list=instance_list)\n",
    "reward=0\n",
    "while reward < 96:\n",
    "    done=False\n",
    "    state=env.reset()\n",
    "    #print(state['obs'])\n",
    "    i=0\n",
    "    while not done:\n",
    "        legal_action=state['action_mask']\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        state, reward, done, info=env.step(action)\n",
    "        i+=1\n",
    "        if done==True:\n",
    "            #print(f\"finished! no legal actions possible after {i} steps\")\n",
    "            break\n",
    "\n",
    "env.render()\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((env.env.current_timestep))\n",
    "print(env.env.optimal_value)\n",
    "print((env.env.current_timestep-env.env.optimal_value)/env.env.optimal_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import restore\n",
    "\n",
    "\n",
    "training_folder='/Users/felix/sciebo/masterarbeit/progra/model-based_rl/training_checkpoints/checkpoints_tune/contrib/AlphaZero/contrib_AlphaZero_custom_jssp_f8da7_00000_0_2022-10-07_11-11-05'\n",
    "for f in os.listdir(training_folder):\n",
    "    if 'checkpoint' in f:\n",
    "        restore_path=training_folder+'/'+f+'/checkpoint-'+str(int(f[-6:]))\n",
    "        if os.path.exists(restore_path):\n",
    "            print(restore_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.env.optimal_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=[1,2,3,4,5]\n",
    "x=np.zeros(2)\n",
    "y=np.zeros(2)\n",
    "print([*x,*y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#print(os.path.dirname(__file__))\n",
    "p1='/Users/felix/sciebo/masterarbeit/progra/model-based_rl'\n",
    "instance_list=['/resources/jsp_instances/standard/la01.txt','/resources/jsp_instances/standard/la02.txt','/resources/jsp_instances/standard/la03.txt','/resources/jsp_instances/standard/la04.txt','/resources/jsp_instances/standard/la05.txt']\n",
    "instance_list=[p1 + s for s in instance_list]\n",
    "print(instance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 18:28:14,434\tWARNING deprecation.py:46 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "2022-10-19 18:28:44,064\tINFO trainable.py:159 -- Trainable.setup took 29.631 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-10-19 18:28:44,136\tWARNING deprecation.py:46 -- DeprecationWarning: `MultiAgentEpisode` has been deprecated. Use `ray.rllib.evaluation.episode.Episode` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_000032\n",
      "agent loaded\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la01.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la02.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la03.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la04.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la05.txt\n",
      "run: 1 of 49 evaluated\n",
      "checkpoint_000035\n",
      "agent loaded\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la01.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la02.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la03.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la04.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la05.txt\n",
      "run: 2 of 49 evaluated\n",
      "checkpoint_000003\n",
      "agent loaded\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la01.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la02.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la03.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la04.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la05.txt\n",
      "run: 3 of 49 evaluated\n",
      "checkpoint_000004\n",
      "agent loaded\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la01.txt\n",
      "/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/la02.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb Zelle 32\u001b[0m in \u001b[0;36m<cell line: 118>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m \u001b[39mfor\u001b[39;00m instance \u001b[39min\u001b[39;00m instance_list:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m     \u001b[39mprint\u001b[39m(instance)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m     eval_sheet[\u001b[39mstr\u001b[39m(f[\u001b[39m-\u001b[39m\u001b[39m6\u001b[39m:]),instance]\u001b[39m=\u001b[39meval_env(agent,jssp_light_obs_wrapper_multi_instances(instances_list\u001b[39m=\u001b[39;49m[instance]))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m run\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrun: \u001b[39m\u001b[39m{\u001b[39;00mrun\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mnr_checkpoints\u001b[39m}\u001b[39;00m\u001b[39m evaluated\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb Zelle 32\u001b[0m in \u001b[0;36meval_env\u001b[0;34m(agent, env)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m start_time\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     action, _, _ \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mcompute_single_action(state, episode\u001b[39m=\u001b[39;49mepisode)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m#print(episode_length)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m#print(f\"action:{action}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     \u001b[39m#print(f\"action_mask {state['action_mask']}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39m#print(f\"action mask of action:{state['action_mask'][action]}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/test_environments.ipynb#X43sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/policy/policy.py:255\u001b[0m, in \u001b[0;36mPolicy.compute_single_action\u001b[0;34m(self, obs, state, prev_action, prev_reward, info, input_dict, episode, explore, timestep, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m episode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     episodes \u001b[39m=\u001b[39m [episode]\n\u001b[0;32m--> 255\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_actions_from_input_dict(\n\u001b[1;32m    256\u001b[0m     input_dict\u001b[39m=\u001b[39;49mSampleBatch(input_dict),\n\u001b[1;32m    257\u001b[0m     episodes\u001b[39m=\u001b[39;49mepisodes,\n\u001b[1;32m    258\u001b[0m     explore\u001b[39m=\u001b[39;49mexplore,\n\u001b[1;32m    259\u001b[0m     timestep\u001b[39m=\u001b[39;49mtimestep,\n\u001b[1;32m    260\u001b[0m )\n\u001b[1;32m    262\u001b[0m \u001b[39m# Some policies don't return a tuple, but always just a single action.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m# E.g. ES and ARS.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/alpha_zero_policy.py:97\u001b[0m, in \u001b[0;36mAlphaZeroPolicy.compute_actions_from_input_dict\u001b[0;34m(self, input_dict, explore, timestep, episodes, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     tree_node \u001b[39m=\u001b[39m episode\u001b[39m.\u001b[39muser_data[\u001b[39m\"\u001b[39m\u001b[39mtree_node\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     95\u001b[0m \u001b[39m# run monte carlo simulations to compute the actions\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m# and record the tree\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m mcts_policy, action, tree_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmcts\u001b[39m.\u001b[39;49mcompute_action(tree_node)\n\u001b[1;32m     98\u001b[0m \u001b[39m# record action\u001b[39;00m\n\u001b[1;32m     99\u001b[0m actions\u001b[39m.\u001b[39mappend(action)\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/mcts.py:129\u001b[0m, in \u001b[0;36mMCTS.compute_action\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_action\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[1;32m    128\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_sims):\n\u001b[0;32m--> 129\u001b[0m         leaf \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mselect()\n\u001b[1;32m    130\u001b[0m         \u001b[39mif\u001b[39;00m leaf\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    131\u001b[0m             value \u001b[39m=\u001b[39m leaf\u001b[39m.\u001b[39mreward\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/mcts.py:77\u001b[0m, in \u001b[0;36mNode.select\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mwhile\u001b[39;00m current_node\u001b[39m.\u001b[39mis_expanded:\n\u001b[1;32m     76\u001b[0m     best_action \u001b[39m=\u001b[39m current_node\u001b[39m.\u001b[39mbest_action()\n\u001b[0;32m---> 77\u001b[0m     current_node \u001b[39m=\u001b[39m current_node\u001b[39m.\u001b[39;49mget_child(best_action)\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m current_node\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/mcts.py:88\u001b[0m, in \u001b[0;36mNode.get_child\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mset_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate)\n\u001b[1;32m     87\u001b[0m     obs, reward, done, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m---> 88\u001b[0m     next_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mget_state()\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren[action] \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     90\u001b[0m         state\u001b[39m=\u001b[39mnext_state,\n\u001b[1;32m     91\u001b[0m         action\u001b[39m=\u001b[39maction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m         mcts\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmcts,\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren[action]\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/ranked_rewards.py:65\u001b[0m, in \u001b[0;36mget_r2_env_wrapper.<locals>.RankedRewardsEnvWrapper.get_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m     state \u001b[39m=\u001b[39m {\n\u001b[0;32m---> 65\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39menv_state\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mget_state(),\n\u001b[1;32m     66\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbuffer_state\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr2_buffer\u001b[39m.\u001b[39mget_state(),\n\u001b[1;32m     67\u001b[0m     }\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m deepcopy(state)\n",
      "File \u001b[0;32m~/sciebo/masterarbeit/progra/model-based_rl/wrapper/jssplight_wrapper.py:107\u001b[0m, in \u001b[0;36mjssp_light_obs_wrapper_multi_instances.get_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    106\u001b[0m     \u001b[39m#return deepcopy(self.env),self.observation_padding_size,self.action_mask_padding_size\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m [deepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_padding_size,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_mask_padding_size]\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tracemalloc import start\n",
    "from ray import rllib, tune\n",
    "from ray.rllib.contrib.alpha_zero.core.alpha_zero_trainer import AlphaZeroTrainer\n",
    "from ray.rllib.policy.sample_batch import DEFAULT_POLICY_ID\n",
    "from ray.rllib.policy.policy_map import PolicyMap\n",
    "from ray.rllib.evaluation.episode import MultiAgentEpisode\n",
    "from ray.tune.registry import register_env\n",
    "#from ray.rllib.contrib.alpha_zero.models.custom_torch_models import DenseModel\n",
    "from src.jss_lite.custom_torch_models import DenseModel_activation_relu as DenseModel\n",
    "#from src.jss_lite.custom_torch_models import ConvNetModel\n",
    "from ray.rllib.models.catalog import ModelCatalog\n",
    "import gym\n",
    "#from ray.rllib.contrib.alpha_zero.core.alpha_zero_trainer import AlphaZeroTrainer\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import ray\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ModelCatalog.register_custom_model(\"dense_model\", DenseModel)\n",
    "\n",
    "#curr_dir=(os.path.dirname(__file__))\n",
    "curr_dir='/Users/felix/sciebo/masterarbeit/progra/model-based_rl'\n",
    "instance_list=['/resources/jsp_instances/standard/la01.txt','/resources/jsp_instances/standard/la02.txt','/resources/jsp_instances/standard/la03.txt','/resources/jsp_instances/standard/la04.txt','/resources/jsp_instances/standard/la05.txt']\n",
    "instance_list=[curr_dir + s for s in instance_list]\n",
    "instance_path=curr_dir+'/resources/jsp_instances/standard/ft06.txt'\n",
    "checkpoint_path='/training_checkpoints/checkpoints_tune'\n",
    "\n",
    "from wrapper.jssplight_wrapper import jssp_light_obs_wrapper\n",
    "from wrapper.jssplight_wrapper import jssp_light_obs_wrapper_multi_instances\n",
    "\n",
    "def env_creator(config):\n",
    "    #env = jssp_light_obs_wrapper(jss_lite(instance_path=instance_path))\n",
    "    env=jssp_light_obs_wrapper_multi_instances(instances_list=instance_list)\n",
    "    return env\n",
    "def env_creator_single(instance):\n",
    "    env=jssp_light_obs_wrapper_multi_instances(instances_list=instance)\n",
    "    return env\n",
    "\n",
    "def eval_env(agent,env):\n",
    "    state=env.reset()\n",
    "    policy = agent.get_policy(DEFAULT_POLICY_ID)\n",
    "    episode = MultiAgentEpisode(\n",
    "        PolicyMap(0,0),\n",
    "        lambda _, __: DEFAULT_POLICY_ID,\n",
    "        lambda: None,\n",
    "        lambda _: None,\n",
    "        0,\n",
    "    )\n",
    "    episode.user_data['initial_state'] = env.get_state()\n",
    "    done = False\n",
    "    episode_length=0\n",
    "    start_time=time.time()\n",
    "    while not done:\n",
    "        action, _, _ = policy.compute_single_action(state, episode=episode)\n",
    "        #print(episode_length)\n",
    "        #print(f\"action:{action}\")\n",
    "        #print(f\"action_mask {state['action_mask']}\")\n",
    "        #print(f\"action mask of action:{state['action_mask'][action]}\")\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        episode.length += 1\n",
    "        episode_length += 1\n",
    "    \n",
    "    return time.time()-start_time, episode_length, reward\n",
    "\n",
    "# use tune to register the custom environment for the ppo trainer\n",
    "tune.register_env('custom_jssp',env_creator)\n",
    "#tune.register_env('custom_jssp_single',env_creator())\n",
    "config = {\n",
    "    \"framework\": \"torch\",\n",
    "    \"disable_env_checking\":True,\n",
    "    \"num_workers\"       : 6,\n",
    "    \"rollout_fragment_length\": 50,\n",
    "    \"train_batch_size\"  : 500,\n",
    "    \"sgd_minibatch_size\": 64,\n",
    "    \"lr\"                : 0.0001,\n",
    "    #\"explore\"           :False,\n",
    "    #\"horizon\"           : 600,\n",
    "    #\"soft_horizon\"      : True,\n",
    "    \"num_sgd_iter\"      : 1,\n",
    "    #\"horizon\"           : 100,\n",
    "    \"mcts_config\"       : {\n",
    "        \"puct_coefficient\"   : 1.5,\n",
    "        \"num_simulations\"    : 100,\n",
    "        \"temperature\"        : 1.5,\n",
    "        \"dirichlet_epsilon\"  : 0.20,\n",
    "        \"dirichlet_noise\"    : 0.03,\n",
    "        \"argmax_tree_policy\" : True,\n",
    "        \"add_dirichlet_noise\": False,\n",
    "    },\n",
    "    \"ranked_rewards\"    : {\n",
    "        \"enable\": True,\n",
    "    },\n",
    "    \"model\"             : {\n",
    "        \"custom_model\": \"dense_model\",\n",
    "\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "agent = AlphaZeroTrainer( config=config, env='custom_jssp')\n",
    "#if restore_agent:\n",
    "#restore_path='training_checkpoints/checkpoints_az_jsslite/checkpoint-5'\n",
    "training_folder='/Users/felix/sciebo/masterarbeit/progra/model-based_rl/published_checkpoints/contrib_AlphaZero_custom_jssp_50160_00000_0_2022-10-17_18-46-57'\n",
    "#training_folder='/home/fs608798/masterarbeit/model-based_rl/training_checkpoints/checkpoints_tune/contrib/AlphaZero/contrib_AlphaZero_custom_jssp_50160_00000_0_2022-10-17_18-46-57'\n",
    "nr_checkpoints=0\n",
    "for f in os.listdir(training_folder):\n",
    "    if 'checkpoint' in f:\n",
    "        nr_checkpoints+=1\n",
    "eval_sheet={}\n",
    "run=0\n",
    "for f in os.listdir(training_folder):\n",
    "    if 'checkpoint' in f:\n",
    "        restore_path=training_folder+'/'+f+'/checkpoint-'+str(int(f[-6:]))\n",
    "        if os.path.exists(restore_path):\n",
    "            print(f)\n",
    "\n",
    "            agent.load_checkpoint(restore_path)\n",
    "            print(\"agent loaded\")\n",
    "            # here comes the evaluation:\n",
    "            for instance in instance_list:\n",
    "                print(instance)\n",
    "                eval_sheet[str(f[-6:]),instance]=eval_env(agent,jssp_light_obs_wrapper_multi_instances(instances_list=[instance]))\n",
    "            run+=1\n",
    "            print(f\"run: {run} of {nr_checkpoints} evaluated\")\n",
    "\n",
    "# generate csv    \n",
    "df=pd.DataFrame.from_dict(eval_sheet)\n",
    "df.to_csv('eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(eval_sheet)\n",
    "df.to_csv('eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "agent.evaluate(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('customjssp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7344f7b5995cbf62a990a56ee6eec8bd53f41a3aff848cd18f1feb05905aa9e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
