{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import rllib, tune\n",
    "from ray.rllib.contrib.alpha_zero.core.alpha_zero_trainer import AlphaZeroTrainer\n",
    "from ray.rllib.policy.sample_batch import DEFAULT_POLICY_ID\n",
    "from ray.rllib.policy.policy_map import PolicyMap\n",
    "from ray.rllib.evaluation.episode import MultiAgentEpisode\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.contrib.alpha_zero.models.custom_torch_models import DenseModel\n",
    "from ray.rllib.models.catalog import ModelCatalog\n",
    "import gym\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "ModelCatalog.register_custom_model(\"dense_model\", DenseModel)\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "train_agent=True\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"framework\": \"torch\",\n",
    "    \"disable_env_checking\":True,\n",
    "    \"num_workers\"       : 0,\n",
    "    \"rollout_fragment_length\": 50,\n",
    "    \"train_batch_size\"  : 500,\n",
    "    \"sgd_minibatch_size\": 64,\n",
    "    \"lr\"                : 0.0001,\n",
    "    \"num_sgd_iter\"      : 1,\n",
    "    \"mcts_config\"       : {\n",
    "        \"puct_coefficient\"   : 1.5,\n",
    "        \"num_simulations\"    : 100,\n",
    "        \"temperature\"        : 1.0,\n",
    "        \"dirichlet_epsilon\"  : 0.20,\n",
    "        \"dirichlet_noise\"    : 0.03,\n",
    "        \"argmax_tree_policy\" : False,\n",
    "        \"add_dirichlet_noise\": True,\n",
    "    },\n",
    "    \"ranked_rewards\"    : {\n",
    "        \"enable\": True,\n",
    "    },\n",
    "    \"model\"             : {\n",
    "        \"custom_model\": \"dense_model\",\n",
    "\n",
    "    },\n",
    "}\n",
    "\n",
    "def env_creator(env_config):\n",
    "    env = jss_lite(instance_path='resources/jsp_instances/standard/ft06.txt')\n",
    "    return env\n",
    "\n",
    "# use tune to register the custom environment for the ppo trainer\n",
    "tune.register_env('custom_jssp',env_creator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict(action_mask:Box([0 0 0 0 0 0 0 0 0 0 0 0], [1 1 1 1 1 1 1 1 1 1 1 1], (12,), int32), obs:Box([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (72,), float64))\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "from src.jss_lite.jss_lite import jss_lite\n",
    "env = jss_lite(instance_path='resources/jsp_instances/standard/ft06.txt')\n",
    "state=env.reset()\n",
    "#print(state)\n",
    "#print((max(2*env.n_jobs,env.n_machines)*6,))\n",
    "env=env_creator(\"test\")\n",
    "state=env.reset()\n",
    "print(env.observation_space)\n",
    "print(env.action_space.n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 18:33:27,501\tWARNING deprecation.py:46 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "(12,)\n",
      "(84,)\n",
      "0\n",
      "12\n",
      "<ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9f31e55390>\n",
      "(72,)\n",
      "(84,)\n",
      "12\n",
      "72\n",
      "<ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9f31e55360>\n",
      "<jss_lite instance>\n",
      "(12,)\n",
      "(84,)\n",
      "0\n",
      "12\n",
      "<ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9f31e556f0>\n",
      "(72,)\n",
      "(84,)\n",
      "12\n",
      "72\n",
      "<ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9f31e555d0>\n",
      "<jss_lite instance>\n",
      "(12,)\n",
      "(84,)\n",
      "0\n",
      "12\n",
      "<ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9f31e556f0>\n",
      "(72,)\n",
      "(84,)\n",
      "12\n",
      "72\n",
      "<ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9f31e555d0>\n",
      "<jss_lite instance>\n",
      "(12,)\n",
      "(84,)\n",
      "0\n",
      "12\n",
      "<ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9f31e556f0>\n",
      "(72,)\n",
      "(84,)\n",
      "12\n",
      "72\n",
      "<ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f9f31e555d0>\n",
      "<jss_lite instance>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "action is not in legal actions: implement to do nothing...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/felix/sciebo/masterarbeit/progra/model-based_rl/train_az_jsslite.ipynb Zelle 4\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/train_az_jsslite.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mstart training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/train_az_jsslite.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/train_az_jsslite.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     agent\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/train_az_jsslite.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtraining iteration \u001b[39m\u001b[39m{\u001b[39;00m_\u001b[39m}\u001b[39;00m\u001b[39m finished\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/felix/sciebo/masterarbeit/progra/model-based_rl/train_az_jsslite.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     agent\u001b[39m.\u001b[39msave_checkpoint(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtraining_checkpoints/checkpoints_az_jsslite\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/tune/trainable.py:360\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warmup_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n\u001b[1;32m    359\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 360\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    361\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mstep() needs to return a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m \u001b[39m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/trainer.py:1136\u001b[0m, in \u001b[0;36mTrainer.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m             \u001b[39m# Allow logs messages to propagate.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m             time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n\u001b[0;32m-> 1136\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1138\u001b[0m result \u001b[39m=\u001b[39m step_attempt_results\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mworkers\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers, WorkerSet):\n\u001b[1;32m   1141\u001b[0m     \u001b[39m# Sync filters on workers.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m step_ctx\u001b[39m.\u001b[39mshould_stop(step_attempt_results):\n\u001b[1;32m   1110\u001b[0m     \u001b[39m# Try to train one step.\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m         step_attempt_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_attempt()\n\u001b[1;32m   1113\u001b[0m     \u001b[39m# @ray.remote RolloutWorker failure.\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[39mexcept\u001b[39;00m RayError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1115\u001b[0m         \u001b[39m# Try to recover w/o the failed worker.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/trainer.py:1214\u001b[0m, in \u001b[0;36mTrainer.step_attempt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39m# No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evaluate_this_iter:\n\u001b[0;32m-> 1214\u001b[0m     step_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_plan_or_training_iteration_fn()\n\u001b[1;32m   1215\u001b[0m \u001b[39m# We have to evaluate in this training iteration.\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m     \u001b[39m# No parallelism.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mevaluation_parallel_to_training\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/agents/trainer.py:2211\u001b[0m, in \u001b[0;36mTrainer._exec_plan_or_training_iteration_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2209\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_iteration()\n\u001b[1;32m   2210\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2211\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_exec_impl)\n\u001b[1;32m   2212\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/util/iter.py:779\u001b[0m, in \u001b[0;36mLocalIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    778\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_once()\n\u001b[0;32m--> 779\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilt_iterator)\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/util/iter.py:807\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 807\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    808\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    809\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/util/iter.py:869\u001b[0m, in \u001b[0;36mLocalIterator.filter.<locals>.apply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_filter\u001b[39m(it):\n\u001b[0;32m--> 869\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    870\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metrics_context():\n\u001b[1;32m    871\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, _NextValueNotReady) \u001b[39mor\u001b[39;00m fn(item):\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/util/iter.py:869\u001b[0m, in \u001b[0;36mLocalIterator.filter.<locals>.apply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_filter\u001b[39m(it):\n\u001b[0;32m--> 869\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    870\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metrics_context():\n\u001b[1;32m    871\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, _NextValueNotReady) \u001b[39mor\u001b[39;00m fn(item):\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/util/iter.py:807\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 807\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    808\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    809\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/util/iter.py:904\u001b[0m, in \u001b[0;36mLocalIterator.flatten.<locals>.apply_flatten\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_flatten\u001b[39m(it):\n\u001b[0;32m--> 904\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    905\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    906\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/util/iter.py:807\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 807\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    808\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    809\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/util/iter.py:807\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 807\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    808\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    809\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py:415\u001b[0m, in \u001b[0;36mRolloutWorker.__init__.<locals>.gen_rollouts\u001b[0;34m()\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_rollouts\u001b[39m():\n\u001b[1;32m    414\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample()\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py:825\u001b[0m, in \u001b[0;36mRolloutWorker.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[39mif\u001b[39;00m log_once(\u001b[39m\"\u001b[39m\u001b[39msample_start\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    820\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGenerating sample batch of size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    821\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrollout_fragment_length\n\u001b[1;32m    822\u001b[0m         )\n\u001b[1;32m    823\u001b[0m     )\n\u001b[0;32m--> 825\u001b[0m batches \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_reader\u001b[39m.\u001b[39;49mnext()]\n\u001b[1;32m    826\u001b[0m steps_so_far \u001b[39m=\u001b[39m (\n\u001b[1;32m    827\u001b[0m     batches[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcount\n\u001b[1;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount_steps_by \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39menv_steps\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    829\u001b[0m     \u001b[39melse\u001b[39;00m batches[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39magent_steps()\n\u001b[1;32m    830\u001b[0m )\n\u001b[1;32m    832\u001b[0m \u001b[39m# In truncate_episodes mode, never pull more than 1 batch per env.\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[39m# This avoids over-running the target batch size.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py:115\u001b[0m, in \u001b[0;36mSamplerInput.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@override\u001b[39m(InputReader)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SampleBatchType:\n\u001b[0;32m--> 115\u001b[0m     batches \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_data()]\n\u001b[1;32m    116\u001b[0m     batches\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_extra_batches())\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batches) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py:288\u001b[0m, in \u001b[0;36mSyncSampler.get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@override\u001b[39m(SamplerInput)\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SampleBatchType:\n\u001b[1;32m    287\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m         item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_env_runner)\n\u001b[1;32m    289\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, RolloutMetrics):\n\u001b[1;32m    290\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics_queue\u001b[39m.\u001b[39mput(item)\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py:694\u001b[0m, in \u001b[0;36m_env_runner\u001b[0;34m(worker, base_env, extra_batch_callback, horizon, normalize_actions, clip_actions, multiple_episodes_in_batch, callbacks, perf_stats, soft_horizon, no_done_at_end, observation_fn, sample_collector, render)\u001b[0m\n\u001b[1;32m    692\u001b[0m t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    693\u001b[0m \u001b[39m# types: Dict[PolicyID, Tuple[TensorStructType, StateBatch, dict]]\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m eval_results \u001b[39m=\u001b[39m _do_policy_eval(\n\u001b[1;32m    695\u001b[0m     to_eval\u001b[39m=\u001b[39;49mto_eval,\n\u001b[1;32m    696\u001b[0m     policies\u001b[39m=\u001b[39;49mworker\u001b[39m.\u001b[39;49mpolicy_map,\n\u001b[1;32m    697\u001b[0m     sample_collector\u001b[39m=\u001b[39;49msample_collector,\n\u001b[1;32m    698\u001b[0m     active_episodes\u001b[39m=\u001b[39;49mactive_episodes,\n\u001b[1;32m    699\u001b[0m )\n\u001b[1;32m    700\u001b[0m perf_stats\u001b[39m.\u001b[39minference_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t2\n\u001b[1;32m    702\u001b[0m \u001b[39m# Process results and update episode state.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py:1154\u001b[0m, in \u001b[0;36m_do_policy_eval\u001b[0;34m(to_eval, policies, sample_collector, active_episodes)\u001b[0m\n\u001b[1;32m   1151\u001b[0m         policy: Policy \u001b[39m=\u001b[39m _get_or_raise(policies, policy_id)\n\u001b[1;32m   1153\u001b[0m     input_dict \u001b[39m=\u001b[39m sample_collector\u001b[39m.\u001b[39mget_inference_input_dict(policy_id)\n\u001b[0;32m-> 1154\u001b[0m     eval_results[policy_id] \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mcompute_actions_from_input_dict(\n\u001b[1;32m   1155\u001b[0m         input_dict,\n\u001b[1;32m   1156\u001b[0m         timestep\u001b[39m=\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mglobal_timestep,\n\u001b[1;32m   1157\u001b[0m         episodes\u001b[39m=\u001b[39;49m[active_episodes[t\u001b[39m.\u001b[39;49menv_id] \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m eval_data],\n\u001b[1;32m   1158\u001b[0m     )\n\u001b[1;32m   1160\u001b[0m \u001b[39mif\u001b[39;00m log_once(\u001b[39m\"\u001b[39m\u001b[39mcompute_actions_result\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1161\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   1162\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOutputs of compute_actions():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(summarize(eval_results))\n\u001b[1;32m   1163\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/alpha_zero_policy.py:97\u001b[0m, in \u001b[0;36mAlphaZeroPolicy.compute_actions_from_input_dict\u001b[0;34m(self, input_dict, explore, timestep, episodes, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     tree_node \u001b[39m=\u001b[39m episode\u001b[39m.\u001b[39muser_data[\u001b[39m\"\u001b[39m\u001b[39mtree_node\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     95\u001b[0m \u001b[39m# run monte carlo simulations to compute the actions\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m# and record the tree\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m mcts_policy, action, tree_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmcts\u001b[39m.\u001b[39;49mcompute_action(tree_node)\n\u001b[1;32m     98\u001b[0m \u001b[39m# record action\u001b[39;00m\n\u001b[1;32m     99\u001b[0m actions\u001b[39m.\u001b[39mappend(action)\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/mcts.py:129\u001b[0m, in \u001b[0;36mMCTS.compute_action\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_action\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[1;32m    128\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_sims):\n\u001b[0;32m--> 129\u001b[0m         leaf \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mselect()\n\u001b[1;32m    130\u001b[0m         \u001b[39mif\u001b[39;00m leaf\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    131\u001b[0m             value \u001b[39m=\u001b[39m leaf\u001b[39m.\u001b[39mreward\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/mcts.py:77\u001b[0m, in \u001b[0;36mNode.select\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mwhile\u001b[39;00m current_node\u001b[39m.\u001b[39mis_expanded:\n\u001b[1;32m     76\u001b[0m     best_action \u001b[39m=\u001b[39m current_node\u001b[39m.\u001b[39mbest_action()\n\u001b[0;32m---> 77\u001b[0m     current_node \u001b[39m=\u001b[39m current_node\u001b[39m.\u001b[39;49mget_child(best_action)\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m current_node\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/mcts.py:87\u001b[0m, in \u001b[0;36mNode.get_child\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m action \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren:\n\u001b[1;32m     86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mset_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate)\n\u001b[0;32m---> 87\u001b[0m     obs, reward, done, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     88\u001b[0m     next_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mget_state()\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren[action] \u001b[39m=\u001b[39m Node(\n\u001b[1;32m     90\u001b[0m         state\u001b[39m=\u001b[39mnext_state,\n\u001b[1;32m     91\u001b[0m         action\u001b[39m=\u001b[39maction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m         mcts\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmcts,\n\u001b[1;32m     97\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/customjssp/lib/python3.10/site-packages/ray/rllib/contrib/alpha_zero/core/ranked_rewards.py:58\u001b[0m, in \u001b[0;36mget_r2_env_wrapper.<locals>.RankedRewardsEnvWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m---> 58\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m     60\u001b[0m         reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr2_buffer\u001b[39m.\u001b[39mnormalize(reward)\n",
      "File \u001b[0;32m~/sciebo/masterarbeit/progra/model-based_rl/src/jss_lite/jss_lite.py:177\u001b[0m, in \u001b[0;36mjss_lite.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39m# update action mask from observation\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation[action,\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maction is not in legal actions: implement to do nothing...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[39m# as long timestemp list is not empty and action is a real and no dummy action; todo: implement if statement for dummy action\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m action \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs:\n\u001b[1;32m    180\u001b[0m     \u001b[39m#assure that it is no dummy job   \u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39m# assign task (from action) to available machine and update the machine status\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39m# block the free machine with current job\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[39m#todo: delete error\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: action is not in legal actions: implement to do nothing..."
     ]
    }
   ],
   "source": [
    "agent = AlphaZeroTrainer( config=config, env='custom_jssp')\n",
    "if train_agent:\n",
    "    # checkpoint_path = analysis.get_last_checkpoint() or args.checkpoint\n",
    "    ## use string number to restore pre trained agent\n",
    "    # nr_restore=\"10\"\n",
    "    #checkpoint_path=f'checkpoints_az/rllib_checkpoint{nr_restore}/checkpoint_{nr_restore.zfill(6)}/checkpoint-{nr_restore}'\n",
    "    #agent.load_checkpoint(\"checkpoints_az/rllib_checkpoint1\")\n",
    "    #print(\"awd\")\n",
    "    #agent.restore(\"checkpoints_az/rllib_checkpoint1/checkpoint_000001/checkpoint-1\")\n",
    "    #agent.load_checkpoint(\"published_checkpoints/az_taxi/checkpoint-34\")\n",
    "    print(\"start training\")\n",
    "    for _ in range(0,10):\n",
    "        agent.train()\n",
    "        print(f\"training iteration {_} finished\")\n",
    "        agent.save_checkpoint(f\"training_checkpoints/checkpoints_az_jsslite\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "length_list=[]\n",
    "reward_list=[]\n",
    "for _ in range(10):\n",
    "    policy = agent.get_policy(DEFAULT_POLICY_ID)\n",
    "    action_list=[]\n",
    "    env = jss_lite(instance_path='resources/jsp_instances/standard/abz5.txt')\n",
    "\n",
    "    obs = env.reset()\n",
    "    # env2 is copy for later going evaluation\n",
    "    env2=deepcopy(env)\n",
    "\n",
    "    episode = MultiAgentEpisode(\n",
    "        PolicyMap(0,0),\n",
    "        lambda _, __: DEFAULT_POLICY_ID,\n",
    "        lambda: None,\n",
    "        lambda _: None,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "    episode.user_data['initial_state'] = env.get_state()\n",
    "\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _, _ = policy.compute_single_action(obs, episode=episode)\n",
    "        action_list.append(action)\n",
    "        #print(action_dic[action])\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        #print(obs)\n",
    "        #env.render(render_mode='human')\n",
    "        #time.sleep(0.1)\n",
    "        episode.length += 1\n",
    "\n",
    "    length_list.append(episode.length)\n",
    "    reward_list.append(reward)\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('customjssp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7344f7b5995cbf62a990a56ee6eec8bd53f41a3aff848cd18f1feb05905aa9e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
