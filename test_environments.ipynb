{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "t=np.empty((4,1),dtype=object)\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import dummy\n",
    "import numpy as np\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "t=np.empty((4,1),dtype=object)\n",
    "import time\n",
    "import os\n",
    "from random import randrange\n",
    "env=jss_lite(instance_path='resources/jsp_instances/standard/ft06.txt')\n",
    "state=env.get_state()\n",
    "\n",
    "env.set_state(state)\n",
    "token=False\n",
    "for _ in range(1):\n",
    "    state=env.reset()\n",
    "    #print(state)\n",
    "    done=False\n",
    "    i=0\n",
    "    #print(state['obs'].shape)\n",
    "    #for i in range(150):\n",
    "    dummy_counter=0\n",
    "    #print(env.get_legal_actions(state))\n",
    "    while not done:\n",
    "        i+=1\n",
    "        legal_action=env.get_legal_actions(state)\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        #action=randrange(env.action_space.n)\n",
    "        #print(action)\n",
    "        if action < env.action_space.n/2:\n",
    "    \n",
    "\n",
    "            #print(\"before:\")\n",
    "            #env.render(start_count=1,x_bar=\"Job\",y_bar=\"Machine\")\n",
    "            state, reward, done, info=env.step(action)\n",
    "            if token==True:\n",
    "                token=False\n",
    "               # env.render()\n",
    "            #print(state['obs'].shape)\n",
    "\n",
    "        else:\n",
    "            dummy_counter+=1\n",
    "            #print(\"dummy action\")\n",
    "            #env.render()\n",
    "            #print(action)\n",
    "            #print(i)\n",
    "            print(env.get_legal_actions(\"obs\"))\n",
    "            #env.render()\n",
    "            state, reward, done, info=env.step(action)  \n",
    "\n",
    "            #print(state['obs'].shape)\n",
    "            token=True\n",
    "                #print(\"after:\")\n",
    "                #env.render(start_count=1,x_bar=\"Job\",y_bar=\"Machine\")\n",
    "        #print(action)\n",
    "        #tmp=(env.processed_and_max_time_job_matrix)\n",
    "        #print(env.count_finished_tasks_machine_matrix)\n",
    "        #print(env.production_list)\n",
    "        #print(state)\n",
    "        #env.render()\n",
    "        if done==True:\n",
    "            print(f\"finished! no legal actions possible after {i+1} steps\")\n",
    "            #print(env.timestemp_list)\n",
    "            break\n",
    "    print(dummy_counter)\n",
    "    #env.render(start_count=1,x_bar=\"Job\",y_bar=\"Machine\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dummy_counter)\n",
    "env.render(start_count=1,x_bar=\"Job\",y_bar=\"Machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.production_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(env.production_list[1,1])==tuple)\n",
    "for entry in env.production_list:\n",
    "    for p in (entry):\n",
    "        print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.processed_and_max_time_job_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "x_bar=\"Machine\"\n",
    "y_bar=\"Job\"\n",
    "df.sort_values(inplace=True,by=\"Job\")\n",
    "fig = px.timeline(df, x_start=\"Start\", x_end=\"Finish\", color=x_bar, y=y_bar)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(action)\n",
    "\n",
    "print(env.get_legal_actions(state))\n",
    "print(env.job_machine_matrix[action,env.count_finished_tasks_job_matrix[action]])\n",
    "cur_machine=env.current_machines_status\n",
    "job_ma=env.job_machine_matrix\n",
    "print(env.count_finished_tasks_job_matrix[action])\n",
    "#print(env.current_machines_status[env.job_machine_matrix[action,env.count_finished_tasks_job_matrix[action]],:])\n",
    "#print(env.job_machine_matrix[action,env.count_finished_tasks_job_matrix[action]])\n",
    "#print(env.current_machines_status)\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ale_py as ale\n",
    "ale.importroms('/Users/felix/sciebo/masterarbeit/progra/model-based_rl/roms/Space Invaders.bin')\n",
    "import gym\n",
    "env = gym.make('SpaceInvaders-v4')\n",
    "env.reset()\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import JSSEnv\n",
    "import src.jss_graph_env.disjunctive_graph_jss_env as jss_env\n",
    "from wrapper.jssplight_wrapper import jssp_light_obs_wrapper_multi_instances\n",
    "\n",
    "import src.jsp_instance_parser \n",
    "import time\n",
    "import gym\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "\n",
    "index=['klagenfurt','alex','lite']\n",
    "df=pd.DataFrame(np.zeros((3,5)),columns=['setuptime','resettime','50xactiontime','col4','col5'],index=index)\n",
    "#df=pd.DataFrame\n",
    "#df.set_index('index')\n",
    "for i in range(100):\n",
    "\n",
    "    def timer(innerfun):\n",
    "        tmp_t=time.time()\n",
    "        tmp_r=innerfun()\n",
    "        return time.time()-tmp_t,tmp_r\n",
    "\n",
    "    tmp_t=time.time()\n",
    "    env2=gym.make('jss-v1', env_config={'instance_path': 'resources/jsp_instances/standard/dmu79.txt'})\n",
    "    t_1=(time.time()-tmp_t)\n",
    "    df['setuptime']['klagenfurt']+=t_1/100\n",
    "    tmp_t=time.time()\n",
    "    instance_list=['resources/jsp_instances/standard/ft06.txt','resources/jsp_instances/standard/ft10.txt','resources/jsp_instances/standard/ft20.txt','resources/jsp_instances/standard/abz5.txt','resources/jsp_instances/standard/abz6.txt','resources/jsp_instances/standard/abz7.txt']\n",
    "#instance_list=['resources/jsp_instances/standard/ft06.txt']\n",
    "    env_3=jssp_light_obs_wrapper_multi_instances(instances_list=instance_list)\n",
    "    #env_3=jss_lite(instance_path='resources/jsp_instances/standard/dmu79.txt')\n",
    "    t_1=time.time()-tmp_t\n",
    "    df['setuptime']['lite']+=t_1/100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tmp_t=time.time()\n",
    "    path='resources/jsp_instances/standard/dmu79.txt'\n",
    "    curr_instance=src.jsp_instance_parser.parse_jps_standard_specification(path)\n",
    "    res,std_matrix=curr_instance\n",
    "    env_alex = jss_env.DisjunctiveGraphJssEnv(res,default_visualisations='gantt_console')\n",
    "    t_2=(time.time()-tmp_t)\n",
    "    df['setuptime']['alex']+=t_2/100\n",
    "    tmp_t=time.time()\n",
    "    t=env2.reset()\n",
    "    t_1=(time.time()-tmp_t)\n",
    "    df['resettime']['klagenfurt']+=t_1/100\n",
    "    tmp_t=time.time()\n",
    "    t2=env_alex.reset()\n",
    "    t_2=(time.time()-tmp_t)\n",
    "    df['resettime']['alex']+=t_2/100\n",
    "    tmp_t=time.time()\n",
    "    t=env_3.reset()\n",
    "    t_1=(time.time()-tmp_t)\n",
    "    df['resettime']['lite']+=t_1/100\n",
    "\n",
    "\n",
    "    state=env2.reset()\n",
    "    for i in range(50):\n",
    "        legal_action=state['action_mask']\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        tmp_t=time.time()\n",
    "        state, reward, done, info=env2.step(action)\n",
    "        t_1=(time.time()-tmp_t)\n",
    "        df['50xactiontime']['klagenfurt']+=t_1/50\n",
    "\n",
    "        if done==True:\n",
    "            print(f\"finished! no legal actions possible after {i} steps\")\n",
    "            break\n",
    "    state=env_3.reset()\n",
    "    for i in range(50):\n",
    "        legal_action=env_3.get_legal_actions()\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        tmp_t=time.time()\n",
    "        state, reward, done, info=env_3.step(action)\n",
    "        t_1=(time.time()-tmp_t)\n",
    "        df['50xactiontime']['lite']+=t_1/50\n",
    "\n",
    "        if done==True:\n",
    "            print(f\"finished! no legal actions possible after {i} steps\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "    action_list=np.arange(0,env_alex.n_jobs*env_alex.n_machines)\n",
    "    for i in range(50):\n",
    "        action_mask=env_alex.valid_action_mask()\n",
    "        actions=action_list[action_mask]\n",
    "        next_action=random.choice(actions)\n",
    "        #next_action=actions[action_mask[0]]\n",
    "        #print(next_action)\n",
    "        tmp_t=time.time()\n",
    "        state,reward,done,info =env_alex.step(next_action)\n",
    "        t_2=(time.time()-tmp_t)\n",
    "        df['50xactiontime']['alex']+=t_2/50\n",
    "        if done == True:\n",
    "            print(f\"finished after {i} steps\")\n",
    "            break\n",
    "        #env.render()\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.jss_lite.jss_lite import jss_lite\n",
    "import time\n",
    "env_3=jss_lite(instance_path='resources/jsp_instances/standard/dmu79.txt')\n",
    "\n",
    "state=env_3.reset()\n",
    "t=time.time()\n",
    "legal_action=env_3.get_legal_actions()\n",
    "print((time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "legal_action=env_3.get_legal_actions(state)\n",
    "print((time.time()-t)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_3=jss_lite(instance_path='resources/jsp_instances/standard/dmu80.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "instance_path = \"/Users/felix/sciebo/masterarbeit/progra/model-based_rl/resources/jsp_instances/standard/ft06.txt\"\n",
    "ins=instance_path.replace('/', ' ').split(' ')[-1].split('.')[-2]\n",
    "\n",
    "df=pd.read_csv('resources/jps_instances_metadata/instances_metadata.csv',index_col='Unnamed: 0')\n",
    "print(df['Optimal value'][ins])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper.jssplight_wrapper import jssp_light_obs_wrapper_multi_instances\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "import numpy as np\n",
    "#env=jss_lite(instance_path='/resources/jsp_instances/standard/la01.txt')\n",
    "#print(env.observation_space)\n",
    "#state=env.reset()\n",
    "\n",
    "#legal_action_old=state['action_mask']\n",
    "#instance_list=['resources/jsp_instances/standard/ft06.txt','resources/jsp_instances/standard/ft10.txt','resources/jsp_instances/standard/ft20.txt','resources/jsp_instances/standard/abz5.txt','resources/jsp_instances/standard/abz6.txt','resources/jsp_instances/standard/abz7.txt']\n",
    "p1='/Users/felix/sciebo/masterarbeit/progra/model-based_rl'\n",
    "env=jss_lite(instance_path=p1+'/resources/jsp_instances/standard/la01.txt')\n",
    "\n",
    "instance_list=['/resources/jsp_instances/standard/la01.txt','/resources/jsp_instances/standard/la02.txt','/resources/jsp_instances/standard/la03.txt','/resources/jsp_instances/standard/la04.txt']\n",
    "instance_list=[p1 + s for s in instance_list]\n",
    "#instance_list=['resources/jsp_instances/standard/ft06.txt']\n",
    "#env=jssp_light_obs_wrapper_multi_instances(instances_list=instance_list)\n",
    "reward=0\n",
    "while reward < 0.95:\n",
    "    done=False\n",
    "    state=env.reset()\n",
    "    #print(state['obs'])\n",
    "    i=0\n",
    "    while not done:\n",
    "        legal_action=state['action_mask']\n",
    "        action=np.random.choice(len(legal_action), 1, p=(legal_action / legal_action.sum()))[0]\n",
    "        \n",
    "        state, reward, done, info=env.step(action)\n",
    "        i+=1\n",
    "        if done==True:\n",
    "            #print(f\"finished! no legal actions possible after {i} steps\")\n",
    "            break\n",
    "\n",
    "env.render()\n",
    "print(env.env.instance)\n",
    "print(reward)\n",
    "\n",
    "print(state['action_mask'])\n",
    "print(env.dummy_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(env.max_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((env.env.current_timestep))\n",
    "print(env.env.optimal_value)\n",
    "print((env.env.current_timestep-env.env.optimal_value)/env.env.optimal_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import restore\n",
    "\n",
    "\n",
    "training_folder='/Users/felix/sciebo/masterarbeit/progra/model-based_rl/training_checkpoints/checkpoints_tune/contrib/AlphaZero/contrib_AlphaZero_custom_jssp_f8da7_00000_0_2022-10-07_11-11-05'\n",
    "for f in os.listdir(training_folder):\n",
    "    if 'checkpoint' in f:\n",
    "        restore_path=training_folder+'/'+f+'/checkpoint-'+str(int(f[-6:]))\n",
    "        if os.path.exists(restore_path):\n",
    "            print(restore_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mask= list(range(10))\n",
    "n_jobs=5\n",
    "print(action_mask)\n",
    "for i in action_mask:\n",
    "    print(i)\n",
    "real_actions=action_mask[:n_jobs]\n",
    "dummy_actions=action_mask[n_jobs:]\n",
    "print(real_actions)\n",
    "print(dummy_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.env.optimal_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x=[1,2,3,4,5]\n",
    "x=np.zeros(2)\n",
    "y=np.zeros(2)\n",
    "print([*x,*y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#print(os.path.dirname(__file__))\n",
    "p1='/Users/felix/sciebo/masterarbeit/progra/model-based_rl'\n",
    "instance_list=['/resources/jsp_instances/standard/la01.txt','/resources/jsp_instances/standard/la02.txt','/resources/jsp_instances/standard/la03.txt','/resources/jsp_instances/standard/la04.txt','/resources/jsp_instances/standard/la05.txt']\n",
    "instance_list=[p1 + s for s in instance_list]\n",
    "print(instance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracemalloc import start\n",
    "from ray import rllib, tune\n",
    "from ray.rllib.contrib.alpha_zero.core.alpha_zero_trainer import AlphaZeroTrainer\n",
    "from ray.rllib.policy.sample_batch import DEFAULT_POLICY_ID\n",
    "from ray.rllib.policy.policy_map import PolicyMap\n",
    "from ray.rllib.evaluation.episode import MultiAgentEpisode\n",
    "from ray.tune.registry import register_env\n",
    "#from ray.rllib.contrib.alpha_zero.models.custom_torch_models import DenseModel\n",
    "from src.jss_lite.custom_torch_models import DenseModel_activation_relu as DenseModel\n",
    "#from src.jss_lite.custom_torch_models import ConvNetModel\n",
    "from ray.rllib.models.catalog import ModelCatalog\n",
    "import gym\n",
    "#from ray.rllib.contrib.alpha_zero.core.alpha_zero_trainer import AlphaZeroTrainer\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import ray\n",
    "from src.jss_lite.jss_lite import jss_lite\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ModelCatalog.register_custom_model(\"dense_model\", DenseModel)\n",
    "\n",
    "#curr_dir=(os.path.dirname(__file__))\n",
    "curr_dir='/Users/felix/sciebo/masterarbeit/progra/model-based_rl'\n",
    "instance_list=['/resources/jsp_instances/standard/la01.txt','/resources/jsp_instances/standard/la02.txt','/resources/jsp_instances/standard/la03.txt','/resources/jsp_instances/standard/la04.txt','/resources/jsp_instances/standard/la05.txt']\n",
    "instance_list=[curr_dir + s for s in instance_list]\n",
    "instance_path=curr_dir+'/resources/jsp_instances/standard/ft06.txt'\n",
    "checkpoint_path='/training_checkpoints/checkpoints_tune'\n",
    "\n",
    "from wrapper.jssplight_wrapper import jssp_light_obs_wrapper\n",
    "from wrapper.jssplight_wrapper import jssp_light_obs_wrapper_multi_instances\n",
    "\n",
    "def env_creator(config):\n",
    "    #env = jssp_light_obs_wrapper(jss_lite(instance_path=instance_path))\n",
    "    env=jssp_light_obs_wrapper_multi_instances(instances_list=instance_list)\n",
    "    return env\n",
    "def env_creator_single(instance):\n",
    "    env=jssp_light_obs_wrapper_multi_instances(instances_list=instance)\n",
    "    return env\n",
    "\n",
    "def eval_env(agent,env):\n",
    "    state=env.reset()\n",
    "    policy = agent.get_policy(DEFAULT_POLICY_ID)\n",
    "    episode = MultiAgentEpisode(\n",
    "        PolicyMap(0,0),\n",
    "        lambda _, __: DEFAULT_POLICY_ID,\n",
    "        lambda: None,\n",
    "        lambda _: None,\n",
    "        0,\n",
    "    )\n",
    "    episode.user_data['initial_state'] = env.get_state()\n",
    "    done = False\n",
    "    episode_length=0\n",
    "    start_time=time.time()\n",
    "    while not done:\n",
    "        action, _, _ = policy.compute_single_action(state, episode=episode)\n",
    "        #print(episode_length)\n",
    "        #print(f\"action:{action}\")\n",
    "        #print(f\"action_mask {state['action_mask']}\")\n",
    "        #print(f\"action mask of action:{state['action_mask'][action]}\")\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        episode.length += 1\n",
    "        episode_length += 1\n",
    "    \n",
    "    return time.time()-start_time, episode_length, reward\n",
    "\n",
    "# use tune to register the custom environment for the ppo trainer\n",
    "tune.register_env('custom_jssp',env_creator)\n",
    "#tune.register_env('custom_jssp_single',env_creator())\n",
    "config = {\n",
    "    \"framework\": \"torch\",\n",
    "    \"disable_env_checking\":True,\n",
    "    \"num_workers\"       : 6,\n",
    "    \"rollout_fragment_length\": 50,\n",
    "    \"train_batch_size\"  : 500,\n",
    "    \"sgd_minibatch_size\": 64,\n",
    "    \"lr\"                : 0.0001,\n",
    "    #\"explore\"           :False,\n",
    "    #\"horizon\"           : 600,\n",
    "    #\"soft_horizon\"      : True,\n",
    "    \"num_sgd_iter\"      : 1,\n",
    "    #\"horizon\"           : 100,\n",
    "    \"mcts_config\"       : {\n",
    "        \"puct_coefficient\"   : 1.5,\n",
    "        \"num_simulations\"    : 100,\n",
    "        \"temperature\"        : 1.5,\n",
    "        \"dirichlet_epsilon\"  : 0.20,\n",
    "        \"dirichlet_noise\"    : 0.03,\n",
    "        \"argmax_tree_policy\" : True,\n",
    "        \"add_dirichlet_noise\": False,\n",
    "    },\n",
    "    \"ranked_rewards\"    : {\n",
    "        \"enable\": True,\n",
    "    },\n",
    "    \"model\"             : {\n",
    "        \"custom_model\": \"dense_model\",\n",
    "\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "agent = AlphaZeroTrainer( config=config, env='custom_jssp')\n",
    "#if restore_agent:\n",
    "#restore_path='training_checkpoints/checkpoints_az_jsslite/checkpoint-5'\n",
    "training_folder='/Users/felix/sciebo/masterarbeit/progra/model-based_rl/training_checkpoints/contrib_AlphaZero_custom_jssp_50160_00000_0_2022-10-17_18-46-57'\n",
    "#training_folder='/home/fs608798/masterarbeit/model-based_rl/training_checkpoints/checkpoints_tune/contrib/AlphaZero/contrib_AlphaZero_custom_jssp_50160_00000_0_2022-10-17_18-46-57'\n",
    "nr_checkpoints=0\n",
    "for f in os.listdir(training_folder):\n",
    "    if 'checkpoint' in f:\n",
    "        nr_checkpoints+=1\n",
    "eval_sheet={}\n",
    "run=0\n",
    "for f in os.listdir(training_folder):\n",
    "    if 'checkpoint' in f:\n",
    "        restore_path=training_folder+'/'+f+'/checkpoint-'+str(int(f[-6:]))\n",
    "        if os.path.exists(restore_path):\n",
    "            print(f)\n",
    "\n",
    "            agent.load_checkpoint(restore_path)\n",
    "            print(\"agent loaded\")\n",
    "            # here comes the evaluation:\n",
    "            for instance in instance_list:\n",
    "                print(instance)\n",
    "                eval_sheet[str(f[-6:]),instance]=eval_env(agent,jssp_light_obs_wrapper_multi_instances(instances_list=[instance]))\n",
    "            run+=1\n",
    "            print(f\"run: {run} of {nr_checkpoints} evaluated\")\n",
    "            df=pd.DataFrame.from_dict(eval_sheet)\n",
    "            df.to_csv('eval.csv')\n",
    "\n",
    "# generate csv    \n",
    "df=pd.DataFrame.from_dict(eval_sheet)\n",
    "df.to_csv('eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(eval_sheet)\n",
    "df.to_csv('eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "agent.evaluate(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('customjssp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7344f7b5995cbf62a990a56ee6eec8bd53f41a3aff848cd18f1feb05905aa9e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
